\documentclass[11pt,oneside,a4paper]{book}

\usepackage{standalone}
\input{../template.tex}
\addbibresource{analisis.bib}

%========== Comandos propios =============
\renewcommand{\P}{\mathcal{P}}
\DeclareMathOperator{\Id}{Id}
\DeclareMathOperator{\Fld}{Fld}
\DeclareMathOperator{\Rel}{Rel}
\DeclareMathOperator{\st}{st}
\DeclareMathOperator{\sh}{sh}
\DeclareMathOperator{\Int}{Int}
\newcommand{\existsst}{\exists^{\st}}
\newcommand{\forallst}{\forall^{\st}}
\newcommand{\forallsf}{\forall^{\rm sf}}
\DeclareMathOperator{\sign}{sign}
\DeclareMathOperator{\Or}{Or}

\def\upint{\mathchoice%
    {\mkern13mu\overline{\vphantom{\intop}\mkern7mu}\mkern-20mu}%
    {\mkern7mu\overline{\vphantom{\intop}\mkern7mu}\mkern-14mu}%
    {\mkern7mu\overline{\vphantom{\intop}\mkern7mu}\mkern-14mu}%
    {\mkern7mu\overline{\vphantom{\intop}\mkern7mu}\mkern-14mu}%
  \int}
\def\lowint{\mkern3mu\underline{\vphantom{\intop}\mkern7mu}\mkern-10mu\int}
% signos de integral inferior y superior de Riemann

\pgfplotsset{width=8cm}

\title{Relaciones Matemáticas: Lecturas de Análisis Matemático}
\author{Joseph Höhlen}

\begin{document}

\includepdf[pages=-]{portadas/build/calculo.pdf}

\frontmatter
\begin{titlepage}
	\raggedleft
	\rule{1pt}{\textheight}
	\hspace{0.05\textwidth}
	\parbox[b]{0.75\textwidth}{
		{\Huge\bfseries Relaciones\\[0.5\baselineskip]Matemáticas:}\\[2\baselineskip] % Título
		{\large\textit{Lecturas de Análisis Matemático}}\\[4\baselineskip] % Subtítulo
		{\Large\textsc{Joseph Höhlen}\\[0.5\baselineskip] \textit{Estudiante del Liceo Galvarino Riveros de Castro}} % Autor
		\vspace{0.5\textheight}
	}
\end{titlepage}

\newpage
~\vfill
\thispagestyle{empty}
\noindent \textsc{Curso Físico-Matemático, Liceo Galvarino Riveros de Castro, Chile}\\\\
\url{www.paginaweb.com}\\\\
La investigación comenzó el 20 de mayo de 2018 y fue hecha con \LaTeX{}, cualquier error o sugerencia dejar en el correo electrónico \url{josejustjose@gmail.com}.\\\\
\textit{Primera publicación, \today{}.} 

\tableofcontents

\chapter*{Preámbulo}
\addcontentsline{toc}{chapter}{Preámbulo}
\chaptermark{Preámbulo}
Para la investigación me he bastado de diversos textos que se me fueron recomendados o que he encontrado por cuenta propia, por supuesto todos ellos están en la bibliografía y son altamente recomendados, pero si me debo restringir a los más importantes he aquí una pequeña descripción (en orden de menos a más favorito):
\begin{enumerate}
\item \textbf{``Cálculo Integral y Diferencial (Serie Schaum)'' de Frank Ayres Jr. \cite{ayres1991calculo}:} Para ser honesto, no soy gran fan de la serie Schaum, aun que aprecio el hecho de que tenga tanta popularidad en el mundo de las ciencias. Sus trabajos suelen ser bastante completos, con explicaciones sencillas, pero es por lo mismo que suelo verlos con desprecio por su falta de generalidad y extrema redundancia. Aquí es cuando Frank Ayres Jr., probablemente el mejor escritor de la serie, se destaca, en particular me impresionó escuchar que trabajaba tanto cálculo en una como varias variables, y me decidí a revisarlo cuando encontramos un problema de precálculo que ni mis amigos de cálculo supieron resolver, a todo esto se le suma, de nuevo, la popularidad y calidad del texto que lo hacen la mejor opción para introducirse e incluso especializarse.
\item \textbf{``Cálculo Infinitesimal'' de Michael Spivak \cite{spivak1996calculo}:} Este es probablemente el segundo libro más recomendado en esta lista y no me cabe duda del porqué. Luego de leer varias versiones de un mismo capítulo en diferentes entregas, este siempre tenía al menos un ejemplo que desconocía y admiraba, debido a su elegancia. A pesar de ser un libro un tanto largo, otorga excelentes explicaciones, diagramas útiles y en particular, admiro (aun que no comparto) su uso de \textit{definiciones provicionales} para la explicación de alguna herramienta del cálculo.
\item \textbf{``Understanding Analysis'' de Stephen Abbott \cite{abbott2001understanding}:} Puedo preguntarle: ¿qué busca en un libro de análisis? ¿Qué tenga varios ejemplos para entenderlo mejor? Tal vez, usted es ambicioso y realmente espera encontrar problemas de alta dificultad, o tal vez le gusten las ilustraciones pues posee memoria visual. Pues déjeme decirle que la obra de Abbott es precisamente lo que busca. A pesar de que no he visto ediciones en español, no es muy difícil de entender y se destaca por ser bastante completo. En particular, lo considero esencial si usted busca entender la introducción axiomática con propiedades matemáticas interesantes; lo utilice bastante para el primer capítulo y la sección en cardinales grandes.
\item \textbf{``Real Mathematical Analysis'' de Charles C. Pugh \cite{pugh2002real}:} \textit{¿En inglés? ¿Y con casi 500 páginas? :(}, puedo comprender que un lector, un tanto principiante, se sienta así, sin embargo, no es lo que usted cree, el libro puede parecer denso, pero no lo es más que cualquier otro en esta lista. Si se decide a leerlo verá como las páginas se pasan volando, si bien posee muchos contenidos, las secciones con asterisco (*) no son obligatorias, más bien son matemáticas por diversión, e incluso me vi que en lecciones complejas, como topología, eran demasiado sencillas de leer. Muchos problemas en cada capítulo y logra lo que muy pocos libros pueden, ser formal y a la vez fácil.
\item \textbf{``Curso de Análise'' de Elon Lages Lima \cite{lima1995curso}:} Este libro llegó a mí por un estudiante de primer año de licenciatura en matemáticas y le estoy infinitamente agradecido. La versión portuguesa de este texto (no te preocupes si no hablas portugués, es entendible de igual manera) es perfecta para estudiantes universitarios. Posee ejercicios, diagramas sencillos, ejemplos y es completo para cualquiera que haya superado la enseñanza básica.
\item \textbf{``Introduction to Real Analysis'' de Robert G. Bartle y Donald R. Sherbert \cite{bartle2011introduction}:} Hay varias razones para tener a este texto como uno de mis favoritos: la primera es que a pesar de su dificultad es bastante popular, de manera que imagino que no será difícil de conseguir. Es uno de los textos más completos que he leído con respecto al tema y si bien no posee tratamiento directo sobre topología (que en mi opinión es uno de los temas más complicados del libro), en todos los otros capítulos posee una infinitud de teoremas, algunos bastante raros entre los libros de análisis, de manera que si te gustan las propiedades, este es para ti.
\item \textbf{``Modern Real Analysis'' de William P. Ziemer \cite{gariepy1995modern}:} También otro libro que me llegó como recomendación. En principio su diseño simple de \LaTeX{} me desanimo a hecharle una mirada, pero en tanto fui avanzando en mi escritura se me fue haciendo uno de los libros más importantes. Su contenido es de lo más general que hay, las expresiones son sumamente ordenadas y formales, y la abundancia de problemas en cada \textbf{sección} (no por capítulo), vuelven a esta una de las obras más dedicadas al tema del análisis. Como su título sugiere, es un texto bastante moderno para los estándares actuales.
\item \textbf{``Análisis Matemático'' y ``Análisis No Estándar'' de Carlos Ivorra Castillo \cite{castillo2018analisis}-\cite{castillo2018ane}:} De la Universidad de Valencia, en España, les presento a lo que en mi opinión es el mejor autor de textos técnicos en matemáticas. En general, todos sus libros son de los más completos (incluso en comparación con los textos norteamericanos y europeos), están llenos de teoremas, diagramas, etc. Todos son accesibles en su sitio web \url{https://www.uv.es/ivorra/Libros/Libros.htm} y poseen numerosas recomendaciones también. Fundamentalmente, Castillo posee dos problemas: la carencia de una sección dedicada a problemas por capítulo y lo difícil de entender sus textos; en particular, me tardaba un máximo de medio mes por capítulo suyo, pero si logras pasar ello te das cuenta que es un autor a quien le sobra la \textit{elegancia} y la \textit{formalidad}, y este libro es, en mi opinión, la introducción más fina a las matemáticas.
\end{enumerate}

\chapter*{Introducción}
\addcontentsline{toc}{chapter}{Introducción}
\chaptermark{Introducción}
La matemática es una ciencia formal, esto significa que se sustenta en principios idealistas (axiomas), para desarrollarse y tornarse específico. La especificación o ramificación de las matemáticas depende de tu enfoque y tus axiomas en particular, por ejemplo, se dice que estudias lógica y teoría de conjuntos cuando tus axiomas tienden a utilizar objetos lógicos (como relaciones y funciones) y conjuntos, la geometría menciona en sus axiomas a los puntos, la teoría de números habla de enteros, en particular y así sucesivamente. Lo que le sigue al lector en las páginas subsiguientes de este libro es un breve estudio del análisis matemático. Pero, si la geometría habla de puntos, ¿de qué habla el análisis? En resumidas cuentas, de todo, de matemáticas en general.

El análisis lo considero como el punto de partida ideal para quien sea que quiera profundizar en sus estudios de matemáticas, esta rama requiere del uso de muchos conceptos particulares que se reparten entre casi todas las subdivisiones populares de las matemáticas de modo que sirve a su vez como la perfecta introducción. Esto lo menciono de antemano, pues mis futuros artículos y libros de matemáticas pueden obviar muchos de los contenidos que aquí pretendo implantar, de forma que si crees que no posees mucho conocimiento matemático este es tu lugar para empezar.

\textbf{¿Por qué el análisis y no cualquier otra cosa?} Usualmente te diría que si tienes la intención de aprender una rama de las matemáticas, cualquiera, sea estadística u álgebra lineal, por dar unos cuantos ejemplos, que buscaras un libro o un par de videos de internet y te enfocases en ello, pero a menos que quieras estudiar dichas materias superficialmente (sin los teoremas difíciles con usos de conceptos como \textit{función biyectiva} u \textit{anillo}) se te hará complicado comenzar desde cero. El análisis, por otro lado, es más comprensible desde sus inicios e incluso formula pequeños teoremas con dichos conceptos, de forma que estudiarlo te asegura una base para cualquier otra cosa.

\textbf{¿Estándar o no estándar?} Si quieres estudiar análisis aparecerá la primera distinción particular, la decisión de estudiar de acuerdo al método estándar o no estándar y, a menos que poseas previo conocimiento de cada uno (lo cual se trata de no exigir en este libro) tu elección será aleatoria. Los métodos estándares son aquellos que se nos enseñan desde la escuela básica, es por eso que son mucho más conocidos y probablemente más fáciles de entender (puesto que se relacionan a números conocidos). Por otra parte, los métodos no estándar son, bueno, no convencionales, consisten en el uso de estos números, los no estándar, para facilitar ciertas demostraciones en el análisis, aun que su introducción no es fácil de entender, pues requiere de la aplicación de dos axiomas nuevos  y una nueva idea: ser no estándar.

Este libro utiliza los métodos no estándares y estándares. Por una parte me asegure de que todo fuera explicado lógicamente de forma que las expresiones no parezcan espontáneas, pero por otro trate de completar lo más posible el libro (sin introducir conceptos ``de más'') utilizando deducciones estándares. Ahora, el libro no es un texto para enseñarle a los bebes como sumar, posee cierto grado de complejidad y se exige conocimiento previo en el sentido de que nuestra meta no es crear conceptos en primera instancia (el concepto de número no debe sonar nuevo) sino formalizar o encontrar un camino lógico para construir estas ideas.

Quiero agradecer a mis amigos, Bastian Ruay, Gabriel Barría, Diego de la Barra, Camilo Lagos y a mi profesor José Luis Oyazo en particular por haber sido de ayuda en la elaboración de este libro, ya sea por su exposición ante temas que desconocía, por revisión, por recomendación de textos o cualquier otra razón. Este libro se lo dedico a todos los alumnos que buscan el camino más lógico introductorio para las matemáticas, que lo disfrute.

\hfill --José Ignacio Cuevas Barrientos alias \textit{Joseph Höhlen}

\mainmatter
\part{Precálculo}

\chapter{Introducción a los números}
El análisis matemático supone digamos un breve vistazo a las matemáticas discretas enseñadas en todo lo que es previo a la universidad de forma que en cierto sentido se tocan temas que recorren toda la matemática tales como un poco de álgebra (principalmente lineal), geometría (principalmente analítica), aritmética e inclusive lógica (en forma de teorías axiomáticas de conjuntos). El objetivo de este libro no es estudiar a fondo estas fantásticas subdivisiones de las matemáticas, sino analizarlas superficialmente para incrementar nuestros recursos y aplicaciones de lo que nos reúne hoy, el análisis como tal.

Ahora, se le exige al lector un cierto tipo de conocimiento previo, digamos saber contar, sumar, multiplicar, etc. Pero apesar de ello se comenzará a estudiar el análisis desde un punto de partida vacío, de forma que completemos su estudio con puras deducciones simples.

\section{Conjuntos}
\begin{mydef}[Conjuntos]
Corresponden a entidades matemáticas que contienen o coleccionan otras entidades (que pueden ser números, puntos o más conjuntos).

Se suelen denotar por las primeras letras del alfabeto en mayúsculas, por ejemplo $A$, $B$, $C$, etc.
\end{mydef}
Por el momento no hablaremos de números, ni puntos, ni otros objetos, sólo supondremos que tenemos a conjuntos, el resto serán descubiertos en la práctica, de forma que los conjuntos sólo puedan contener más conjuntos.

Cuando queramos decir que un objeto $x$ es un elemento de un conjunto $A$ escribiremos $x\in A$ (de lo contrario $x\notin A$).

Para describir los elementos que pertenezcan a $A$ los enlistamos separados por comas y delimitados por corchetes:
$$A=\{a,b,c,\dots\}$$
Ahora, sólo tenemos un objeto (los conjuntos), pero para poder realizar deducciones y demostraciones aún requerimos de una serie de teoremas primitivos, a estos les llamaremos \textit{axiomas} y estarán confinados dentro de \textit{teorías} y \textit{sistemas formales}. Por el momento estudiaremos los axiomas de Zermelo-Fraenkel (o ZFC\footnote{La C es de \textit{axiom of choice} o \textit{axioma de elección}, a veces incluido en este modelo y cuyas aplicaciones veremos más adelante.} para acortar) los cuales son:
\begin{axiom}[de Extensionalidad]
Si dos conjuntos $A$ y $B$ poseen los mismos elementos, entonces se dice que son iguales.
$$
\forall AB,\;(x\in A\iff x\in B)\iff A=B
$$
\end{axiom}
Para extender este axioma introduciremos también la notación de que si, por ejemplo, todo elemento de $A$ está en $B$ (pero no necesariamente esto se da a la inversa) entonces $A\subseteq B$ (léase ``$A$ es subconjunto de $B$''). Recíprocamente si $B$ contiene todo elemento de $A$ entonces $B\supseteq$ (léase ``$B$ es superconjunto de $A$'').

\begin{prop}[Propiedades del subconjunto]
Las propiedades de la subconjunción son:
\begin{enumerate}
\item $A\subseteq A$ (reflexividad).
\item $A\subseteq B\wedge B\subseteq A\iff A=B$ (anti-simetría).
\item $A\subseteq B\wedge B\subseteq C\implies A\subseteq C$ (transitividad).
\item $A\subseteq B\iff B\supseteq A$.
\end{enumerate}
También son aplicables para $\supseteq$.
\end{prop}

La propiedad de sub o superconjunción se le agrega el apellido \textit{``estricto''} cuando se asumen las propiedades con la certeza de que ambos conjuntos son distintos, es decir:
$$
\begin{aligned}
A\subset B&\equiv A\subseteq B\wedge A\neq B\\
A\supset B&\equiv A\supseteq B\wedge A\neq B
\end{aligned}
$$

\begin{prop}[Propiedades del subconjunto estricto]
Las propiedades del subconjunto estricto son:
\begin{enumerate}
\item $A\not\subset A$ (irreflexividad).
\item $A\subset B\iff B\not\subset A$ (asimetría).
\item $(A\subset B\wedge B\subseteq C)\implies A\subset C$.
\item $(A\subseteq B\wedge B\subset C)\implies A\subset C$.
\item $(A\subset B\wedge B\subset C)\implies A\subset C$ (transitividad).
\item $A\subset B\iff B\supset A$.
\item $A\subset B\iff A\not\supseteq B$.
\end{enumerate}
También aplicable para $\supset$.
\end{prop}

\begin{axiom}[de Especificación]
Podemos definir un subconjunto $A$ de $B$ como todos los elementos de $B$ que cumplan la propiedad $P(x)$:
$$
\forall B\exists A\forall x\in B,\;(x\in A\iff x\in B\wedge P(x))
$$
\end{axiom}
\begin{thm}[Paradoja de Russell]\label{thm:russell}
No existe el conjunto $R$ tal que
$$R=\{x:x\notin x\}$$
\end{thm}
\begin{proof}
Supongamos por contradicción que $R$ existe, luego, por axioma de la especificación debe ser subconjunto de un tal $A$. Su mera existencia implica la contradicción de que $R\in R$ es equivalente a $R\notin R$, por tanto, $R\notin A$, es decir, $R$ no existe dentro de ningún conjunto.
\end{proof}
Se le llama al teorema~\ref{thm:russell} la \textit{paradoja de Russell}, porque quienes lo postularon (Bertrand Russell y Ernst Zermelo) lo utilizaron en un principio para demostrar la inconsistencia del intento de teoría axiomática de Georg Cantor. Eventualmente, el mismo Cantor admite que su teoría era inconsistente cuando se da cuenta de que se puede demostrar y refutar toda proposición en ella.

El error de Cantor fue el enunciar que existe todo conjunto definido por
$$A=\{x:P(x)\},$$
lo cual no es tan diferente del axioma de especificación, pero el detalle de decir que $A$ es subconjunto de otro es lo que marca la diferencia.
\begin{axiom}[-- Conjunto vacío]
Existe un conjunto que no posee elementos llamado \textit{conjunto vacío} y denotado como $\emptyset$.
$$
\begin{aligned}
&\exists\emptyset\forall x,\; x\notin\emptyset\\
&\emptyset=\{x:x\neq x\}
\end{aligned}
$$
\end{axiom}
Este conjunto esta dotado de muchas propiedades, por el momento podemos enunciar que, por ejemplo, siempre se cumple que $x\supseteq\emptyset$. Además, es único porque por el axioma de entensionalidad de existir más conjuntos vacíos serían el mismo.
\begin{thm}[Teorema de Cantor]
No existe un conjunto que contenga a todos los conjuntos. Es decir, no existe un
$$U=\{x:x=x\}.$$
\end{thm}
\begin{proof}
Supongamos que existe tal conjunto, luego, por definición todo conjunto pertenece a él y podríamos enunciar
$$R=\{x\in U:x\notin x\}$$
y, nuevamente, estamos obligados a admitir que $R\in U$ lo que conlleva a la paradoja de Russell y a demostrar inconsistente a nuestra propia teoría.
\end{proof}

\section{Operaciones sobre conjuntos}
\begin{axiom}[del Par]
Téngase dos conjuntos $x$ e $y$, existe un conjunto tal que sus elementos son los mismos $x$ e $y$.
$$
\begin{aligned}
&\forall xy\exists z:(x\in z\wedge y\in z)\\
&z=\{x,y\}
\end{aligned}
$$
\end{axiom}
El axioma del par hace referencia, sin embargo, a lo que matemáticamente llamamos un \textit{par desordenado}, puesto que $\{x,y\}=\{y,x\}$ por el axioma de extensionalidad. Entonces podemos definir un par ordenado como
$$
(x,y)=\{\{x\},\{x,y\}\}
$$
donde evidentemente, el orden sí importa. Este se le llama \textit{par ordenado de Kuratowski} (en memoria de su creador). Otro intento destacable es el \textit{par ordenado de Wiener} que se define como:
$$(x,y)=\{\{\emptyset,\{x\}\},\{\{y\}\}\}$$
En realidad, como definamos el par ordenador es arbitrario, sólo importa que no existan par ordenados iguales mientras dichos elementos difieran.

\begin{lem}\label{lem:ordered-pair}
Dado un par desordenado $\{x,y\}=\{x',y'\}$ se da que $x=x'$ e $y=y'$ o $x=y'$ e $y=x'$.
\end{lem}
\begin{thm}
Dado un par ordenado $(x,y)=(x',y')$ se da que $x=x'$ e $y=y'$.
\end{thm}
\begin{proof}
Por definición del par ordenado $\{\{x\},\{x,y\}\}=\{\{x'\},\{x',y'\}\}$, luego por el lema~\ref{lem:ordered-pair} se tiene que $\{x\}=\{x'\}$ e $\{x,y\}=\{x',y'\}$ o $\{x\}=\{x',y'\}$ e $\{x,y\}=\{x'\}$.

En el primer caso, por axioma de extensionalidad $x=x'$ y por el lema~\ref{lem:ordered-pair} $y=y'$.

Si se da el segundo caso, también por axioma de extensionalidad, los dos conjuntos deben tener los mismos elementos, es decir, $x=y=x'=y'$.
\end{proof}

Luego, se define la terna ordenada como $(x,y,z)=((x,y),z)$, en general, una $n$-tupla ordenada se define como
$$(x_1,x_2,\dots,x_n)=((x_1,x_2,\dots,x_{n-1}),x_n).$$
\begin{axiom}[de Unión]
Dados cualesquiera dos conjuntos $A$ y $B$, existe otro tal que sus elementos son todos los de $A$ y $B$.
$$
\forall AB\exists C\forall x,\;x\in A\vee x\in B\iff x\in C
$$
\end{axiom}
También por el axioma de especificación se puede denotar como que
$$C=\{x:x\in A\text{ o }x\in B\}.$$
Para reducir esta notación diremos que este tal $C$ corresponde a la operación $A\cup B$ (léase ``unión entre $A$ y $B$''). Esta operación se hace más fácil de entender con los llamados diagramas de Venn, en donde el resultado de la operación aparece como el área pintada.
\begin{figure}
\centering
\begin{tikzpicture}
\draw[pattern=north east lines, pattern color=niceblue] (0,0) circle (2) node[fill=white,left]{$A$};
\draw[pattern=north west lines, pattern color=nicered] (2.5,0) circle (2) node[fill=white,right]{$B$};
\draw (0,0) circle (2) (2.5,0) circle (2);
\draw (1.25,0) node[fill=white]{$A\cup B$};
\end{tikzpicture}
\caption{Unión de conjuntos.}
\end{figure}

\begin{prop}[Propiedades de la unión]
La operación de unión cuenta con las propiedades de:
\begin{enumerate}
\item $A\cup A=A$ (idempotencia).
\item $A\cup B=B\cup A$ (conmutatividad).
\item $(A\cup B)\cup C=A\cup(B\cup C)$ (asociatividad).
\item $A\cup\emptyset=A$ (elemento neutro).
\end{enumerate}
\end{prop}

Aquí, ademas, introduciremos una notación curiosa, supongamos que queremos unir muchos elementos, digamos un conjunto de conjuntos\footnote{En ZFC se suele llamar a los conjuntos de conjuntos, \textit{clases}.} $X=\{X_1,X_2,\dots,X_n\}$, esto se denota como
$$
\bigcup_{x\in X}x=X_1\cup X_2\cup\cdots\cup X_n.
$$
Para reducir notación, se escribirá $\bigcup X$ en lugar de $\bigcup_{x\in X}x$.

También podemos definir un conjunto $A\cap B$ (léase ``intersección entre $A$ y $B$'') tal que posea los elementos que son estrictamente tanto de $A$ como de $B$, es decir:
$$
A\cap B=\{x\in A:x\in B\}
$$
\begin{figure}
\centering
\begin{tikzpicture}
\begin{scope}
\clip (0,0) circle (2);
\clip (2.5,0) circle (2);
\draw[pattern=north east lines, pattern color = nicepurple] (1.25,0) circle (2) node[fill=white]{$A\cap B$};
\end{scope}
\draw (0,0) circle (2) node[left]{$A$} (2.5,0) circle (2) node[right]{$B$};
\end{tikzpicture}
\caption{Intersección de conjuntos.}
\end{figure}

\begin{prop}[Propiedades de la intersección]
La operación de la intersección cuenta con las propiedades de:
\begin{enumerate}
\item $A\cap A=A$ (idempotencia).
\item $A\cap B=B\cap A$ (conmutatividad).
\item $(A\cap B)\cap C=A\cap(B\cap C)$ (asociatividad).
\item $A\cap\emptyset=\emptyset$ (absorbente o aniquilador).
\end{enumerate}
\end{prop}

Al igual que con la unión cuando queramos encontrar la intersección de los elementos de una clase $X=\{X_1,X_2,\dots,X_n\}$, podemos utilizar libremente la notación
$$
\bigcap_{x\in X}x=X_1\cap X_2\cap\cdots\cap X_n.
$$
Para reducir notación, se escribirá $\bigcap X$ en lugar de $\bigcap_{x\in X}x$.

También diremos de ahora en adelante que todo par de conjuntos que no posean elementos en común, es decir, tales que $A\cap B=\emptyset$ serán \textit{disjuntos} entre sí.

Otra operación posible es la de un conjunto $A\setminus B$ (léase ``diferencia de $A$ con $B$'') tal que posee todos los elementos de $A$ que no están en $B$, es decir:
$$
A\setminus B=\{x\in A:x\notin B\}
$$
\begin{figure}
\centering
\begin{tikzpicture}
\draw[pattern=north east lines, pattern color=niceblue] (0,0) circle (2) node[fill=white,left]{$A\setminus B$};
\fill[white] (2.5,0) circle (2);
\draw (0,0) circle (2) ++(0,2) node[above]{$A$} (2.5,0) circle (2) ++(0,2) node[above]{$B$};
\end{tikzpicture}
\caption{Diferencia de conjuntos.}
\end{figure}

\begin{prop}[Propiedades de la diferencia]
Sean $A$ y $B$ conjuntos cualesquiera se cumple:
\begin{enumerate}
\item $A\setminus\emptyset=A$ (elemento neutro).
\item $A\setminus A=\emptyset$ (inverso).
\item $A\setminus(B\cup C)=(A\setminus B)\cap(A\setminus C)$.
\item $A\setminus(B\cap C)=(A\setminus B)\cup(A\setminus C)$.
\end{enumerate}
\end{prop}

También existe un conjunto $A\Delta B$ (léase ``diferencia simétrica de $A$ con $B$'') tal que posee todos los elementos no-comunes entre $A$ y $B$, osea
$$
\begin{aligned}
A\Delta B&=(A\setminus B)\cup(B\setminus A)\\
&={x\in A\cup B:x\notin A\cap B}.
\end{aligned}
$$
\begin{figure}
\centering
\begin{tikzpicture}
\draw[pattern=north east lines, pattern color=niceblue] (0,0) circle (2);
\draw[pattern=north east lines, pattern color=nicered] (2.5,0) circle (2);
\begin{scope}
\clip (0,0) circle (2);
\clip (2.5,0) circle (2);
\fill[white] (1.25,0) circle (2) node[black]{$A\Delta B$};
\end{scope}
\draw (0,0) circle (2) ++(0,2) node[above]{$A$} (2.5,0) circle (2) ++(0,2) node[above]{$B$};
\end{tikzpicture}
\caption{Diferencia simétrica entre conjuntos.}
\end{figure}

\begin{prop}[Propiedades de la diferencia simétrica]
La diferencia simétrica consta de las propiedades de:
\begin{enumerate}
\item $A\Delta B=B\Delta A$ (conmutatividad).
\item $(A\Delta B)\Delta C=A\Delta(B\Delta C)$ (asociatividad).
\item $A\Delta\emptyset=A$ (elemento neutro).
\item $A\Delta A=\emptyset$ (inverso).
\end{enumerate}
\end{prop}

Además, podríamos decir que dado un subconjunto $A$ de $B$, existe un conjunto $\complement_B A$ (léase ``complemento de $A$ en $B$'') tal que es subconjunto de $B$ y posee todos los elementos que no pertenecen a $A$.
$$
\complement_B A=\{x\in B:x\notin A\}
$$

\begin{figure}
\centering
\begin{tikzpicture}[scale=1.5]
\draw[pattern=north east lines,pattern color=nicegreen] (0,0) rectangle (3,2);
\fill[white] (1.5,1) circle (.5);
\draw (0,0) rectangle (3,2) node[above right]{$B$} (1.5,1) circle (.5) node {$A$} (2,1.5) node[right]{$\complement_B A$}; 
\end{tikzpicture}
\caption{Complemento de un subconjunto.}
\end{figure}

\begin{prop}[Propiedades del complemento]
Dados conjuntos cualesquiera $A$ y $B$ subconjuntos de $X$ se cumple:
\begin{enumerate}
\item $\complement_X \emptyset=X$.
\item $\complement_X X=\emptyset$.
\item $\complement_X(\complement_X A)=A$ (doble complemento).
\item $A\cup \complement_X A=X$.
\item $A\cap \complement_X A=\emptyset$.
\item $A\setminus B=A\cap\complement_X B$.
\item $\complement_X(A\cup B)=\complement_X A\cap\complement_X B$ (De Morgan).
\item $\complement_X(A\cap B)=\complement_X A\cup\complement_X B$ (De Morgan).
\item $\complement_X(A\setminus B)=\complement_X A\cup B$.
\end{enumerate}
\end{prop}
A veces se utiliza la notación $A^\complement$ para señalar el complemento, usualmente para hacer los procesos más fáciles de transcribir al papel.
\begin{axiom}[por partes]
Sea $A$ un conjunto cualquiera, existe un conjunto tal que posee todos los posibles subconjuntos de $A$:
$$
\begin{aligned}
&\forall A,\;(\exists \P A:(\forall x,\;(x\subseteq A\iff x\in \P A)))\\
&\P A=\{x:x\subseteq A\}
\end{aligned}
$$
\end{axiom}

\begin{prop}[Propiedades del conjunto potencia]
Sean $A$ y $B$ conjuntos cualesquiera, se cumple:
\begin{enumerate}
\item $\P\emptyset=\{\emptyset\}$.
\item $\emptyset,A\in\P A$.
\item $A\subseteq B\iff\P A\subseteq\P B$.
\item $\P(A\cap B)=\P A\cap\P B$.
\item $\P A\cup\P B\subseteq\P(A\cup B)$.
\end{enumerate}
\end{prop}

\begin{prop}
Para todo conjunto $A$ existe un conjunto $R(A)$ tal que $R(A)\in\P A$, pero $R(A)\notin A$.
\end{prop}
\begin{proof}
Supongamos un conjunto $R(A)$ tal que
$$R(A)=\{x\in A:x\notin x\},$$
luego, por definición $R(A)\in\P A$, pero por reducción al absurdo $R(A)\notin A$.
\end{proof}
\begin{cor}
Todo conjunto posee un superconjunto estricto, es decir, para todo $A$ existe un $B$ tal que $B\supset A$.
\end{cor}
\begin{proof}
Sólo basta suponer que $B=A\cup R(A)$ o que $B=A\cup\{A\}$ (puesto que por teorema de Russell $A\notin A$).
\end{proof}

\begin{thm}
Para todo par de conjuntos no vacíos $A$ y $B$ existe un conjunto que contiene a todos los posibles pares ordenados de elementos de $A$ con $B$ (en ese orden).
\end{thm}
\begin{proof}
Primero, admitamos la notación de que dicho conjunto es $A\times B$ (léase ``producto de $A$ con $B$'') y, por tanto, se definiría como
$$A\times B=\{(x,y):x\in A, y\in B\},$$
pero, el axioma de la especificación requiere que dicho conjunto sea subconjunto de otro.

Por construcción sabemos que los conjuntos no son vacíos y podríamos decir que hay un $x\in A$ y un $y\in B$ tal que ${x,y}\subset A\cup B$, aquí aplicamos el axioma por partes para decir que
$$\{x\},\{x,y\}\in\P(A\cup B),$$
por lo tanto, el par ordenado $(x,y)=\{\{x\},\{x,y\}\}$ es elemento de la segunda potencia de la unión entre $A$ y $B$, es decir,
$$(x,y)\in\P\P(A\cup B).$$
Finalmente, el mismo axioma de especificación nos permite construir el conjunto
$$
A\times B=\{(x,y)\in\P\P(A\cup B):x\in A, y\in B\}.
$$
\end{proof}
\begin{figure}
\centering
\begin{tikzpicture}
\draw (0,0) rectangle (4,3) node[above right]{$A\times B$};
\draw[gray!50,very thin,step=.5] (0,0) grid (4,3);
\draw[gray,very thin] (0,0) grid (4,3);
\fill (2,1.5) circle (.05) node[below right]{$(x,y)$};
\draw (2,.1) -- ++(0,-.2) node[below]{$x\in A$} (.1,1.5) -- ++(-.2,0) node[left]{$y\in B$};
\end{tikzpicture}
\caption{Producto de $A$ con $B$.}
\end{figure}

Como dato extra, introducimos la notación de que el producto (ordenado) de $n$ conjuntos es
$$
\begin{aligned}
A_1\times\cdots\times A_n&=(A_1\times\cdots\times A_{n-1})\times A_n\\
&=\{(x_1,\dots,x_n)\in\P\P(A_1\cup\cdots\cup A_n):x_1\in A_1,\dots,x_n\in A_n\}
\end{aligned}
$$
A su vez, el producto de $n$ veces el mismo conjunto lo denotaremos como $A^n$ tal que
$$A^{1}=A,\quad A^{n'}=A^{n}\times A.$$
Es decir que $A\times A$ se puede abreviar como $A^2$.

\section{Funciones y números}
Hasta el momento sólo hemos hablado de conjuntos (y no será diferente de aquí en adelante), pero debemos introducir un elemento clave del análisis: los números. He aquí tenemos dos opciones, una sería introducir otra serie de axiomas para formalizar el concepto de número, o que el número como tal sea una etiqueta para un cierto tipo de conjuntos.

Como la idea no es tener tantos axiomas (o no más de los que necesitamos) optaré por la segunda, comenzando desde el conjunto vacío. Se definirá inicialmente $0\equiv\emptyset$\footnote{Cabe decir que esta representación conjuntivista del ``0'' y otros números es únicamente temporal, y para hacerle hincapié a la formalidad, en la realidad dotamos de propiedades al 0 y a $\emptyset$ por separado.} y $n'\equiv n\cup\{n\}$ como puntos de partida tales que un conjunto infinito de números estén definidos por el método
\begin{align*}
0&\equiv\emptyset\\
1&\equiv 0'=\{0\}\\
2&\equiv 1'=\{0,1\}\\
&\vdots
\end{align*}
Un problema con nuestra teoría hasta el momento es que no nos permite introducir conjuntos como el natural por el axioma de especificación, por lo que, hemos de incorporar un último axioma a la lista.
\begin{axiom}[de Infinitud]
Existen conjuntos inductivos
$$\exists N:(0\in N\wedge\forall x,\;(x\in N\implies x'\in N)).$$
\end{axiom}
Se le llama axioma de infinitud porque es aquel que nos permite construir conjuntos infinitos. Su método es el uso de conjuntos inductivos, luego, un conjunto se define inductivo si contiene al cero (conjunto vacío) y posee a todos los sucesores de sus miembros, es decir
$$
\Ind N\iff(0\in N\wedge\forall x,\;(x\in N\implies x'\in N)).
$$

\begin{thm}
Existe un único conjunto inductivo tal que es subconjunto de todo conjunto inductivo.
\end{thm}
\begin{proof}
Asumamos un conjunto inductivo $X$ cualquiera, luego, si $N$ es el conjunto mencionado en el teorema, se define según el axioma de especificación e infinitud como
$$N\equiv\{x\in X:\forall Y\subseteq X,\;(\Ind Y\implies x\in Y)\}.$$
Tal que los elementos de $N$ están contenidos en todos los subconjuntos inductivos de $Y$.

Evidentemente $N$ es inductivo porque todo conjunto inductivo posee al cero y dado un elemento $x\in N$ se debe a que todo $x\in Y:(Y\subseteq X)$, como $Y$ es inductivo $x'\in Y$ y $x'\in N$.

Luego, supongamos un conjunto inductivo $Z$ cualquiera (contenido o no en $X$), nótese que su intersección con $X$ es subconjunto de $X$, es decir $Y=X\cap Z$, luego $N\subseteq X\cap Z\subseteq Z$.

Observe que $N$ es único porque de haber otro $N'$ con la misma propiedad se da que $N\subseteq N'$ (porque $N'$ es subconjunto inductivo de $X$) y que $N'\subseteq N$. De ahora en adelante definiremos dicho conjunto como
$$
\begin{aligned}
\N&\equiv\{x:\forall A,\;(\Ind A\implies x\in A)\}\\
&=N:(\Ind N\wedge(N\subseteq A\iff\Ind A))
\end{aligned}
$$
Nótese que $\N$ es ahora el conjunto inductivo más \textit{``pequeño''}.
\end{proof}

\begin{thm}[Axiomas de Peano]
El conjunto $\N$ satisface
\begin{enumerate}
\item $0\in\N$.
\item $\forall n,\;(n\in\N\implies n'\in\N)$.
\item $\neg\exists n\in\N:(n'=0)$.
\item $\forall nm\in\N,\;(n'=m'\iff n=m)$.
\item $\forall X\subseteq\N,\;((0\in X\wedge\forall x,\;(x\in X\implies x'\in X))\iff X=\N)$.
\end{enumerate}
\end{thm}
\begin{proof}
Los axiomas de Peano 1 y 2 son triviales. El axioma 3 se demuestra ya que si existiera dicho $n$ habría un subconjunto estricto de $\N$ que no lo poseería y que sería inductivo, luego como demostramos que $\N$ es subconjunto de todo conjunto inductivo esto sería contradictorio. El axioma 5 se demuestra similar al 3.
\end{proof}

El principio de inducción implica que dado un subconjunto $A$ de $\N$ que posea a todos los números que satisfagan la fórmula o propiedad $P(x)$:
$$A=\{x\in\N:P(x)\}$$
Tal que $0\in A$ y se suponga que $n\in A$ tal que con dicha hipótesis se demuestra que $n'\in A$ entonces $A=\N$, es decir, todo $x\in\N$ satisface $P(x)$.

\begin{mydef}[Función]
Es una aplicación $f:A\rightarrow B$ tal que $f\subseteq A\times B$. Aquí se le llama a $A$ el \textit{dominio} de $f$ y $B$ el \textit{contradominio} o \textit{codominio} de $f$. Para cada $a\in A$ existe un único $b\in B$ tal que $(a,b)\in f$, dicho $b$ adquiere la notación de ser $b=f(a)$. A $b$ se le llama la \textit{imagen} de $a$ en $f$ y a $a$ se le llama la \textit{antiimagen} o \textit{preimagen} de $b$ en $f$.
\end{mydef}

\begin{figure}
\centering
\begin{tikzpicture}
\draw (0,0) rectangle (3,3) node[above right]{$A\times B$};
\draw[gray!50,very thin,step=.5] (0,0) grid (3,3);
\draw[gray,very thin] (0,0) grid (3,3);
\foreach \x in {0,.5,...,3}
	\fill[niceblue] (\x,\x) circle (.05);
\draw[niceblue,thick] (0,0) -- (3,3) node[above]{$f$};
\end{tikzpicture}
\caption{Diagrama de una aplicación $f:A\rightarrow B$.}
\end{figure}

En la práctica cada función tendrá su forma de representarse, por ejemplo, la función $f$ puede representar que para todo $x$ le corresponde una imagen $f(x)$, pero dicha imagen puede denotarse como $f^1_0x$ (por dar un ejemplo cualquiera), en todo caso la notación de la imagen la indicaremos por medio de la simbología $x\mapsto f^1_0x$. Luego la función se define precisamente por la notación
\begin{align*}
f:\quad A&\longrightarrow B\\
x&\longmapsto f(x)
\end{align*}
Esto nos permite tener una forma mucho más clara y precisa de denotar la función en vez que a través de
$$f\equiv\{(x,y)\in A\times B:y=f(x)\}.$$

Nótese que la función también podría ser \textit{multivariable} y asignarle a una $n$-tupla ordenada $(x_1,x_2,\dots,x_n)$ una única imagen $f^n(x_1,x_2,\dots,x_n)=y$, donde $x_1\in A_1,\,x_2\in A_2,\,\dots,\,x_n\in A_n,\,y\in B$, entonces dicha función se denota por
\begin{align*}
f:\quad A_1\times A_2\times\cdots\times A_n&\longrightarrow B\\
(x_1,x_2,\dots,x_n)&\longmapsto f^n(x_1,x_2,\dots,x_n)
\end{align*}

Un ejemplo sencillo de función sería definir la función sucesor $s(x)$ tal que todo $x$ tenga una imagen $x'$. El dominio y contradominio es el conjunto de los naturales:
\begin{align*}
s:\quad \N&\longrightarrow\N\\
x&\longmapsto x'
\end{align*}

Otro ejemplo, aun más sencillo es la función identidad $\Id_A$ sobre $A$ tal que la imagen sea siempre igual a la antiimagen:
\begin{align*}
\Id_A:\quad A&\longrightarrow A\\
x&\longmapsto x
\end{align*}

Considere las aplicaciones $f:A\rightarrow B$ y $g:B\rightarrow C$, entonces se define una \textit{composición} como
\begin{align*}
f\circ g:\quad A&\longrightarrow C\\
x&\longmapsto g(f(x))
\end{align*}
Nótese que la composición es asociativa, es decir dadas tres aplicaciones $f:A\rightarrow B$, $g:B\rightarrow C$ y $h:C\rightarrow D$, se demuestra que:
$$(f\circ g)\circ h=h((f\circ g)(x))=h(g(f(x)))=(g\circ h)(f(x))=f\circ(g\circ h).$$
\begin{figure}
\centering
\begin{tikzpicture}[scale=2]
\node (A) at (0,0) {$A$};
\node (B) at (1,0) {$B$};
\node (C) at (1,-1) {$C$};
\node (D) at (2,-1) {$D$};
\begin{scope}[->]
\draw (A) -- node[above]{$f$} (B);
\draw (B) -- node[right]{$g$} (C);
\draw (C) -- node[below]{$h$} (D);
\draw (A) -- node[sloped,below]{$f\circ g$} (C);
\draw (B) -- node[sloped,above]{$g\circ h$} (D);
\draw (A) to[out=45,in=90] node[above right]{$f\circ(g\circ h)$} (D);
\draw (A) to[out=-90,in=-135] node[below left]{$(f\circ g)\circ h$} (D);
\end{scope}
\end{tikzpicture}
\end{figure}
Además, es evidente que $f=\Id_A\circ f=f\circ\Id_B$.

\begin{mydef}[Función inyectiva u otras]
Dada una aplicación $f:A\rightarrow B$ se dice que es:
\begin{description}
\item[{\it Inyectiva} o {\it biunívoca}] -- Cuando distintos conjuntos poseen distintas imágenes.
$$\text{$f$ Inyectivo}\iff(f(a)=f(b)\iff a=b).$$
\item[\it Suprayectiva] -- Cuando todo elemento del contradominio posee al menos una antiimagen.
$$\text{$f$ Suprayectivo}\iff\forall b\in B,\;(\exists a\in A:b=f(a)).$$
\item[\it Biyectiva] -- Cuando $f$ es inyectiva y suprayectiva. También si todo elemento del contradominio posee una única antiimagen.
$$\text{$f$ Biyectiva}\iff\forall b\in B,\;(\exists!a\in A:b=f(a)).$$
\end{description}
\end{mydef}

Nótese que dada una aplicación $f:A\rightarrow B$ biyectiva puedes definir una función la cual llamaremos el \textit{inverso} y denotaremos como $f^{-1}$:
\begin{align*}
f^{-1}:\quad B&\longrightarrow A\\
x&\longmapsto f^{-1}(x)
\end{align*}
El inverso es también una aplicación biyectiva y es fácil definirla mejor como
$$
f^{-1}=\{(x,y)\in B\times A:x=f(y)\}.
$$
\begin{figure}
\centering
\begin{tikzpicture}[scale=2]
\node (A) at (0,0) {$A$};
\node (B) at (1,0) {$B$};
\draw[->] (A.north east) -- node[above]{$f$} (B.north west);
\draw[->] (B.south west) -- node[below]{$f^{-1}$} (A.south east);
\end{tikzpicture}
\end{figure}

Nótese que dada la aplicación $f:A\rightarrow B$ biyectiva, la composición $f\circ f^{-1}=\Id_A$ y $f^{-1}\circ f=\Id_B$.
\begin{figure}
\centering
\begin{tikzpicture}[scale=2]
\node (A) at (0,0) {$A$};
\node (a) at (1,0) {$A$};
\node (B) at (0,-1) {$B$};
\node (b) at (1,-1) {$B$};
\begin{scope}[->]
\draw (A) -- node[above]{$\Id_A$} (a);
\draw (A) -- node[left]{$f$} (B);
\draw (a) -- node[right]{$f$} (b);
\draw (B) -- node[below]{$\Id_B$} (b);
\end{scope}
\end{tikzpicture}
\end{figure}

\begin{lem}
Para todo natural $n\in\N$ se cumple que $0\in n'$ y $m\in n$ sí y sólo si $m'\in n'$.
\end{lem}
\begin{proof}
Procederemos a demostrar el lema por inducción. Dado que $n=0$, entonces $0\in 0'$ por definición. Asimismo no existe $m$ tal que pertenezca a $n$.

Por hipótesis las propiedades se aplican para $n$ y se demuestra para $n'$. La primera propiedad es trivial, puesto que $n\subset n'$. Luego si $m\in n$ existen dos posibilidades, o $m\in s^{-1}(n)$ o $m=s^{-1}(n)$ (recuerde que $s$ es el sucesor). En el primer caso $m'\in n'$ porque, por definición $m'=m\cup\{m\}$, $n'=n\cup\{n\}=s^{-1}(n)\cup\{s^{-1}(n),n\}$ y $m\in s^{-1}(n)$. En el segundo caso, por definición, $m'=s(s^{-1}(n))=n$ y $n'=n\cup\{n\}$.
\end{proof}

\begin{thm}[Teorema de recursión]
Dada un conjunto no vacío $A$ tal que $a\in A$. Se define una \textbf{única} aplicación $f:\N\rightarrow A$ con $g:A\rightarrow A$ a través de definir que $f(0)=a$ y $f(n')=g(f(n))$.
\end{thm}
\begin{proof}
Podemos demostrar su existencia por inducción. Cabe recordar que $n\in n'$ de forma que definimos $f_n:n'\rightarrow A$.

Para $n=0$ se cumple que $f_0=\{(0,a)\}$.

Nótese que por construcción definimos $f_{n'}=f_n\cup\{(n',g(f_n(n)))\}$, si $m\in n$ se da que $f_{n'}(m)=f_n(m)$. A su vez, se demuestra que
$$f_{n'}(0)=a,\quad f_{n'}(m')=g(f_{n'}(m))=g(f_n(m)),$$
luego, para $m=n$, se demuestra similarmente que
$$f_{n'}(n')=g(f_{n'}(n))=g(f_n(n)).$$
También podemos demostrar que $f_n$ es único asumiendo otra aplicación $h:n'\rightarrow A$ tal que
$$h(0)=a,\quad h(n')=g(h(n)).$$
Para ello utilizaremos inducción sobre $n$. Para $h(0)=a=f_n(0)$. Por hipótesis $h(n)=f_n(n)$ y para $n'$ se cumple
$$h(n')=g(h(n))=g(f_n(n))=g(f_{n'}(n))=f_{n'}(n').$$
Finalmente se define la aplicación $f:\N\rightarrow A$ a través de que $f(n)=f_n(n)$.
\end{proof}

Observe que la forma más sencilla de aplicar el teorema de recursión sería a través de una función constante, tomando que $g=\Id_A$ se obtiene una función $f:\N\rightarrow A$ tal que $f(0)=a$ y $f(n')=f(n)$, es decir
$$f=\{(x,y)\in\N\times A:y=a\}.$$

\begin{mydef}[Adición]
Definamos un esquema de funciones $(n+):\N\rightarrow\N$ por el teorema de recursión tal que
$$
(n+)(0)=n,\quad (n+)(m')=((n+)(m))'
$$
En la practica escribiremos $n+m$ en vez de $(n+)(m)$, es decir que, $n+0=n$ y $n+m'=(n+m)'$.
\end{mydef}

Nótese que por definición del esquema de la adición se demuestra que:
$$n+1=n+0'=(n+0)'=n',$$
esto nos será útil para acostumbrarnos a la nueva notación.

\begin{mydef}[Multiplicación]
Se define un esquema de funciones $(n\cdot):\N\rightarrow\N$ por el teorema de recursión tal que
$$
(n\cdot)(0)=0,\quad (n\cdot)(m+1)=(n\cdot)(m)+n
$$
En la practica escribiremos $n\cdot m$ en vez de $(n\cdot)(m)$, es decir que, $n\cdot 0=0$ y $n\cdot(m+1)=n\cdot m+n$.
\end{mydef}
Otra forma de comprender la multiplicación (una más común) es como una suma periódica, es decir:
$$n\cdot m=\underbrace{n+\cdots+n}_m$$

\begin{thm}
$(\N,+)$ es un monoide conmutativo con la propiedad extra de que $a+c=b+c\iff a=b$ (cancelación).
\end{thm}
\begin{proof}
La propiedad asociativa se demuestra por inducción sobre $c$. Para $c=0$ se da
$$(a+b)+0=a+b=a+(b+0),$$
por hipótesis se asume que se aplica para $c$, luego se demuestra para $c+1$:
$$(a+b)+(c+1)=(a+b)+c+1=a+(b+c)+1=a+((b+c)+1)=a+(b+(c+1)).$$
La propiedad del elemento neutro se demuestra por inducción sobre $a$, evidentemente
$$0+0=0+0=0,$$
el caso $a$ es hipotético y el caso $a+1$ se demuestra por el método
$$\begin{aligned}
(a+1)+0&=a+1 &&\text{(Definición de +)}\\
&=(a+0)+1 &&\text{(Definición de +)}\\
&=(0+a)+1 &&\text{(Hipótesis)}\\
&=0+(a+1) &&\text{(Asociatividad)}
\end{aligned}$$
La propiedad conmutativa se demuestra por inducción sobre $b$, pero previo a ello demostraremos el caso $b=1$:

Por propiedad del elemento neutro se cumple que
$$1+0=0+1,$$
proseguimos a demostrar el caso $a+1$:
$$\begin{aligned}
1+(a+1)&=(1+a)+1 &&\text{(Asociatividad)}\\
&=(a+1)+1 &&\text{(Hipótesis)}
\end{aligned}$$
Ahora, el caso $b=0$ es trivial (elemento neutro), por tanto nos queda demostrar solo el caso $b+1$:
$$\begin{aligned}
a+(b+1)&=(a+b)+1 &&\text{(Asociatividad)}\\
&=(b+a)+1 &&\text{(Hipótesis)}\\
&=b+(a+1) &&\text{(Definición de +)}\\
&=b+(1+a)\\
&=(b+1)+a &&\text{(Asociatividad)}
\end{aligned}$$

La propiedad de cancelación se demuestra por inducción sobre $c$. Evidentemente es cierta para $c=0$ por definición de la suma
$$a+0=b+0\iff a=b,$$
el caso $c+1$ es más complicado, pero se demuestra con el siguiente racionamiento
$$\begin{aligned}
a+(c+1)=b+(c+1)&\iff (a+c)+1=(b+c)+1 &&\text{(Asociatividad)}\\
&\iff a+c=b+c &&\text{(4\textsuperscript{o} axioma de Peano)}\\
&\iff a=b &&\text{(Hipótesis)}
\end{aligned}$$
\end{proof}

\section{Relaciones}
\begin{mydef}[Relación binaria]
Una relación o relator es un conjunto $R\subseteq A^2$ tal que $(a,b)\in R\iff aRb$ donde $aRb$ es una proposición definida por el relator $R$.
\end{mydef}

En un principio las relaciones pueden sonar similares a las funciones, sin embargo, existen dos diferencias fundamentales: la primera es que un elemento $a$ posee una única imagen $b$, en cambio, pueden existir múltiples $b$ tales que $aRb$ sea cierto; la segunda es que dado que $(a,b)\in f$ es porque $b=f(a)$ mientras que $(a,b)\in R$ es porque $aRb$ es cierto.

Ejemplos de relaciones lo son $\subset$, $\in$ y $=$.

\begin{figure}
\centering
\begin{tikzpicture}[scale=.75]
\fill[niceblue,opacity=.5] (0,1) -- (5,6) -- (0,6) node[above,opacity=.75]{$\in_\N$} -- cycle;
\draw (0,0) grid (6,6) node[above right]{$\N^2$};
\foreach \x in {0,...,6}
{
\draw (\x,0) +(0,.1) -- ++(0,-.1) node[below]{$\x$};
\draw (0,\x) +(.1,0) -- ++(-.1,0) node[left]{$\x$};
}
\end{tikzpicture}
\caption{Pertenencia sobre $\N$}
\end{figure}

\begin{prop}[Operaciones entre relaciones]
Dado un conjunto de relaciones $\mathscr{R}$ tal que $R,S\in\mathscr{R}$, se cumple que:
\begin{enumerate}
\item $\bigcup\mathscr{R}$ es una relación.
\item $\bigcap\mathscr{R}$ es una relación.
\item $R-S$ es una relación.
\item $R\Delta S$ es una relación.
\item $\complement_{A^2}R$ es una relación.
\end{enumerate}
\end{prop}

Cabe destacar que definiremos también el inverso a una relación, denotado como $R^{-1}$ como
$$
R^{-1}=\{(y,x):(x,y)\in R\}.
$$
Observe que ${\supseteq}\equiv{\subseteq^{-1}}$.
\begin{prop}[Propiedades de la relación inversa]
Sea $R$ una relación cualquiera, se cumple:
\begin{enumerate}
\item $(R^{-1})^{-1}=R$ (doble inverso).
\item $\Dom(R^{-1})=\Img R$ e $\Img(R^{-1})=\Dom R$.
\item El inverso de toda operación entre dos relaciones es la operación sobre los inversos de las relaciones
\item $\Fld(R^{-1})=\Fld R$.
\item $R\subseteq S\iff R^{-1}\subseteq S^{-1}$.
\end{enumerate}
\end{prop}

\begin{lem}
Dada una relación cualquiera $R$ y un par ordenado $(x,y)\in R$ se cumple que $x,y\in \bigcup\bigcup R$.
\end{lem}
\begin{proof}
Nótese que como $(x,y)\in R$ se cumple $\{x\},\{x,y\}\in\bigcup R$ y por tanto $x,y\in\bigcup\bigcup R$.
\end{proof}
\begin{mydef}[Dominio, imagen y campo]
Dada una relación $R$ se definen los siguientes conceptos:
\begin{description}
\item[\it Dominio de R] -- Se denotará como $\Dom R$ y se define como el conjunto de todos los $x$ tales que $(x,y)\in R$:
$$\Dom R=\{x\in\bigcup\bigcup R:(x,y)\in R\}$$
\item[\it Imagen de R] -- Se denotará como $\Img R$ y se define como el conjunto de todos los $y$ tales que $(x,y)\in R$:
$$\Img R=\{y\in\bigcup\bigcup R:(x,y)\in R\}$$
\item[\it Campo de R] -- Se denotará como $\Fld R$ y se define como el conjunto de todos los $z$ tales que son dominio o imagen:
\begin{align*}
\Fld R&=\{z\in\bigcup\bigcup R:(z,y)\in R\vee(x,z)\in R\}\\
&=\Dom R\cup\Img R
\end{align*}
\end{description}
\end{mydef}
\begin{prop}[Definición de relación]\label{prop:relation}
Para que sea $R$ una relación syss\footnote{Abreviación para ``si y sólo si''.} $R\subseteq\Dom R\times\Img R$.
\end{prop}
\begin{proof}
Se nota que $R$ Relación $\implies R\subseteq\Dom R\times\Img R$, puesto que dado un elemento cualquiera $(x,y)\in R$, por definición $x\in\Dom R$ e $y\in\Img R$, por tanto es evidente que $(x,y)\in\Dom R\times\Img R$.

Luego $R\subseteq\Dom R\times\Img R\implies R$ Relación, puesto que $\Dom R\times\Img R$ sólo posee pares ordenados cuyos elementos pertenecen a $R$, por tanto, $R$ también posee sólo pares ordenados, por ejemplo, $(x,y)$. Finalmente, para que $R$ sea una relación debe cumplirse que sus $x$ e $y$ pertenezcan a un único conjunto, es decir, que debe haber un superconjunto de $\Dom R$ e $\Img R$ y $\Fld R$ satisface dicha necesidad.
\end{proof}
\begin{mydef}[Relación]
Decimos que $R$ es una relación \textit{``aplicada''} de $A$ a $B$ syss $\Dom R\subseteq A$ e $\Img R\subseteq B$. $R$ es una relación sobre $A$ si $\Dom R\subseteq A$ e $\Img R\subseteq A$.
\end{mydef}
\begin{cor}
Dados dos conjuntos $A$ y $B$ existe un conjunto de todas las relaciones de $A$ a $B$
\end{cor}
\begin{proof}
Dicho conjunto es $\P(A\times B)$ por definición y proposición~\ref{prop:relation}.
\end{proof}
\begin{mydef}[Aplicaciones]
Una aplicación cualquiera es una terna ordenada $(A,R,B)$ donde $R\subseteq A\times B$. Usualmente las aplicaciones se denotan como $R:A\rightarrow B$. A su vez definimos las endoaplicaciones como aquellas únicamente sobre $A$ (por tanto se denotan como $R:A\rightarrow A$ con $R\subseteq A^2$).

Una aplicación no determinista es una relación. Estas no poseen restricciones mas allá de lo que ya se menciona.

Una aplicación parcial es una función $F$ tal que contiene a los pares ordenados $(x,y)$ y $(x,z)$ si y solo sí $y=z$. Satisface que si es de $A$ a $B$ se cumple que $\Dom F\subseteq A$ e $\Img F\subseteq B$.

Una aplicación (común) es una función $f$ tal que es una aplicación parcial con la restricción de que si se escribe $f:A\rightarrow B$ es porque $\Dom F=A$ e $\Img F\subseteq B$.
\end{mydef}
Decimos que dada una aplicación $(A,f)$, donde $f$ es una función binaria o funtor diádico\footnote{Que depende de dos cantidades}, posee una \textit{ley de clausura} o \textit{ley de composición interna} cuando $\Fld f=A$, es decir, que $*:A^2\rightarrow A$.
\begin{mydef}[Propiedades de las relaciones]
Dado una relación $R\subseteq X\times X$ puede cumplir las siguientes propiedades:
\begin{description}
\item[\it Reflexividad] $\forall x\in X,\;(x,x)\in R$.
\item[\it Irreflexividad] $\forall x\in X,\;(x,x)\notin R$.
\item[\it Simetría] $xRy\iff yRx$.
\item[\it Antisimetría] $xRy\wedge yRx\iff x=y$.
\item[\it Asimetría] $xRy\iff y\not Rx$.
\item[\it Transitividad] $xRy\wedge yRz\iff xRz$.
\item[\it Comparabilidad] Se dice que un par desordenado es comparable bajo $R$ si y solo sí $\forall x,y\in X:(x\neq y),\;(xRy\vee yRx)$.
\end{description}
\end{mydef}
Observe que todas estas propiedades las hemos aplicado previamente en este libro, la mención de su definición formal es puramente recordatoria y aclaratoria para quienes no lo hayan deducido ya.
\begin{mydef}[Relación de orden]
Será $R$ una relación de orden (parcial) si es reflexiva, antisimétrica y transitiva. Una relación de orden total cumple, además de todas las propiedades anteriores, comparabilidad en $\Fld R$.
\end{mydef}
\begin{thm}
La relación $\leq$ (léase ``menor o igual que'') en $\N$ dada por
$$n\leq m\iff\exists! r\in\N:n+r=m,$$
donde $r$ se le llama \textit{diferencia entre n y m}, es una relación de orden total.
\end{thm}
\begin{proof}
La reflexividad es trivial.

La antisimetría se deduce debido a que, por hipótesis, se da que
$$n\leq m\wedge m\leq n\iff\exists r,s\in\N:n+r=m\wedge m+s=n$$
de lo cual, sustituyendo en cualesquiera de las ecuaciones se obtiene
$$(n+r)+s=n=n+0\underset{\text{(cancelación)}}{\iff} r+s=0$$
Luego, debemos demostrar que el único caso posible es $r=s=0$, para ello lo haremos por contradicción, si $s\neq 0$ (por ejemplo), entonces existe un $t$ tal que $s=t'$:
$$r+t'=(r+t)'=0$$
luego, (por definición de $\N$) no existe $u\in\N$ tal que $u'=0$, por tanto $s=0$ y por definición de +, $r=0$.

La transitividad es trivial.

La comparabilidad se demuestra por inducción sobre $n$. Evidentemente, para 0 se cumple
$$0\leq m\iff 0+m=m,$$
luego, para el caso $n$ (hipótesis) puede cumplirse $n\leq m$ o $m\leq n$, y por tanto, nos queda demostrar el caso $n+1$. El caso $m\leq n$ es trivial. Para la hipótesis que $n\leq m$ lo dividiremos en dos subcasos, uno en el que el $r=0$ y otro en que $r\neq 0$. El primero es sencillo, puesto que implica $n=m$, por tanto, por cancelación se demuestra $m\leq n+1$ con diferencia 1. En cambio, si $r\neq 0$ entonces es el sucesor de un tal $s'=1$, por tanto, sustituyendo se demuestra la propiedad a partir del método
$$\begin{aligned}
n\leq m&\iff \exists r=s'\in\N:n+r=m &&\text{(Hipótesis)}\\
&\iff n+(s+1)=m\\
&\iff n+(1+s)=m &&\text{(Conmutatividad)}\\
&\iff (n+1)+s=m
\end{aligned}$$
En todo caso se demuestra la uncidad de la diferencia por cancelación.
\end{proof}
Definimos la relación ${\geq}\equiv{\leq^{-1}}$ (léase ``mayor o igual que''). $\geq$ es una relación de orden.

Definimos la relación $\lt$ (léase ``menor que'') como aquella tal que $n\lt m\iff n\leq m\wedge n\neq m$ y la relación $\gt$ (léase ``mayor que'') como aquella tal que $n\gt m\iff n\geq m\wedge n\neq m$. Ambas cumplen irreflexividad, transitividad y \textbf{tricotomía}; esta última se refiere a que siempre se cumple una y solo una de las siguientes: $n\lt m$, $n=m$ o $n\gt m$.
\begin{mydef}
Dado un caso en que $n\leq m$ con diferencia $r$ la definiremos con la notación $r=m-n$.
\end{mydef}
De esto se deemuestra que el inverso de la función parcial sucesor $s$ es $x-1$.
\begin{mydef}[Mínimo y máximo]
Dada una endoaplicación no determinista de $\leq$ sobre $A$ (también descrita como un par ordenado $(A,\leq)$) y un subconjunto estricto del mismo $B\subset A$. Se admite que:
\begin{description}
\item[\it Máximo] $\exists\max B\iff\forall x\in B\exists!y\in B:(x\leq y\iff y=\max B)$.
\item[\it Mínimo] $\exists\min B\iff\forall x\in B\exists!y\in B:(y\leq x\iff y=\min B)$.
\end{description}
\end{mydef}
Nótese que la unicidad se demuestra por antisimetría.

\section{Conjuntos finitos e infinitos}
\begin{mydef}[Finitud]
Definimos el conjunto $I_n$ con $n\in\N$ como
$$I_n=\{m\in\N:m\lt n\},$$
de forma que un conjunto $A$ se considerará \textbf{finito} si existe un natural $n\in\N$ tal que $f:I_n\rightarrow A$ (o $g:A\rightarrow I_n$) es una aplicación biyectiva. De lo contrario se admite que $A$ es \textbf{infinito}.
\end{mydef}
Desarrollaremos a fondo la definición de conjunto finito definiendo la aplicación
\begin{align*}
a:I_n&\longrightarrow A\\
i&\longmapsto a_{i+1}
\end{align*}
Tal que, por ejemplo, un conjunto finito cualquiera $A$ puede expresarse como $A=\{a_1,a_2,\dots,a_n\}$.
\begin{thm}[Principio del buen orden]
Todo subconjunto no vacío de $\N$, posee mínimo elemento,
$$\forall A\subseteq\N,\;(A\neq\emptyset\iff\exists\min A).$$
\end{thm}
\begin{proof}
Introduzcamos la notación de que existe un conjunto $I_n\subseteq\N$ tal que $I_n=\{m\in\N:m\leq n\}$. Luego, diremos que para cada $A$ existe un $I_n\subseteq\N\setminus A$. Si $0\in A$ entonces $\min A=0$ puesto que todo $x\in\N\implies 0\leq x$. Si $0\notin A$ entonces $I_n\neq\emptyset$, sin embargo, $I_n\neq\N$, por tanto, no satisface el 5\textsuperscript{o} axioma de Peano, es decir, que existe un $m\in I_n$ tal que $m'\notin I_n$ y efectivamente, dicho número es $n$ (porque $n'\geq n$), luego si consideramos el $I_n$ mayor que satisfaga $I_n\subseteq\N\setminus A$ entonces $n'\in A$ y, $\min A=n'$.
\end{proof}
\begin{mydef}[Delimitación o acotación]
Dada una endoaplicación no determinista $(A,\leq)$, diremos que un subconjunto $B\subseteq A$ está delimitado o acotado si existe una cota superior $M\in A$ tal que $\forall b\in B,\;b\leq M$ (se considera el menor $M$ que lo satisfaga) y existe una cota inferior $m\in A$ tal que $\forall  b\in B,\;m\leq b$ (se considera el mayor $m$ que lo satisfaga). Nótese que no es una condición necesaria que $m\in B$ ni $M\in B$.
\end{mydef}
\begin{thm}
Sea $X\subseteq\N$ entonces las siguientes expresiones son equivalentes:
\begin{enumerate}[$a)$]
\item $X$ es finito.
\item $X$ está acotado.
\item $X$ posee mayor y menor.
\end{enumerate}
\end{thm}
\begin{proof}
Para que estas expresiones sean equivalentes debemos demostrar que $(a)\iff(b)\iff(c)$. Comenzaremos por demostrar $(a)\iff(b)$.

Como $X$ es finito lo denotaremos como $X=\{x_1,x_2,\dots,x_n\}$, luego definimos un natural $y=x_1+x_2+\cdots+x_n$ tal que $\forall x_i\in X,\;x_i\leq y$, por tanto, $X$ está acotado (aun que su cota superior no es necesariamente $y$).

El recíproco se demuestra porque, al estar acotado posee un máximo $M\in X$ por tanto, $X\subseteq I_{M+1}$, luego demostraremos la finitud por inducción sobre $M$. El caso 0 es trivial, puesto que entonces $X=\{0\}=I_0$. Por hipótesis de inducción existe un $I_n$ tal que $x:I_n\rightarrow X$ es biyectivo, luego en el caso inductivo demostramos que el conjunto $Y=X\cup\{M+1\}$ es finito, lo que logramos utilizando la misma función
$$f\cup\{(n,M+1)\}:I_{n+1}\rightarrow Y$$
que es biyectiva, por tanto, $X\cup\{M+1\}$ es finito.

Luego demostramos el caso $(b)\iff(c)$.

Por el principio del buen orden se demuestra la existencia del mínimo. La cota superior $M$, como dijimos, es única y la menor (en $\N$), luego existen dos casos, $M\in A$ o $M\notin A$. El primer caso es trivial. Para el segundo caso veremos que $M\neq 0$ (porque $A\neq\emptyset$), por tanto, $M=n'$, tal que $\forall a\in A,\;a\lt n'$, como $M$ es el menor, entonces $\forall a\in A,\;a\leq n$, pero entonces $n$ y $M$ son cotas superiores, lo que sería contradictorio a decir que $M$ era la menor, por lo tanto, $M\in A$ y $M=\max A$. El reciproco es trivial pues su máximo es su cota superior.
\end{proof}
\begin{thm}
Sean $n,m\in\N$, existe una aplicación biyectiva $f:I_m\rightarrow I_n$ syss $n=m$.
\end{thm}
\begin{proof}
Lo demostraremos por inducción sobre $n$. El caso $n=0$ es trivial. Luego, procedemos a demostrar el caso $n+1$. Evidentemente $m\neq 0$, por lo tanto, $m=r+1$.

Aquí existen dos casos, el primero tal que existe una aplicación $f$ tal que $f(r)=n$, entonces $f:I_r\rightarrow I_n$ es una aplicación biyectiva, $r=n$ y $m=n+1$.

El segundo caso es aquel que $f(r)\neq n$, entonces admitimos que existe
$$(f\setminus\{(u,n),(r,v)\}\cup\{(u,v),(r,n)\}):I_r\rightarrow I_n$$
tal que es una aplicación biyectiva.
\end{proof}
\begin{mydef}[Cardinalidad]
Definimos la cantidad $|A|$ como el cardinal de $A$ que otorga el natural $n\in\N$ como tal que existen funciones biyectivas $f:I_n\rightarrow A$. Si el conjunto es \textbf{infinito} (no existe un $n\in\N$ tal que sea su cardinal), se escribe que su cardinalidad es $\infty$ (aun que no se debe suponer que $\infty$ es un número ni que está contenido en $\N$).
\end{mydef}
Bajo esta definición, el cardinal del conjunto vacío es $|\emptyset|=0$, mientras que $|\N|=\infty$.
\begin{cor}
Dos conjuntos $A$ y $B$ poseen el mismo cardinal si existe una aplicación $f:A\rightarrow B$ biyectiva.
\end{cor}
\begin{thm}\label{thm:card-sum}
Sean $A$ y $B$ conjuntos finitos, entonces
$$|A|+|B|=|A\cup B|+|A\cap B|.$$
\end{thm}
\begin{proof}
Para el primer caso suponga que $A$ y $B$ son disjuntos, su cardinalidad es $|A|=n$ y $|B|=m$ tal que $a:I_n\rightarrow A$ y $b:I_m\rightarrow B$ son biyectivas, entonces existe $f:I_{n+m}\rightarrow A\cup B$ tal que es biyectiva, puesto que:
$$f(x)=\begin{cases}
a(x),& 0\leq x\lt n\\
b(x-n),& n\leq x\lt m
\end{cases}$$
Para el segundo caso $C=B\setminus(A\cap B)$ tal que $B=C\cup(A\cap B)$, por demostración anterior, $|B|=|C|+|A\cap B|$. Nótese que $A\cup B=A\cup C$, donde, por demostración anterior, $|A\cup B|=|A|+|C|$, sumando $|A\cap B|$ a ambos lados y queda demostrado.
\end{proof}
\begin{cor}
Sean $A$ y $B$ conjuntos, entonces:
\begin{enumerate}[i)]
\item $A\subseteq B\implies |A|\leq|B|$.
\item Existe $f:A\rightarrow B$ inyectiva syss $|A|\leq|B|$.
\end{enumerate}
\end{cor}
\begin{proof}
Veamos que ambas demostraciones son similares así que probaremos la primera solamente:

Si $A$ es subconjunto de $B$, entonces existe $C=B\setminus A$. Luego $|B|=|A|+|C|$, donde $|C|$ es un natural, por definición.
\end{proof}
\begin{thm}[Teorema de Cantor-Schröder-Bernstein]
Sean $A$ y $B$ dos conjuntos tales que existen las funciones $f:A\rightarrow B$ y $g:B\rightarrow A$ inyectivas. Existe $h:A\rightarrow B$ biyectiva.
\end{thm}
\begin{proof}
Definamos una función $F:\P(A)\rightarrow\P(A)$ tal que $F[\alpha]=A\setminus g\left[B\setminus f[\alpha]\right]$. Sea $\alpha\subset\beta\subseteq A$ veamos que
\begin{align*}
f[\alpha]\subset f[\beta]&\iff B\setminus f[\beta]\subset B\setminus f[\alpha]\\
&\iff g\left[B\setminus f[\beta]\right]\subset g\left[B\setminus f[\alpha]\right]\\
&\iff F[\alpha]\subset F[\beta].
\end{align*}
Supongamos que existe un $\xi$ tal que $\xi=F[\xi]$, entonces $A\setminus\xi=g\left[B\setminus f[\xi]\right]$. Finalmente consideramos la función simplificada $f|_\xi:\xi\rightarrow f[\xi]$ y $g|_{B\setminus f[\xi]}:B\setminus f[\xi]\rightarrow A\setminus\xi$, entonces $h=f|_\xi\cup g^{-1}|_{B\setminus f[\xi]}$ es biyectiva.
\end{proof}
\begin{thm}
Sean $A$ y $B$ conjuntos finitos, entonces
$$|A\times B|=|A|\,|B|.$$
\end{thm}
\begin{proof}
Como $A$ y $B$ son finitos existen $a:I_n\rightarrow A$ y $b:I_m\rightarrow B$ tal que son biyecciones, donde $n$ y $m$ son sus respectivas cardinalidades. Veamos que
$$A\times B=\bigcup_{k=0}^{n-1}\{a_k\}\times B$$
nótese, sin embargo, que $|\{a_i\}\times B|=|B|=m$, y como son conjuntos disjuntos (pues $a$ es inyectiva), vemos que
$$|A\times B|=\underbrace{m+\cdots+m}_{n\,\rm veces}=nm.$$
(Nota: tal vez esta demostración parezca \textit{informal} pues requiere de propiedades no aun demostradas, estas serán tratadas en el siguiente capítulo.)
\end{proof}
\begin{mydef}[Conjunto enumerable]
Se dice que $A$ será un conjunto enumerable si es finito o si existe una aplicación biyectiva $\N\rightarrow A$.
\end{mydef}
\begin{thm}
Todo conjunto infinito posee un subconjunto infinito enumerable.
\end{thm}
\begin{proof}
Sea $X$ un conjunto infinito. Si $X$ es numerable, entonces la demostración es instantánea. Si $X$ no es numerable entonces definiremos una aplicación $f:\N\rightarrow X$ tal que no es biyectiva, pero si inyectiva. Sea $x_A$ un elemento contenido en $A$, entonces $f(0)=x_X$, luego $A_n=X\setminus\bigcup_{i=0}^n\{f(i)\}$ y $f(n+1)=x_{A_n}$. Finalmente $\Img f$ es un subconjunto de $X$ y es enumerable.
\end{proof}
\begin{thm}
Todo subconjunto natural es enumerable.
\end{thm}
\begin{proof}
Supongamos que $A\subset\N$, es evidente que $A$ puede ser finito, pero supongamos que fuera infinito, entonces debemos demostrar que $|A|=|\N|$. Para ello debemos demostrar que existe una función $f:A\rightarrow\N$ que es biyectiva, en este caso la función es la siguiente
$$f(a)=|\{b:b\lt a\}|.$$
\end{proof}
De este teorema se concluye que los conjuntos ``infinitos más pequeños'' son enumerables (para más información ver sección~\ref{sec:big-cardinals}).

\section{Introducción a la aritmética}
\begin{mydef}[Relación y clase de equivalencia]
Se define una \textit{relación de equivalencia} como aquella que es \textbf{reflexiva}, \textbf{simétrica} y \textbf{transitiva}. Dada una relación de equivalencia $R$ definimos una \textit{clase de equivalencia} como
$$[a]=\{b\in\Fld R:aRb\}.$$
Dado un campo $A$ para una relación de equivalencia $R$, se define un \textit{conjunto cociente} $A/R$ como el conjunto de todas las clases de equivalencias de $A$, es decir,
$$A/R=\{[a]:a\in A\}.$$
\end{mydef}
Ahora, podemos definir una relación de equivalencia $R$ sobre $\N^2$ tal que
$$(a,b)R(c,d)\iff a+d=b+c,$$
nótese que si $a\geq b$ (y, por tanto, $c\geq d$) se puede escribir
$$(a,b)R(c,d)\iff a-b=c-d.$$
De esto, definimos un conjunto $\Z\equiv(\N\times\N)/R$\footnote{La Z viene de la palabra \textit{zahlen} que, en alemán, significa \textit{número}.}, denominado \textit{conjunto de los enteros}.

Definimos la suma y la multiplicación en $\Z$ por las fórmulas
$$[(a,b)]+[(c,d)]=[(a+c,b+d)],\quad [(a,b)][(c,d)]=[(ac+bd,ad+bc)]$$
\begin{mydef}[Estructuras algebraicas]
Podemos clasificar una aplicación binaria con ley de clausura,
\begin{align*}
*:\quad A^2&\longrightarrow A\\
(a,b)&\longmapsto ab
\end{align*}
como una de las siguientes estructuras algebraicas:
\begin{enumerate}
\item Un \textit{semigrupo} si para cada elemento se cumple que $(ab)c=a(bc)$ (asociatividad).
\item Un \textit{monoide} si es semigrupo y existe un elemento $e$ tal que $ae=ea=a$ (elemento neutro).
\item Un \textit{grupo} (común) si es monoide y para cada elemento existe un respectivo \textit{inverso} o \textit{simétrico} tal que $aa^{-1}=a^{-1}a=e$.
\item Un \textit{grupo abeliano} o \textit{conmutativo} si es un grupo y satisface que $ab=ba$ (conmutatividad).
\end{enumerate}
\end{mydef}
\begin{thm}
La aplicación $(\Z,+)$ es un grupo abeliano.
\end{thm}
\begin{proof}
Definamos los números en $\Z$ por las siguientes normas:
\begin{enumerate}[$a$)]
\item $[(n,0)]\equiv+n$, donde $n\in\Z$ es equivalente a $n\in\N$.
\item $[(0,n)]\equiv-n$, donde $-n$ es el inverso de $n$ bajo la suma.
\item Si $m\geq n$ entonces $[(m,n)]=[(m-n,0)]=+(m-n)$.
\item Si $m\leq n$ entonces $[(m,n)]=[(0,n-m)]=-(n-m)$.
\end{enumerate}
Entonces, la asociatividad, elemento neutro y conmutatividad se mantienen de $\N$ y, por definición, se demuestra la existencia de inverso.
\end{proof}
Para reducir notación, denotaremos $a$ en vez de $+a$.
\begin{mydef}[Anillo]
Es aquel que corresponde a una terna ordenada $(A,+,\cdot)$ tal que $A$ es un conjunto con leyes de clausura sobre $+$ y $\cdot$ tal que $(A,+)$ es un grupo abeliano, $(A,\cdot)$ es un semigrupo y se cumple que $a(b+c)=ab+ac$ y $(a+b)c=ac+bc$ (distributividad).

Se le llama \textit{anillo unitario} a aquel tal que $(A,\cdot)$ es un monoide. Se le llama \textit{anillo conmutativo} a aquel tal que $(A,\cdot)$ posee conmutatividad.

Si $(A,\cdot)$ es un grupo abeliano, se dice que $(A,+,\cdot)$ es un cuerpo.
\end{mydef}
\begin{thm}
La terna $(\Z,+,\cdot)$ es un anillo conmutativo.
\end{thm}
\begin{proof}
Ya se probó que $(\Z,+)$ es un grupo abeliano, por tanto procedemos a demostrar la distributividad y que $(\Z,\cdot)$ es un monoide conmutativo. Las demostraciones serán por inducción comenzando por la distributividad (por la izquierda).

Una especie de lema que hemos de probar es que $a\cdot 0=0\cdot a=0$ (elemento absorvente). El caso $a=0$ es trivial. Procedemos a demostrar el caso $a+1$:
$$\begin{aligned}
0\cdot(a+1)&=0\cdot a+0\cdot 1 &&\text{(definición)}\\
&=0+0 &&\text{(hipótesis y definición)}\\
&=0 &&\text{(definición)}\\
&=(a+1)\cdot 0 &&\text{(definición)}
\end{aligned}$$

La distrivutividad por la izquierda se demuestra por inducción en $c$. El caso $c=0$ se demuestra porque 0 es elemento neutro y absorvente:
$$a(b+0)=ab=ab+0=ab+a\cdot 0.$$
El caso $c+1$ se demuestra por el siguiente procedimiento:
$$\begin{aligned}
a(b+(c+1))&=a((b+c)+1) &&\text{(asociatividad)}\\
&=a(b+c)+a &&\text{(definición)}\\
&=ab+ac+a &&\text{(hipótesis)}\\
&=ab+a(c+1) &&\text{(definición)}
\end{aligned}$$
El caso $c=0$ de la distributividad por la derecha se demuestra por elemento neutro y definición:
$$(a+b)0=0=0+0=a\cdot 0+b\cdot 0,$$
el caso $c+1$ se demuestra por el siguiente procedimiento:
$$\begin{aligned}
(a+b)(c+1)&=(a+b)c+(a+b) &&\text{(definición)}\\
&=(ac+bc)+(a+b) &&\text{(hipótesis)}\\
&=ac+(bc+(a+b)) &&\text{(asociatividad)}\\
&=ac+((a+b)+bc) &&\text{(conmutatividad)}\\
&=(ac+(a+b))+bc &&\text{(asociatividad)}\\
&=((ac+a)+b)+bc &&\text{(asociatividad)}\\
&=(a(c+1)+b)+bc &&\text{(definición)}\\
&=a(c+1)+(b+bc) &&\text{(asociatividad)}\\
&=a(c+1)+(bc+b) &&\text{(conmutatividad)}\\
&=a(c+1)+b(c+1) &&\text{(definición)}
\end{aligned}$$
El caso $c=0$ de la asociatividad es trivial:
$$(ab)\cdot 0=0=a\cdot 0=a(b\cdot 0),$$
el caso $c+1$ se demuestra bajo el siguiente procedimiento:
$$\begin{aligned}
(ab)(c+1)&=(ab)c+ab &&\text{(definición)}\\
&=a(bc)+ab &&\text{(hipótesis)}\\
&=a(bc+b) &&\text{(distributividad)}\\
&=a(b(c+1)) &&\text{(definición)}
\end{aligned}$$
El elemento neutro de la multiplicación es el 1. El caso $a=0$ es trivial. El caso $a+1$ se demuestra por el procedimiento:
$$\begin{aligned}
(a+1)\cdot 1&=a+1 &&\text{(definición)}\\
&=a\cdot 1+1\cdot 1 &&\text{(definición)}\\
&=1\cdot a+1\cdot 1 &&\text{(hipótesis)}\\
&=1\cdot(a+1) &&\text{(distributividad)}
\end{aligned}$$
La conmutatividad se demuestra por inducción sobre $b$. El caso $b=0$ es trivial por ser elemento absorvente. El caso $b+1$ se demuestra por el siguiente procedimiento:
$$\begin{aligned}
a\cdot(b+1)&=ab+a\cdot 1 &&\text{(distributividad)}\\
&=ba+a\cdot 1 &&\text{(hipótesis)}\\
&=ba+1\cdot a &&\text{(elemento neutro)}\\
&=(b+1)\cdot a &&\text{(distrivutividad)}
\end{aligned}$$
\end{proof}
\begin{thm}
Sea $(A,*)$ un grupo, el elemento neutro $e$ es único al igual que el inverso relativo $(-a)$. 
\end{thm}
\begin{proof}
Supongamos que existe un segundo elemento neutro $e'$, entonces
$$e=ee'=e'e=e'.$$
Supongamos que existe un segundo inverso relativo $(-a)'$, entonces
$$(-a)=(-a)+0=(-a)+(a+(-a)')=((-a)+a)+(-a)'=0+(-a)'=(-a)'.$$
\end{proof}
Nótese que $(+a)(+b)=ab$, $(+a)(-b)=-ab$, $(-a)(+b)=-ab$ y $(+a)(+b)=ab$.
\begin{mydef}[Divisibilidad]
Definiremos la relación $(|,\Z)$ (léase ``es divisible por'') tal que
$$a\mid b\iff\exists q\in\Z:a=bq.$$
El valor $q$ le llamamos la \textit{razón} o el \textit{cociente} de $a$ entre $b$ y se define según la notación $q=a/b$. 
\end{mydef}

Admitamos la notación de que sea $A$ un conjunto, $A_0=A\setminus 0$. Entonces definimos una nueva relación (de equivalencia) $(R,\Z\times\Z_0)$ tal que
$$(a,b)R(c,d)\iff ad=bc$$
nótese que si $a\mid b$ (y $c\mid d$) podemos denotarlo como
$$(a,b)R(c,d)\iff\frac ab=\frac cd.$$
Con esto definimos el conjunto $\Q\equiv(\Z\times\Z_0)/R$\footnote{La Q es de la palabra alemán \textit{quotient} que significa \textit{cociente}. La notación de $\Z$ y $\Q$ fue introducida por primera vez por el grupo de matemáticos europeos N. Bourbaki en el primer capítulo de su libro \textit{Algébre}.}, al que llamamos \textit{conjunto de números racionales}.

En general, denotaremos
$$[(a,b)]=\frac{a}{b}.$$
La relación $\geq$ se cumple cuando:
$$\frac{a}{b}\geq\frac{c}{d}\iff ad\geq cb.$$
Las reglas para sumar y multiplicar en $\Q$ son:
$$\frac{a}{b}+\frac{c}{d}=\frac{ad+cb}{bd},\quad\frac{a}{b}\frac{c}{d}=\frac{ac}{bd}.$$
Quiero mencionar el porque de no incluir el $1/0$, pues si existiese dicho valor se podría demostrar la inconsistencia de que $0=1/0\cdot 0=1$ (por elem. neutro e inverso multiplicativo).
\begin{thm}
La terna $(\Q,+,\cdot)$ es un cuerpo.
\end{thm}
\begin{proof}
Definamos los números en $\Q$ bajo las condiciones:
\begin{enumerate}[$a$)]
\item $[(a,1)]=a$, donde $a\in\Q$ es equivalente con $a\in\Z$.
\item $[(1,a)]=a^{-1}$, donde $a^{-1}$ es el inverso o simétrico de $a$.
\item Si existe un $c$ tal que $a\mid c$ y $b\mid c$, entonces $[(a,b)]=[(a/c,b/c)]$.
\item Téngase $a\mid b$ entonces $[(a,b)]=[(a/b,1)]$ (caso particular de $c$).
\item Téngase $b\mid a$ entonces $[(a,b)]=[(1,b/a)]$ (caso particular de $c$).
\end{enumerate}
Por extensión se demuestra que $(\Q,+,\cdot)$ es un grupo conmutativo y el inverso en $\cdot$ se demuestra por definición.
\end{proof}
\begin{mydef}[Sumatoria y pitatoria]
Una sumatoria es una especie de suma periódica tal que, por recursión es:
$$\sum_{i=0}^0 f(i)=f(0),\quad \sum_{i=0}^{n+1} f(i)=f(n+1)+\sum_{i=0}^n f(i)$$
La pitatoria (o producto) es una especie de multiplicación periódica:
$$\prod_{i=0}^0 f(i)=f(0),\quad \prod_{i=0}^{n+1} f(i)=f(n+1)\cdot\prod_{i=0}^n f(i)$$
En las definiciones se debe entender $i$ como el \textit{índice (inferior)}, $n$ como el \textit{índice superior} y $f(i)$ como la fórmula. Se lee la expresión como \textit{la sumatoria (o pitatoria) desde $i$ hasta $n$ de $f(i)$}. El índice puede no ser cero, en dicho caso
$$\sum_{i=m}^n f(i)=\sum_{i=0}^{n-m} f(i+m),\quad\prod_{i=m}^n f(i)=\prod_{i=0}^{n-m} f(i+m)$$
\end{mydef}
Para reducir la notación escribiremos a futuro
$$\sum_{i=i_0}^n f(i)=f(i_0)+f(i_0+1)+\cdots+f(n).$$
Un caso particular de la pitatoria es el \textit{factorial}. Es una función que definiremos como
$$
n!=\prod_{i=1}^n i=n\cdot(n-1)\cdots 1
$$
\begin{thm}[Propiedades de la sumatoria]
Dado $m,r\leq n$ se cumple que:
\begin{enumerate}[$a$)]
\item $\sum_{i=1}^n c=nc$.
\item $\sum_{i=m}^n f(i)+g(i)=\sum_{i=m}^nf(i)+\sum_{i=m}^ng(i)$.
\item $\sum_{i=m}^n c\cdot f(i)=c\cdot\sum_{i=m}^n f(i)$.
\item $\sum_{i=m}^n f(i)=\sum_{i=r}^{n-m+r} f(i+m-r)$ (cambio de índice).
\item $\sum_{i=m}^n f(i)=f(m)+\sum_{i=m+1}^{n} f(i)$.
\end{enumerate}
\end{thm}
\begin{proof}
La $a$) y $e$) se demuestra por inducción sobre $n$. La $b$), $c$) y $d$) por propiedades de anillo.
\end{proof}
Definirimos la \textit{combinatoria} de $n$ con $m$ (si y solo sí $0\leq m\leq n$) como
$$
\binom{n}{m}=\frac{n!}{m!(n-m)!}
$$
\begin{thm}
Dados $m\leq n$ naturales se cumple que:
\begin{enumerate}[$a$)]
\item $\binom{n}{m}=\binom{n}{n-m}$.
\item $\binom{n}{0}=\binom{n}{n}=1,\quad\binom{n}{1}=n$.
\item $m\lt n\iff\binom{n}{m}+\binom{n}{m+1}=\binom{n+1}{m+1}$ (regla de Pascal).
\item Las combinatorias son naturales.
\end{enumerate}
\end{thm}
\begin{proof}
\begin{enumerate}[$a$)]
\setcounter{enumi}{2}
\item Siga el siguiente procedimiento:
\begin{align*}
\binom{n}{m}+\binom{n}{m+1}&=\frac{n!}{m!(n-m)!}+\frac{n!}{(m+1)!(n-m-1)}\\
&=\frac{n!}{m!(n-m)(n-m-1)!}+\frac{n!}{(m+1)m!(n-m-1)!}\\
&=\frac{n!(m+1)+n!(n-m)}{(m+1)!(n-m)!}\\
&=\frac{(n+1)!}{(m+1)!(n-m)!}=\binom{n+1}{m+1}.
\end{align*}
\end{enumerate}
\end{proof}
Una aplicación curiosa y hasta atractiva del teorema ya enseñado (en especial la regla de Pascal) es que con ella podemos comprender el fenómeno que hemos de describir. Para los primeros $n\in\N$ (desde el cero hasta el cinco, por ejemplo) ordene todas las posibles combinatorias de forma $\binom{n}{m}$, el resultado ha de verse así:
\begin{figure}
\centering
\begin{tabular}{>{$n=}l<{$}*{11}{c}}
0 &&&&&&1&&&&&\\
1 &&&&&1&&1&&&&\\
2 &&&&1&&2&&1&&&\\
3 &&&1&&3&&3&&1&&\\
4 &&1&&4&&6&&4&&1&\\
5 &1&&5&&10&&10&&5&&1
\end{tabular}
\caption{Triángulo de Pascal o Tartaglia.}
\end{figure}

Como la etiqueta indica, a esta famoso diagrama se le llama el triángulo de Pascal (en honor a su regla) y posee la peculiar característica que todo número es la suma de los dos números sobre sí. Otra forma es ordenar los números con $n$ horizontal y $m$ vertical:
\begin{figure}
\centering
\begin{tabular}{c|*{5}{c}}
 &0&1&2&3&4\\\hline
0 &1\\
1 &1&1\\
2 &1&2&1\\
3 &1&3&3&1\\
4 &1&4&6&4&1
\end{tabular}
\end{figure}

Definiremos las potencias $x^n$ (léase ``$x$ elevado a $n$'', donde a $x$ se le llama \textit{base} y a $n$ se le llama \textit{exponente}) por recursión:
$$x^0=1,\quad x^{n+1}=x^n\cdot x.$$
\begin{thm}[Propiedades del exponente]
Dados $n,m\in\N$ se cumple que
\begin{enumerate}[$a$)]
\item $a^{n}a^{m}=a^{n+m}$.
\item $(a^n)^m=a^{nm}$.
\item $(ab)^n=a^nb^n$.
\item $a^{-n}=\frac{1}{a^n}$.
\end{enumerate}
\end{thm}
\begin{proof}
Todas son demostrables por inducción.
\end{proof}
Utilizando la distributividad podemos observar un patrón curioso en las potencias de un binomio $a+b$:
\begin{align*}
(a+b)^0&=1\\
(a+b)^1&=1\cdot a+1\cdot b\\
(a+b)^2&=1\cdot a^2+2ab+1\cdot b^2\\
(a+b)^3&=1\cdot a^3+3a^2b+3ab^2+1\cdot b^3\\
&\vdots
\end{align*}
De esto se desarrolla el siguiente teorema:
\begin{thm}[Binomio de Newton]
Dado un exponente $n\in\N$ se cumple que
$$
(a+b)^n=\sum_{i=0}^n\binom{n}{i}a^{n-i}b^i.
$$
\end{thm}
\begin{proof}
Procederemos a demostrarlo por inducción sobre $n$. El caso $n=0$ es trivial. El caso $n+1$ se demuestra por el siguiente procedimiento: Comenzaremos por desarrollar un poco la ecuación utilizando la definición de potencia, hipótesis inductiva y propiedades de la sumatoria.
\begin{align*}
(a+b)^{n+1}&=(a+b)^n(a+b)\\
&=a\sum_{i=0}^n\binom{n}{i}a^{n-i}b^i+b\sum_{i=0}^n\binom{n}{i}a^{n-i}b^i\\
&=\sum_{i=0}^n\binom{n}{i}a^{n+1-i}b^i+\sum_{i=0}^n\binom{n}{i}a^{n-i}b^{i+1}
\end{align*}
Luego, por cambio de índice se cumple
$$\sum_{i=0}^n\binom{n}{i}a^{n-i}b^{i+1}=\sum_{i=1}^{n+1}\binom{n}{i-1}a^{n+1-i}b^i$$
Para poder unir ambas sumatorias hemos de ajustar índice inferior y superior en ambos, es decir
$$\sum_{i=0}^n\binom{n}{i}a^{n+1-i}b^i=a^{n+1}+\sum_{i=1}^n\binom{n}{i}a^{n+1-i}b^i$$
y
$$\sum_{i=1}^{n+1}\binom{n}{i-1}a^{n+1-i}b^i=b^{n+1}+\sum_{i=1}^n\binom{n}{i-1}a^{n+1-i}b^i.$$
Al tener ambos mismo indice inferior y superior podemos combinar ambas sumatorias y, utilizando la regla de Pascal, concluir que
$$\sum_{i=1}^n\binom{n}{i}a^{n+1-i}b^i+\sum_{i=1}^n\binom{n}{i-1}a^{n+1-i}b^i=\sum_{i=1}^n\binom{n+1}{i}a^{n+1-i}b^i$$
Finalmente, $a^{n+1}=\binom{n+1}{0}a^{n+1}b^0$ y $b^{n+1}=\binom{n+1}{n+1}a^0b^{n+1}$ de manera que queda demostrado que
$$(a+b)^{n+1}=\sum_{i=0}^{n+1}\binom{n+1}{i}a^{n+1-i}b^i,$$
como se quería probar.
\end{proof}
Finalmente, considero apropiado terminar con una definición de los números más apropiada. Primero, consideraremos un conjunto arbitrario de los primeros $d$ enteros a aquellos que llamaremos \textit{cifras}, digamos $I_d$. Luego, el siguiente número debería ser $d$, a aquel número le llamaremos la \textit{decena}, de forma que todo número será expresado como las cifras por potencias de la decena, es decir, sea $n\in\N$, se expresa
$$n=\sum_{i=0}^m c_id^i=c_md^m+\cdots+c_1d+c_0$$
Donde $c_i\in I_d$. En la práctica no denotaremos $d^i$ como tal sino que sea $n$ un número (natural) de $m$ cifras, entonces
$$n=c_mc_{m-1}\cdots c_0$$
Donde aquella notación \textbf{no} debe leerse como el producto sino como la forma de ordenar los números. Bajo tales definiciones, nótese que $d=1d+0=10$. En particular, nuestro convenio es utilizar las cifras $\{0,1,2,3,4,5,6,7,8,9\}$, pero también podríamos utilizar las cifras $\{0,1\}$, luego al tener ``2'' cifras, el ``2'' se denotaría como ``10''. Esto puede sonar confuso, pero no debe serlo, sólo es la forma de construir números (sin utilizar infinitos símbolos).

Los números fraccionarios son denotables en forma decimal cuando no son reductibles a un denominador unitario, en tal caso se escriben en forma
$$
n=\sum_{i=-m}^r c_id^i=\cdots+c_{-2}d^{-2}+c_{-1}d^{-1}+c_0+c_1d^1+c_2d^2+\cdots
$$
En la practica escribiremos sus cifras como
$$n=c_r\cdots c_1c_0,c_{-1}c_{-2}\cdots c_{-m}$$
Donde vuelvo a recalcar que no se debe entender como un producto sino como un orden de las cifras (un detalle es que usualmente en países hispanoparlantes se utiliza la coma para diferenciar la parte decimal, pero en los países angloparlantes se suele usar el punto).

\chapter{Los números reales (e hiperreales)}
Una de las ideas más antiguas de la matemática es poder ordenar los números en una recta, evidentemente en $\N$ y en $\Z$, aquella recta está llena de espacios vacíos, pero ¿y con $\Q$? Ahora, la recta parece continua, esto se debe a que dado un par de puntos $x,y\in\Q$ tal que $x\lt y$ siempre existe un punto intermedio $x\lt z=\frac{x+y}{2}\lt y$ tal que $z\in\Q$, por lo que, no \textbf{deberían} haber espacios vacíos.

Sin embargo, los hay, definamos primero
$$r^2=2$$
¿En qué lugar entra $r$ en $\Q$? La respuesta corta es que no, y este es uno de los números más sencillos con los que se demuestra que $\Q$ posee ``espacios vacíos''.
\begin{thm}
$\not\exists r\in\Q:r^2=2$.
\end{thm}
\begin{proof}
Utilicemos una demostración por reducción al absurdo. Supongamos que $r=a/b$ con $a$ y $b$ siendo coprimos\footnote{Esto significa que no existe un $c$ tal que $a\mid c$ y $b\mid c$ simultaneamente}. Entonces, elevando ambos lados por 2 obtenemos que
\begin{align*}
2&=\frac{a^2}{b^2}\\
a^2&=2b^2
\end{align*}
Luego, por la última expresión, podemos ver que $a^2$ es par (múltiplo de 2), nótese que esto sólo se da si $a$ es par, por tanto, $a=2c$ (con $c\in\N$):
\begin{align*}
4c^2&=2b^2\\
b^2&=2c^2
\end{align*}
Luego como $b^2$ es par, $b$ es par y por tanto $b=2d$. Como tanto $a$ y $b$ son pares, la expresión $a/b$ es reductible, lo que es una contradicción. Por tanto, $r\neq a/b$ y, por extensión, $r\notin\Q$.
\end{proof}
Más adelante veremos que $r$ existe, es un número real, pero no racional (alias \textit{irracional}). De ahora en adelante denotaremos este $r$ como $\sqrt{2}$.

\section{La Teoría Conjuntivista Interna (IST)}
El análisis matemático suele dividirse en dos tipos muy diferentes entre sí. El análisis \textit{estándar} y \textit{no estándar}. Para ponerlos en perspectiva, ambos tratan de lo mismo, ambos poseen los mismos elementos, pero la teoría no estándar hace diferencia entre los elementos estándar y los que no.

Este capítulo comprende la Teoría Conjuntivista Interna (IST) creada por Edward Nelson para formalizar y reenforzar la teoría del Análisis No Estándar (NSA) de Abraham Robinson. La teoría IST se nos presentará, igual que la ZFC, con sus respectivos axiomas, sin embargo, no debe comprenderse como un reinicio, sino más bien como un complemento. Para sintetizar, los contenidos previos no han de sentirse \textit{en vano}, sino que esta lección ha de sentirse como la extensión del capítulo anterior para poder reconocer a los elementos no estándar.

El primer concepto que hemos de introducir es la propiedad de ciertos conjuntos de ser \textit{estándar} (recordar que matemáticamente sólo existen conjuntos, los números son también conjuntos). Esta idea no será definida en primer lugar, sino que declararemos axiomas que indicaran el comportamiento de los conjuntos estándares y no estándares.

Por el momento, nos dignamos con entender que $\st x$ significa $x$ es estándar. A su vez definiremos las siguientes expresiones para notación futura
$$\existsst x:\phi(x)\iff\exists x:(\st x\wedge\phi(x)),\quad\forallst x,\phi(x)\iff\forall x:(\st x\implies\phi(x)).$$
A su vez, utilizaremos la siguiente notación para usar uno de nuestros axiomas:
$$\forallsf x,\phi(x)\iff\forallst x,(x\text{ finito}\implies\phi(x)).$$
Una de las razones para la cual estudiar NSA es que el resto de la matemática (comúnmente llamada \textit{matemática clásica} u \textit{discreta}) sigue siendo válida, los axiomas de IST serán como mejoras o ligeras modificaciones a ZFC, pero ambos conocimientos seguirán existiendo sin problema. Cabe destacar que se puede dar que un conjunto no estándar este contenido en otro estándar y que dicha propiedad satisface la ley de blanco y negro, es decir, un conjunto es o no estándar.
\begin{mydef}[Conceptos internos y externos]
Los axiomas ZFC son aplicables para conjuntos \textit{internos}. Una noción o concepto será llamada \textit{interna} si no tiene distinción entre conjuntos estándares y no estándares. De lo contrario es \textit{externo}.
\end{mydef}
Por ejemplo, la propiedad $x\gt y$ es interna, puesto que $x$ e $y$ pueden ser estándares o no. Mientras que la propiedad $\st x$ es externa.
\begin{axiom}[de Idealización (I)]
Dada una relación binaria interna $R$, las siguientes afirmaciones son equivalentes:
\begin{enumerate}[i)]
\item Para todo $F$ estándar y finito existe un $x$ que satisface $R(x,y)$ para todo $y\in F$ estándar.
\item Existe un $x$ que satisface $R(x,y)$ para todo $y$ estándar.
\end{enumerate}
$$\forallsf F\exists x\forallst y\in F\;R(x,y)\iff\exists x\forallst y \;R(x,y)$$
\end{axiom}
\begin{axiom}[de Estandarización (S)]
Todo conjunto estándar $x$ posee un subconjunto estándar $y$ tal que los elementos estándar de $y$ satisfacen la relación (externa si se quiere) $R(z)$.
$$\forallst x\existsst y\forallst z:(z\in x\iff(z\in y\wedge R(z)))$$
\end{axiom}
Considere que el axioma de estandarización es realmente una reinvención del axioma de especificación, si reemplazamos el último por (S) no habrían cambios a nuestra teoría, pero nos retienen de utilizar relaciones externas para construir conjuntos.
\begin{axiom}[de Transferencia (T)]
Sea $R(x_1,\dots,x_n)$ una propiedad interna, entonces:
\begin{enumerate}[i)]
\item Si todos los conjuntos estándares cumplen $R(x_1,\dots,x_n)$ entonces todos los conjuntos cumplen $R(x)$.
$$\forallst x_1\cdots\forallst x_n,\;R(x_1,\dots,x_n)\implies\forall x_1\cdots\forall x_n,\;R(x_1,\dots,x_n)$$
\item Si existen conjuntos que cumplen $R(x_1,\dots,x_n)$ existen conjuntos estándares que cumplen $R(x_1,\dots,x_n)$.
$$\exists x_1\cdots\exists x_n,\;R(x_1,\dots,x_n)\implies\existsst x_1\cdots\existsst x_n,\;R(x_1,\dots,x_n)$$
\end{enumerate}
\end{axiom}
De este modo, los tres axiomas de la teoría IST deletrean su nombre.

El primer problema que nos presenta la teoría IST es que no nos indica de antemano un conjunto (cualquiera) de números que sea estándar, por el momento parece imposible, pero en realidad no lo es. Nótese que el axioma del conjunto vacío define a dicho conjunto en base a una relación interna ($\in$), por tanto, $\emptyset$ es un conjunto interno, y por consecuente la relación $R(x)\iff x=\emptyset$ es interna, luego, por (T) $\emptyset$ es un conjunto estándar.

Es más, $\N$ también es un conjunto interno, por consecuente la relación $R(x)\iff x=\N$ es interna y por (T), nuevamente, se demuestra que $\N$ es estándar. Nótese que la propiedad $R(x)\iff x=\{\emptyset\}$ es interna y por tanto, el 1 es estándar. En general, dado un par de números estándares $x$ e $y$, la propiedad $R(z)\iff z=x\cup y$ es interna y por tanto $x\cup y$ es estándar, su intersección es estándar, su diferencia es estándar, su producto cruz es estándar, etc.

Para que el lector comprenda esto trataré de explicarlo más claramente, una propiedad interna se caracteriza por no basarse en la noción de ser estándar, cuando definimos al conjunto vacío en ningún momento se nos ocurrió decir si era o no estándar, sino que lo definimos independiente a esta idea, es por ello que la propiedad es interna y, por tanto, todos los números definidos en base a otros estándares lo son; sin embargo, si llamamos a una propiedad sea, por ejemplo $n\in\N$ y $\st n$ sería externa, porque aquí si hacemos mención a dicha idea y, por tanto, no podemos utilizar el principio (T).

Retomando el tema, hemos demostrado, a partir del principio (T) que todos los números conocidos o, mejor dicho, \textit{apreciables} son estándares, por tanto, ¿cómo convencernos de que existen los no estándares en primer lugar?
\begin{thm}
Existen números no estándar
\end{thm}
\begin{proof}
Consideremos la relación binaria interna $x\neq y$, nótese que por el teorema de Cantor sabemos que no existen conjuntos que contengan a todos los elementos, por tanto, para todo $F$ existe $x$ tal que todos los $y\in F$ satisfacen $x\neq y$, luego por principio (I), sabemos que existen $x$ tal que no son iguales a ningún conjunto estándar, es decir, existen $x$ no estándar.
\end{proof}
\begin{mydef}[Límites y apreciabilidad]
Por el momento se nos hace conveniente definir que es un número limitado y que es uno apreciable. En pocas palabras, un número limitado positivo es aquel que satisface $x\gt 0$, pero existe un $n\in\N$ (estándar) tal que $x\leq n$. Un número apreciable positivo es aquel que satisface $x\gt 0$, pero existe un $n\in\N$ (estándar) tal que $\frac 1n\leq x$.

En caso contrario se dirá que $x$ es ilimitado e infinitesimal respectivamente.
\end{mydef}
\begin{thm}
Los naturales no estándares son ilimitados.
\end{thm}
\begin{proof}
Consideremos la relación binaria $R(x,y)\iff x,y\in\N\wedge x\gt y$, nótese que si $F$ es subconjunto finito de $\N$ entonces está acotado y por tanto $F$ posee un máximo $M$, es decir, que existe un tal $M+1\in\N$ (por axioma de Peano) tal que para todos $y\in F$ satisface $M+1\gt y$; luego por principio (I):
\begin{align*}
&\forallsf F,\;\exists M+1\forallst y\in F\;(M+1,y\in\N\wedge M+1\gt y)\\
&\iff\exists x\forallst y\;(x,y\in\N\wedge x\gt y)
\end{align*}
Es decir, como aquella propiedad se cumple para todo subconjunto finito de $\N$, podemos concluir que existen números naturales (aquellos no estándares) que son mayores que todos los naturales estándares.
\end{proof}
Ahora, téngase en claro que hemos escogido meticulosamente las palabras con las cuales explicar esto, la mayoría de textos (e inclusive yo) mencionan esta propiedad como que los naturales no estándar son \textit{infinitos}, prefiero el término \textit{ilimitado}, por que infinito hace alusión a que no existe otro $n\in\N$ tal que $n\gt x$ y bajo esa definición (que es además interna) todos los naturales son finitos, inclusive los no estándares.

Ejemplifiquemos esto, supongamos que $\omega$ es un natural no estándar cualquiera, evidentemente es finito puesto que existe $\omega+1\gt\omega$. De hecho pueden pensar que los no estándares son toda una nueva sección \textit{desconocida} (en el sentido de que no la estudiamos a fondo) de los naturales, pero al contrario de otros textos yo no lo considero una \textit{extensión}, de hecho, es ilógico decir que $\N$ es el conjunto de los naturales estándares y $*\N$ su extensión con los no estándares (ya veremos por qué).
\begin{thm}\label{thm:std-equal}
Sean $A$ y $B$ conjuntos cualquiera se cumple que:
\begin{enumerate}[$a$)]
\item $A\subseteq B$ si todos los elementos estándares de $A$ están en $B$.
\item $A=B$ si todos los elementos estándares de $A$ lo están también en $B$ y viceversa.
\end{enumerate}
\end{thm}
\begin{proof}
El apartado $a$) se demuestra por el principio de transferencia, es decir
$$\forallst AB(\forallst x\in A,\;x\in B\implies\forall x\in A,\;x\in B)$$
Siendo demostrado el apartado $a$), por $A\subseteq B\wedge B\subseteq A\iff A=B$ se demuestra el apartado $b$).
\end{proof}
\begin{thm}
Las siguientes expresiones son equivalentes:
\begin{enumerate}[i)]
\item Todos los elementos de $E$ son estándar.
\item $E$ es estándar y finito.
\end{enumerate}
\end{thm}
\begin{proof}
Supongamos que $E$ contiene un elemento no estándar, entonces $x\neq y$ a todo $y$ estándar, por principio (T) decimos que para todo conjunto estándar y finito $F$ existe un $x\in E$ tal que es diferente a todo elemento estándar de $F$, por tanto, para todo conjunto estándar y finito $F$ se cumple $E\not\subseteq F$.
\begin{align*}
\exists x\in E:\neg\st x &\iff\exists x\in E\forallst y,\;x\neq y\\
&\iff\forallsf F\exists x\in E\forallst y\in F,\;x\neq y\\
&\iff\forallsf F,\;E\not\subseteq F
\end{align*}
Por negación lógica obtenemos que todo elemento de $E$ es estándar syss existe un conjunto estándar y finito que es superconjunto de $E$
$$\forall x\in E,\;\st x\iff\existsst F,\;E\subseteq F$$
Luego, se puede dar que $E=F$ o que $E\subset F$, en segundo caso, como $F$ es finito, $E$ es finito y cómo $F$ es estándar, $E$ también, es decir, ya se ha demostrado.
\end{proof}
\begin{mydef}[Parte estándar]
Sea $E$ un conjunto, definiremos la parte estándar $^SE$ como
$$^SE=\{x\in E:\st x\}.$$
\end{mydef}
\begin{thm}
Sea $E$ un conjunto no estándar o infinito, $^SE$ no existe.
\end{thm}
\begin{proof}
Ya sabemos por el teorema anterior que si $E$ es estándar y finito todos sus elementos son estándar, por tanto sus elementos son todos estándar, por tanto, para que $E$ posea elementos no estándar debe ser no estándar o infinito y sabemos que dichos elementos no son nulos (por coimplicancia). Luego, si $^SE$ existe, $E\setminus{^SE}$ existe y contiene a todos los elementos no estándares de $E$, por teorema~\ref{thm:std-equal}, $E\setminus{^SE}=\emptyset$ lo que sugiere que $E$ no posee elementos no estándares lo que es una contradicción.
\end{proof}
Entonces, ¿por qué definir un concepto que esencialmente no existe? Primero, porque es útil para la notación escribir $x\in {^SE}$ en lugar de $x\in E\wedge\st x$ y segundo, porque si bien no existe internamente es completamente válido externamente. Nótese que podemos culpar su ``falta de existencia'' debido a que está definido por una relación externa y ningún axioma nos permite dicha cuestión (si siquiera el S, puesto que si construyes un subconjunto de $E$ con la propiedad $x=x$, tendrá todos los elementos estándares y no estándares de $E$), pero en esencia es como decir que el conjunto sólo existe externamente.
\begin{figure}
$$\text{Conjuntos}
\begin{cases}
\text{Internos} \begin{cases}
\text{Estándar}\\
\text{No estándar}
\end{cases}\\
\text{Externos (no existen)}
\end{cases}$$
\caption{Tipos de conjuntos.}
\end{figure}
\begin{thm}
Sean $n,m\in\N$ se cumple que:
\begin{enumerate}[$a$)]
\item Si $m$ es limitado y $n\leq m$, entonces $n$ es limitado.
\item Si $n$ es ilimitado y $n\leq m$, entonces $m$ es ilimitado.
\item Si $n$ es limitado y $m$ ilimitado, entonces $n\lt m$.
\end{enumerate}
\end{thm}
\begin{proof}
\begin{enumerate}[$a$)]
\item Si $m$ es limitado es porque $m$ es estándar, luego existe un $n\in{^S\N}$ que cumple $n\leq m$, por tanto, $n$ es limitado.
\item Si $n$ es ilimitado es porque $\forallst x\in\N,\;x\lt n$, luego, $x\lt m$ y $m$ es ilimitado.
\item Si $n$ es limitado es porque existen $x\in{^S\N}$ tal que $n\leq x$, por definición de ser ilimitado se cumple $n\leq x\lt m$.
\end{enumerate}
\end{proof}
\begin{thm}\label{thm:std-sum-prod}
La suma de dos naturales es limitada syss los sumandos son limitados. La multiplicación es limitada y no nula syss sus factores son limitados y no nulos.
\end{thm}
\begin{proof}
La suma se demuestra porque si $n$ y $m$ son dos naturales limitados, son estándares, por tanto su suma es estándar y, por tanto, limitada. La multiplicación puede ser explicada por lo anterior, para ello, se da cuenta de que $nm=\underbrace{n+\cdots+n}_m$, si alguno de los factores es ilimitado, utilizando conmutatividad se llega a una suma periódica de sumandos ilimitados, lo que por lo anterior es ilimitado.
\end{proof}

\section{Cuerpos métricos}
\begin{mydef}[Anillo (o cuerpo) (totalmente) ordenado]
Se dice que la cuádrupla $(A,+,\cdot,\geq)$ es un anillo (o cuerpo) (totalmente) ordenado si $(A,+,\cdot)$ es un anillo o un cuerpo y si $\geq$ es una relación de orden (total) en $A$, que, además cumple:
\begin{enumerate}[$a$)]
\item $a\geq b\iff a+c\geq b+c$ (compatibilidad con la suma).
\item $a\geq b\wedge c\geq 0\iff ac\geq bc$ (compatibilidad con el producto).
\end{enumerate}
\end{mydef}
\begin{thm}
Sea $R$ un anillo totalmente ordenado, se cumple que:
\begin{enumerate}[$a$)]
\item $a\geq b\iff -a\leq -b$.
\item $a\geq b\iff a^{-1}\leq b^{-1}$.
\end{enumerate}
\end{thm}
\begin{proof}
Sabemos, por compatibilidad con el producto que si $ac\geq bc$ entonces $a\geq b\wedge c\geq 0$, negando ambos lados (por equivalencia) tenemos que $ac\lt bc\iff a\lt b\vee c\lt 0$, sabemos que $a\lt b$ es falso, por tanto, $c$ ha de ser menor que cero, además sabemos que $ac=bc\iff a=b\vee c=0$, finalmente consideramos el caso particular que $c=-1$ y queda demostrado \textit{a}).

Para el caso $b$) hay que considerar el signo de $a$ y $b$. Si $b$ es negativo, la propiedad es trivial. Si $a$ es negativo, $b$ ha de ser negativo, se cambia el orden para volver a ambos positivos. Si ambos son positivos utilizando la compatibilidad con el producto utilizas $c=(ab)^{-1}$.
\end{proof}
\begin{mydef}[Anillo ordenado arquimediano]
Sea la cuádrupla $(A,+,\cdot,\geq)$ un anillo (o cuerpo) (totalmente) ordenado \textit{arquimediano} si y solo sí cumple que $\forall x\in A,\exists n\in\N:x\lt n$ (propiedad arquimediana).
\end{mydef}
Evidentemente, $\Q$ es un cuerpo totalmente ordenado arquimediano, puesto que $n/m\lt n+1$.

Sea $(R,+,\cdot,\geq)$ un cuerpo totalmente ordenado arquimediano, se definen los intervalos en $R$ como
$$\begin{array}{r@{\;=\;}lr@{\;=\;}l}
[a,b] &\{x\in R:a\leq x\leq b\}, &[a,+\infty) &\{x\in R:a\leq x\},\\[0cm]
[a,b) &\{x\in R:a\leq x\lt b\}, &(a,+\infty) &\{x\in R:a\lt x\},\\
(a,b] &\{x\in R:a\lt x\leq b\}, &(-\infty,b] &\{x\in R:x\leq b\},\\
(a,b) &\{x\in R:a\lt x\lt b\}, &(-\infty,b) &\{x\in R:x\lt b\},
\end{array}$$
además se cuenta el intervalo $(-\infty,+\infty)=R$. Diremos que todo intervalo con cotas $a$ y $b$ (es decir que sea escrito como $[a,b],(a,b),\dots$) posee un centro $O=\frac{a+b}{2}$ y un radio $R=\frac{b-a}{2}$ tal que sus cotas son $O-R$ y $O+R$.
\begin{thm}
Sea $R$ un anillo ordenado arquimidiano, entonces para todo $x\in R$ existe un $n\in\Z$ tal que $n\leq x\lt n+1$.
\end{thm}
\begin{proof}
Sea $x\geq 0$ entonces, por propiedad arquimidiana existe un $k\in\Z$ tal que $x\lt k$, al menos uno satisface $k-1\leq x\lt k$ (sustituya $n=k-1$). Si $x\lt 0$, $-x\gt 0$ por tanto existe $k-1\lt -x\leq k$, multiplicando por $-1$ se obtiene $-k\leq x\lt -k+1$ (sustituya $n=-k$).
\end{proof}
\begin{mydef}[Parte entera y fraccionaria]
Sea $R$ un anillo ordenado arquimediano, se define la \textit{parte entera} o \textit{función suelo} $\lfloor\,\rfloor:R\rightarrow\Z$ como aquella que le asigna a todo $x\in R$ el número entero tal que $\lfloor x\rfloor\leq x\lt\lfloor x\rfloor+1$. A su vez se define su parte fraccionaria $\langle\,\rangle:R\rightarrow [0,1)$ tal que $\lfloor x\rfloor+\langle x\rangle=x$.

Las funciones de parte entera son tres en realidad:
\begin{enumerate}
\item La función suelo ya definida.
\item La función techo que es aquella tal que le otorga a un $x$ el número entero que satisface $\lceil x\rceil-1\lt x\leq\lceil x\rceil$.
\item La función redondeo que es aquella tal que:
$$[x]=\begin{cases}
\lfloor x\rfloor, &\langle x\rangle\in [0,1/2)\\
\lceil x\rceil, &\langle x\rangle\in [1/2,1)
\end{cases}$$
\end{enumerate}
\end{mydef}
\begin{mydef}[Función valor absoluto]
	Sea $R$ un anillo ordenado arquimediano, se define el \textit{valor absoluto} $|\,|:R\rightarrow R^+\cup\{0\}$ de sus elementos como aquella función que los convierte en elementos positivos, usualmente se asocia esta función como la distancia entre el origen y el número:
	$$|x|=\begin{cases}
		\phantom{-}x,&x\geq 0\\
		-x,&x\lt 0
	\end{cases}$$
\end{mydef}
\begin{thm}
	Sea $R$ un anillo ordenado arquimediano y $x,a\in R$, son equivalentes:
	\begin{enumerate}[\textit{a})]
		\item $-a\leq x\leq a$.
		\item $x\leq a\wedge -x\leq a$.
		\item $|x|\leq a$.
	\end{enumerate}
\end{thm}
\begin{proof}
	Por definición sabemos que $-a\leq x\leq a\iff -a\leq x\wedge x\leq a$, a su vez, por definición de anillo ordenado $-a\leq x\iff a\geq -x\iff -x\leq a$. Por \textit{c}), si $x\geq 0$ entonces $x\leq a$, luego si $x\lt 0$ entonces $-x\leq a$.
\end{proof}
\begin{thm}
	Sea $R$ un anillo ordenado arquimediano y $x,y\in R$, se cumple:
	\begin{enumerate}[$a$)]
		\item $|x+y|\leq|x|+|y|$.
		\item $|xy|=|x||y|$.
		\item $|x|-|y|\leq||x|-|y||\leq|x-y|$.
		\item $|x-z|\leq|x-y|+|y-z|$.
	\end{enumerate}
\end{thm}
\begin{proof}
	Para las siguientes demostraciones utilizaremos $u=|x|$, $v=|y|$ y $w=|z|$.
	\begin{enumerate}[$a$)]
		\item Nótese que al tener 2 variables hemos de tener 4 posibles casos, dos descritos por $\pm(u+v)$ y los otros dos por $\pm(u-v)$. Para el primero es evidente que $|\pm(u+v)|=|\pm u|+|\pm v|=u+v$, el segundo se nota que $|x+y|=|\pm(u-v)|=u-v\lt u+v=|\pm u|+|\pm v|$.
		\item Aquí es aún más simple, porque si el signo de $x$ es igual al signo de $y$ es evidente que $|uv|=|\pm u||\pm v|=uv$. Si son diferentes también es sencillo ver que $|-uv|=|\pm u||\mp v|=uv$.
		\item Observe que tengan el signo que quieran $|x|-|y|=u-v$. Si $x\geq y$ entonces $||x|-|y||=|x|-|y|$, si $x\lt y$ entonces $|x|-|y|\lt||x|-|y||$. Si $x$ e $y$ tienen mismo signo entonces $|\pm(u-v)|=|u-v|=||x|-|y||$, si difieren en signo, entonces $|\pm(u+v)|=u+v\gt||x|-|y||$.
		\item Esta es consecuencia inmediata de la \textit{a}), sustituya $x'=x-y$ e $y'=y-z$.
	\end{enumerate}
\end{proof}
Como ejercicio se recomienda demostrar las siguientes propiedades curiosas:
\begin{align*}
	\max\{x,y\}&=\frac{x+y+|y-x|}{2},\\
	\min\{x,y\}&=\frac{x+y-|y-x|}{2}
\end{align*}
\begin{mydef}[Distancia]
	Sea $M$ un conjunto de números, se define la distancia como una aplicación $d:M\times M\rightarrow R$ tal que satisface los siguientes axiomas:
	\begin{enumerate}[(1)]
		\item $d(x,y)\geq 0$.
		\item $d(x,y)=0\iff x=y$.
		\item $d(x,y)=d(y,x)$ (conmutatividad).
		\item $d(x,z)\leq d(x,y)+d(y,z)$ (desigualdad triangular).
	\end{enumerate}
	Un espacio métrico es una dupla $(M,d)$ donde $M$ es el conjunto y $d$ una distancia en $M$. También se le suele decir a $M$ el espacio métrico por si solo.
\end{mydef}
No es difícil demostrar que $(\Q,d)$ con $d(x,y)=|x-y|$ es un espacio métrico.

De aquí en adelante nos enfocaremos en los números no estándar en esta sección.
\begin{mydef}
	Sean $x,y\in R$, se le denominará:
	\begin{itemize}
		\item $x$ es ilimitado syss $\forallst s,\;|x|\gt s$.
		\item $x$ es infinitesimal syss $\forallst s,\;|x|\lt\frac 1s$.
		\item $x\simeq y$ ($x$ es \textit{infinitamente cercano} a $y$) syss $x-y$ es infinitesimal.
		\item $x\gg y$ ($x$ es \textit{considerablemente mayor que} $y$) syss $x\gt y$ y $x\not\simeq y$.
		\item $x\ll y$ ($x$ es \textit{considerablemente menor que} $y$) syss $y\gg x$.
		\item $|x|\simeq\infty$ syss $x$ es ilimitado.
	\end{itemize}
\end{mydef}
\begin{thm}\label{thm:infinitesimals}
Existen los infinitesimales y el único estándar es el cero.
\end{thm}
\begin{proof}
Por el principio (I) demostraremos la existencia de infinitesimales no estándar bajo la relación $x,y\neq 0\wedge|x|\lt|y|$. Para cada conjunto finito $F$ aplicaremos la función valor absoluto, de manera que obtendremos un nuevo conjunto al que denominaremos $S$. Si $s$ es el mínimo de $S$, entonces sabemos que existe $0\lt\frac{s}{s+1}\lt s$, de forma que hemos demostrado que para todo conjunto $F$ existe un $x$ no nulo menor a todos sus elementos. Luego, sabemos que existen elementos no nulos menores a todos los estándares, es decir, no estándares infinitesimales.

Sabemos que no son estándares puesto que si $0\neq\epsilon\simeq 0$, entonces $1/\epsilon$ es ilimitado, por tanto, no estándar. $1/0$ no existe, y ya hemos demostrado que 0 es estándar.
\end{proof}
Ahora, la decisión de considerar el cero como infinitesimal o apreciable es decisión personal la verdad, nosotros lo categorizamos como tal porque nos es útil en nuestros teoremas, pero filosoficamente es discutible.
\begin{thm}
Sea $\epsilon\simeq 0$ entonces:
\begin{enumerate}[$a$)]
\item $s\in{^SR}\wedge s\gt 0\iff|\epsilon|\lt s$.
\item $|\delta|\lt|\epsilon|\implies\delta\simeq 0$.
\item $s\in{^SR}\implies s\epsilon\simeq 0$.
\item $\delta\simeq 0\iff\delta+\epsilon\simeq 0$.
\end{enumerate}
\end{thm}
\begin{proof}
\begin{enumerate}[$a$)]
\item Esta es la definición de infinitesimal.
\item Por definición $\forallst s\gt 0,\;|\epsilon|\lt s$, por transitividad, $|\delta|\lt s$, por tanto, $\delta$ es infinitesimal.
\item Es trivial si $\epsilon=0\vee s=0$. En caso contrario (ambos no nulos), podemos ver que por el teorema~\ref{thm:std-sum-prod} $1/(s\epsilon)$ sería limitado si $1/s$ y $1/\epsilon$ lo fueran, $1/\epsilon$ es ilimitado, por tanto, $1/(s\epsilon)$ lo es, es decir que $s\epsilon$ es infinitesimal.
\item Supongamos que $|\delta|\geq|\epsilon|$, entonces
$$|\delta+\epsilon|\leq|\delta|+|\epsilon|\leq 2|\epsilon|,$$
donde $2\epsilon\simeq 0$ por $c$).
\end{enumerate}
\end{proof}
\begin{thm}
Sean $r,s\in R$ estándar, $r\simeq s$ syss $r=s$.
\end{thm}
\begin{proof}
Supongamos por contradicción que $r\neq s$, entonces $r-s$ sería infintesimal no nulo y estándar, lo que sabemos que es imposible por el teorema~\ref{thm:infinitesimals}.
\end{proof}
\begin{thm}\label{thm:inf-close-nsa}
Sean $r,r',s,s'\in R$ tal que $r\simeq r'$ y $s\simeq s'$ se cumple:
\begin{enumerate}[$a$)]
\item $r+s\simeq r'+s'$.
\item $rs\simeq r's'$.
\item $1/r\simeq 1/r'$.
\item $r\lt s\wedge r\not\simeq s\implies r'\lt s$.
\item $\forallst n\in\N,\;r^n\simeq r'^n$.
\end{enumerate}
\end{thm}
\begin{proof}
En las demostraciones siguientes utilizaremos $r'=r+\epsilon$ y $s'=s+\delta$.
\begin{enumerate}[$a$)]
\item $r'+s'=r+s+\epsilon+\delta$ y $\epsilon+\delta\simeq 0$.
\item $r's'=rs+r\delta+\epsilon s+\epsilon\delta$ y $r\delta+\epsilon s+\epsilon\delta\simeq 0$.
\item $$\frac{1}{r}-\frac{1}{r'}=\frac{\epsilon}{r^2+r\epsilon}$$
Aquí $r^2+r\epsilon=t^{-1}$ es limitado (aunque no estándar), por tanto, $t\epsilon\simeq 0$.
\item Por el primer apartado sabemos que $s-r=t$ es un número positivo apreciable y mayor que epsilon por definición, es decir $t\gt\epsilon$ (puesto que los números apreciables no nulos son mayores que cualquier infinitesimal), luego $s-r'=t-\epsilon$ y por la propiedad anterior se demuestra que es mayor que cero.
\item $$r'^n=(r+\epsilon)^n=r^n+\epsilon\sum_{i=0}^{n-1}\binom{n}{i}r^i\epsilon^{n-1-i}$$
Luego, $\sum_{i=0}^{n-1}\binom{n}{i}r^i\epsilon^{n-1-i}$ es evidentemente apreciable porque $r^{n-1}$ es apreciable y el resto de sumandos es infinitesimal y un apreciable más un infinitesimal es apreciable (por definición), un apreciable por un infinitesimal es infinitesimal.

Nótese que el exponente debe ser estándar porque de lo contrario sería ilimitado y por tanto tendríamos un producto entre infinitesimales e ilimitados.
\end{enumerate}
\end{proof}
En síntesis, dados $\epsilon,\delta$ infinitesimales, $x,y$ apreciables y $\omega,\Gamma$ ilimitados, la aritmética de los números no estándar se reduce en:
\begin{enumerate}
\item Suma:
	\begin{itemize}
	\item $\epsilon+\delta$ es infinitesimal.
	\item $x+y$ es apreciable (posiblemente infinitesimal).
	\item $\omega+\epsilon$, $\omega+x$ es ilimitado.
	\end{itemize}
\item Producto:
	\begin{itemize}
	\item $\epsilon\delta$, $\epsilon x$ es infinitesimal.
	\item $xy$ es apreciable.
	\item $x\omega$, $\omega$ es ilimitado.
	\end{itemize}
\item Inverso multiplicativo:
	\begin{itemize}
	\item $1/\epsilon$ es ilimitado (con $\epsilon\neq 0$).
	\item $1/x$ es apreciable.
	\item $1/\omega$ es infinitesimal.
	\end{itemize}
\item Indeterminaciones: $\epsilon/\delta$, $\omega/\Gamma$, $\epsilon\omega$, $\omega+\Gamma$ (la última sólo cuando los números difieren en signo).
\end{enumerate}

Ahora, un par de cosas para terminar, los ilimitados como los infinitesimales (excepto el cero) son todos no estándar, los apreciables son, en general, estándar, sin embargo, podemos construir un apreciable no estándar a través de la suma de uno estándar con un infinitesimal no nulo (por ejemplo, $5+\epsilon$ es apreciable y no estándar si $\epsilon\simeq 0$ no estándar).

En esta unidad nos acercaremos a la idea de construir rectas numéricas, pero para mayor comprensión de la diferencia entre los ilimitados, apreciables e infinitesimales está debería ser la recta numérica (nótese que esta no es una extensión de la recta clásica sino que incluye a los no estándares, pero que estan presentes en ambos).
\begin{figure}
\centering
\begin{tikzpicture}
\fill[nicegreen] (-.2,-.15) rectangle (.2,.15);
\draw[nicegreen] (-.2,-.15) -- (-.2,-1.25) -- (-4,-1.25) -- (-4,-2.75) -- (6.5,-2.75) -- (6.5,-1.25) -- (.2,-1.25) -- (.2,-.15);
\draw[<->] (-3.5,0) -- (3.5,0) node[right]{Ilimitados};
\foreach \x in {-3,-2,2,3}:
	\draw (\x,.1) -- (\x,-.1) node[below]{$\x\omega$};
\draw (-1,.1) -- (-1,-.1) node[below]{$-\omega$} (0,.1) -- (0,-.1) node[below]{0} (1,.1) -- (1,-.1) node[below]{$\omega$};
\begin{scope}[shift={(0,-2)}]
\fill[niceblue] (-.2,-.15) rectangle (.2,.15);
\draw[niceblue] (-.2,-.15) -- (-.2,-1.25) -- (-4,-1.25) -- (-4,-2.75) -- (6.5,-2.75) -- (6.5,-1.25) -- (.2,-1.25) -- (.2,-.15);
\draw[<->] (-3.5,0) -- (3.5,0) node[right]{Apreciables};
\foreach \x in {-3,...,3}:
	\draw (\x,.1) -- (\x,-.1) node[below]{$\x$};
\end{scope}
\begin{scope}[shift={(0,-4)}]
\draw[<->] (-3.5,0) -- (3.5,0) node[right]{Infinitesimales};
\foreach \x in {-3,-2,2,3}:
	\draw (\x,.1) -- (\x,-.1) node[below]{$\x\epsilon$};
\draw (-1,.1) -- (-1,-.1) node[below]{$-\epsilon$} (0,.1) -- (0,-.1) node[below]{0} (1,.1) -- (1,-.1) node[below]{$\epsilon$};
\end{scope}
\end{tikzpicture}
\caption{Recta numérica con números no estándar.}
\end{figure}

\section{Secuencias}
\begin{mydef}[Secuencia]
	Una secuencia o sucesión es la imagen de una aplicación $s:\N\rightarrow M$ donde sus elementos se denotan $s(n)=s_n$, por lo general, escribiremos
	$$\{s_n\}_{n=0}^\infty=\{s_n\}_{n\geq 0}=\{s_n\}_{n\in\N}$$
	para escribir una secuencia. Si una secuencia parte en cualquier natural, solemos abreviar la secuencia como $\{s_n\}_n$

	También diremos que la secuencia es \textit{convergente} hacia un \textit{límite} $L$ en un espacio métrico $M$ syss para todo $\epsilon\gt 0$ existe un $m$ tal que todo $n\in\N:n\geq m$ cumple $d(s_n,L)\lt\epsilon$. De lo contrario se dice que la secuencia es \textit{divergente}.
\end{mydef}
Antes de dar vueltas en torno a la definición ya dicha señalaremos tipos de sucesiones que se nos serán útiles, en particular las \textit{monótonas} y \textit{estrictas}. Decimos que una sucesión es monótona creciente si
$$s_0\leq s_1\leq\cdots\leq s_n,$$
también se le dice monótona decreciente si
$$s_0\geq s_1\geq\cdots\geq s_n.$$
Se dice que una sucesión es estricta creciente o decreciente si en vez de $\leq$ y $\geq$ sus elementos se ordenan según los signos $\lt$ y $\gt$ respectivamente.

Supongo que la definición de secuencia por si misma es clara, sin embargo, comprendo si el lector no entiende la definición de secuencia convergente y divergente. Desgraciadamente, como científicos estamos obligados a adopta explicaciones formales sin importar su dificultad, sin embargo, eso no nos abstiene de ilustrar mejor una noción.

Para ello, primero hemos de introducir un nuevo tipo de diagrama al que llamaremos \textit{gráfico de funciones}, como vimos, una sucesión es algo así como la imagen de una función cuyo dominio son los naturales, por tanto, serán igualmente útiles. Como una función $f$ es un subconjunto de un producto $A\times B$ dibujamos dicho conjunto como una cuadricula, en ella los elementos se situan en dos rectas llamados ejes coordenados, el horizontal se llama eje $x$ y el vertical $y$, usualmente los elementos de $A$ van en el eje $x$ y los de $B$ en el eje $y$.

Una sucesión es una aplicación $s:\N\rightarrow M$ y como $\N$ es un conjunto infinito sólo gráficaremos una sección de la sucesión, los pares $(n,s_n)$ representan puntos en la cuadricula y para que se vea más elegante uniremos dichos puntos con lineas imaginarias como se demuestra en la fig.~\ref{fig:demo-sec-graph}.
\begin{figure}
	\centering
	\begin{tikzpicture}
		\begin{axis}[demo,
			enlargelimits = true,
			ticks = major, xtick = {1,...,10}, ytick = \empty,
			xlabel = {$x=n$}, ylabel = {$y=s_n$}]
			\addplot+[const plot,niceblue,samples at={1,...,10},mark=none,thick] {(1+2/x)^x};
		\end{axis}
	\end{tikzpicture}
	\caption{Gráfico de $s_n$.}
	\label{fig:demo-sec-graph}
\end{figure}

Cabe destacar que el gráfico se ve como una escalera porque la secuencia tiene dominio $\N$, entonces el valor de $s_n$ es el mismo en todo el intervalo $[n,n+1)$, en el punto $n+1$ la función ``salta'' a $s_{n+1}$. Una forma menos confusa (pero más estéticamente fea) es sólo dibujar un punto en la coordenada $(n,s_n)$.

Lo que nos dice la definición de convergencia es que existe un valor llamado límite $L$ de la sucesión tal que mientras más crece $n$ (la antiimagen), $s_n$ (la imagen) se \textit{acerca} más a $L$. De lo contrario, si la función no se \textit{acerca} a ningún valor en concreto se dice que diverge.

Uno de los ejemplos más comunes es la sucesión
$$s_n=\left(1+\frac 1n\right)^n$$
que visualmente demuestra a la perfección como debe verse una función convergente, también graficaremos una recta a la altura de su límite $L$ para volverlo más claro para el lector (ver fig.~\ref{fig:euler-graph}).
\begin{figure}
	\centering
	\begin{tikzpicture}
		\begin{axis}[demo,
			ymin=0, ymax=5,
			xmin=0, xmax=50,
			samples=30,
			ticks = major, xtick = \empty, ytick = {2.7182818}, yticklabels = {$L$},
			xlabel={$x=n$}, ylabel={$y=\left(1+\dfrac{1}{n}\right)^n$}
			]
			\addplot[niceblue,domain=0:50,dashed] {2.7182818};
			\addplot[niceblue,domain=0:50,smooth] {(1+1/x)^x};
		\end{axis}
	\end{tikzpicture}
	\caption{Gráfico de secuencia convergente.}
	\label{fig:euler-graph}
\end{figure}

A futuro, denotaremos el límite de una sucesión como
$$L=\lim_n s_n,$$
a su vez, cuando una sucesión posea límite $L$ diremos que sus términos $s_n$ \textit{tienden} a $L$, lo que denotaremos como
$$s_n\to L.$$
Nótese también que la definición de límite puede ser descrita de otra manera un tanto más ``amigable'', por definición del valor absoluto decir $|s_n-L|\lt\epsilon$ es lo mismo que decir $L-\epsilon\lt s_n\lt L+\epsilon$, es decir, $s_n\in(L-\epsilon,L+\epsilon)$. Si leemos la definición de límite con esta nueva expresión diría: \textit{el límite $L$ de una sucesión es aquel tal que para todo $\epsilon\gt 0$ existe un $m$ natural cuyos términos sucesores están todos contenidos en $(L-\epsilon,L+\epsilon)$}.
\begin{mydef}[Acotado]
Se dice que una sucesión $\{s_n\}_n$ es acotada si existe algún $x\in M$ y un $C\in R$ tal que $d(s_i,x)\leq C$.
\end{mydef}
Es decir, que todos los elementos de la sucesión están a menos de una distancia $C$ de un punto fijo $x$. Nótese que por desigualdad triangular el punto fijo puede ser cualquiera, digamos un tal $y\in M$:
$$d(s_i,y)\leq d(s_i,x)+d(x,y)\leq C+d(x,y)$$
Luego $C'=C+d(x,y)$ es la cota de $S$. Esto nos servirá para demostrar que una sucesión es acotada syss existe un $C\in R$ tal que $|s_i|\leq C$.
\begin{thm}
Toda sucesión convergente es acotada.
\end{thm}
\begin{proof}
Si $\{s_n\}_n$ es convergente podemos tomar un $\epsilon$ cualquiera tal que existe un término $m$ para el cual todo $n\geq m$ satisfaga $d(s_n,l)\lt\epsilon$, por tanto definimos un número
$$C=\max\{\epsilon,d(s_0,l),\dots,d(s_{m-1},l)\},$$
luego evidentemente $C$ es una cota por que $\forall n\in\N,\;d(s_n,l)\leq C$.
\end{proof}
\begin{thm}
Sea $c\in M$, $\{s_n\}_n$ y $\{r_n\}_n$ dos sucesiones convergentes:
\begin{enumerate}[$a$)]
\item $\{s_n\}_n$ sólo posee un límite.
\item Sea $C$ una cota de $\{s_n\}_n$ entonces $\lim_n s_n\leq C$.
\item $\lim_n (s_n+r_n)=\lim_n s_n+\lim_n r_n$.
\item $\lim_n s_nr_n=\lim_n s_n\cdot\lim_n r_n$.
\end{enumerate}
\end{thm}
\begin{proof}
Antes de continuar definiremos que el límite $s_n\to l$ y $r_n\to L$.
\begin{enumerate}[$a$)]
\item Supongamos por contradicción que $S$ posee los límites $l$ y $L$, entonces podemos tomar un $\epsilon=d(l,L)$, además, sabemos que existe un $m$ tal que para todo $n\geq m$ se cumple que $d(s_n,l)\lt\epsilon/2$ y $d(s_n,L)\lt\epsilon/2$, por tanto, se concluye que
$$\epsilon=d(l,L)\leq d(l,s_n)+d(s_n,L)\lt\epsilon/2+\epsilon/2=\epsilon,$$
lo que es absurdo.
\item Por tricotomía se debe cumplir que $|l|\lt C$, $|l|=C$ o $|l|\gt C$; vamos a demostrar que $|l|\gt C$ es imposible, dado ese caso se debe cumplir que para todo $n\in\N$ se cumpla $|s_n|\lt|l|$, es decir que $0\lt|l|-|s_n|\leq|l-s_n|$, luego, $0\lt|s_n-l|$. Si creamos un conjunto $T=\{|s_n-l|:n\in\N\}$, su elemento mínimo, que denotaremos como $m$ cumple $0\lt m$, por tanto, existe un $\epsilon\in(0,m)$ el cual demuestra que $S$ es divergente, lo que es contradictorio.
\item Por definición de límite se admite que $|s_n-l|\lt\epsilon/2$ y $|r_n-L|\lt\epsilon/2$, luego por propiedades del valor absoluto se tiene que
$$|(s_n+r_n)-(l+L)|\leq|s_n-l|+|r_n-L|\lt\epsilon.$$
\item Supongamos que ese es el caso, ahora procederemos a desarrollar el valor absoluto:
$$|s_nr_n-lL|=|s_nr_n-s_nL+s_nL-lL|=|s_n(r_n-L)+(s_n-l)L|$$
En base de sus propiedades demostramos que
$$|s_nr_n-lL|\leq|s_n||r_n-L|+|L||s_n-l|$$
Como las sucesiones son convergentes existe un $C$ tal que $|s_n|\leq C$, nótese que no perdemos generalidad asumiendo que $S$ posee una cota mayor o igual a la de $R$, por tanto, $|r_n|\leq C'\leq C'+\Delta=C$, donde $\Delta=C-C'\geq 0$. Por propiedad $c$) sabemos que $|L|\leq C'\leq C$. Finalmente, podemos asegurar que existe un $\delta=\epsilon/2C$ tal que $|s_n-l|\lt\delta$ y $|r_n-L|\lt\delta$, por tanto:
$$|s_nr_n-lL|\lt 2\delta C=\epsilon.$$
\end{enumerate}
\end{proof}
\begin{prop}
Algunos límites útiles son:
\begin{enumerate}[$a$)]
\item La sucesión $s_n=c$ converge a $c$.
\item La sucesión $s_n=n$ es divergente.
\item $1/n\to 0$ (desde $n=1$).
\item La sucesión $s_n=(-1)^n$ es divergente.
\item Sea $|r|\lt 1$ entonces $r^n\to 0$.
\item Sea $\lim_n s_n=L$ entonces $\lim_n\frac{1}{n}(s_0+s_1+\cdots+s_n)=L$.
\item $\lim_n \left(1+\dfrac{1}{n}\right)^n=1+\dfrac{1}{1!}+\dfrac{1}{2!}+\cdots$.
\end{enumerate}
\end{prop}
\begin{proof}
\begin{enumerate}[$a$)]
\item Es trivial, puesto que $d(c,c)=0\lt\epsilon$.
\item Supongamos por contradicción que es convergente en un límite $L$, entonces si tomamos $\epsilon=1$ debe existir un $m$ tal que sus elementos sucesores estén a una distancia menor que $1$ de $L$, luego como $0\leq|m-L|\lt 1$ se concluye que $-1\lt m-L\lt 1$, sumando 2 en la inecuación\footnote{Aquellas fórmulas descritas en términos de $\leq$ o $\lt$ (o sus inversos) son comunmente llamadas \textit{inecuaciones}.}, se obtiene que $1\lt(m+2)-L\lt3$, por tanto, $s_n=n$ es divergente.
\item Nótese que $1\lt2\lt\cdots\lt n\lt n+1\lt\cdots$, por tanto, $1\gt\frac{1}{2}\gt\cdots\gt\frac{1}{n}\gt\frac{1}{n+1}\gt\cdots$, es decir, la sucesión es estricta decreciente. Tomemos $\epsilon=\frac{1}{m-1}$ entonces evidentemente para todo $n\geq m$ se cumple $|\frac{1}{n}|\lt\epsilon$.
\item Nótese que la sucesión se escribe como $\{1,-1,1,-1,\dots\}$. Supongamos que es convergente a un límite $L$, entonces tomemos $\epsilon=1$ tal que $|s_n-L|\lt 1$, tomando un $n$ par y otro impar tenemos que $|1-L|\lt 1$ y $|-1-L|\lt 1$, por tanto, se da que
$$2=|1-(-1)|=|1-L+L+(-1)|\leq|1-L|+|-1-L|\lt 1+1=2$$
lo que es una contradicción.
\item Como $|r|\lt 1$, $|r|^2\lt|r|$, luego $|r|^3\lt|r|^2$ y así sucesivamente. Tomese $\epsilon=|r^{m-1}|$, entonces evidentemente para todo $n\geq m$ se cumple que $|r^n|\lt|r^m|$, como se quería demostrar.
\item Consideremos la sucesión
$$r_n=\frac{s_0+s_1+\cdots+s_n}{n},$$
procederemos a demostrar que es convergente a $L$ puesto que si lo es se cumple que $\lim_n r_n-L=0$. Comencemos por separar la suma en dos, nótese que para cualquier $m\lt n$ natural se da la igualdad
$$r_n-L=\frac{s_0+\cdots+s_m-mL}{n}+\frac{(s_{m+1}-L)+\cdots+(s_n-L)}{n}$$
Como $s_0+\cdots+s_m-mL=t_m$ es un número dado, la expresión $t_m/n\to 0$, por tanto existe un $m_0$ tal que los $m\geq m_0$ satisfacen
$$\left|\frac{s_0+\cdots+s_m-mL}{n}\right|\lt\frac{\epsilon}{2},$$
también existe un $m_0$ tal que todos los $m\geq m_0$ cumplen que $|s_m-L|\lt\epsilon/2$ (definición de convergencia), luego
\begin{align*}
|r_n-L|&\leq\left|\frac{s_0+\cdots+s_m-mL}{n}\right|+\left|\frac{(s_{m+1}-L)+\cdots+(s_n-L)}{n}\right|\\
&\leq\left|\frac{s_0+\cdots+s_m-mL}{n}\right|+\frac{|s_{m+1}-L|+\cdots+|s_n-L|}{n}\\
&\lt\frac{\epsilon}{2}+\frac{n-m}{n}\frac{\epsilon}{2}\lt\frac{\epsilon}{2}+\frac{\epsilon}{2}=\epsilon.
\end{align*}
\item Por el binomio de Newton se tiene que
\begin{align*}
\left(1+\frac{1}{n}\right)^n&=1^n+\frac{n}{1!}\frac{1}{n}+\frac{n(n-1)}{2!}\frac{1}{n^2}+\frac{n(n-1)(n-2)}{3!}\frac{1}{n^3}+\cdots\\
&=1+\frac{1}{1!}+\frac{1}{2!}\left(1-\frac{1}{n}\right)+\frac{1}{3!}\left(1-\frac{1}{n}\right)\left(1-\frac{2}{n}\right)+\cdots
\end{align*}
Luego, por suma y multiplicación de límites tenemos que los términos convergen a
$$\left(1+\frac{1}{n}\right)^n=1+\frac{1}{1!}+\frac{1}{2!}+\frac{1}{3!}+\cdots$$
Al número resultante le llamamos \textit{número de Euler}, se denota como $e=2.71828\dots$ y fue descubierto por el famoso matemático Leonhard Euler. Cabe destacar que $e\notin\Q$ y que será un número fundamental en las páginas siguientes.
\end{enumerate}
\end{proof}
\begin{thm}[Teorema del Sandwich]
Dadas las sucesiones $\{a_n\}_n$, $\{b_n\}_n$ y $\{c_n\}_n$ tales que para todo $n\in\N$ se cumpla $a_n\leq b_n\leq c_n$, si $a_n,c_n\to L$, entonces $b_n\to L$.
\end{thm}
\begin{proof}
Por definición $|a_n-L|\lt\epsilon$ y $|c_n-L|\lt\epsilon$, por tanto, se cumple que
$$-\epsilon\lt a_n-L\leq b_n-L\leq c_n-L\lt\epsilon,$$
lo que demuestra que $L$ es límite en $\{b_n\}_n$.
\end{proof}
\begin{mydef}[Sucesión de Cauchy]
Se dice que una sucesión $\{s_n\}_n$ es de Cauchy si para todo $\epsilon\gt 0$ existe un $j\in\N$ tal que para todo $n,m\geq j$ naturales se cumple que $d(s_m,s_n)\lt\epsilon$. Es decir $\{s_n\}_n$ es de Cauchy si
$$\forall\epsilon\gt 0\exists j\in\N\forall n,m\geq j:n,m\in\N,\;d(s_m,s_n)\lt\epsilon$$
\end{mydef}
\begin{thm}[Criterio de convergencia de Cauchy]
Toda sucesión convergente es de Cauchy y toda sucesión de Cauchy está acotada.
\end{thm}
\begin{proof}
Si $\{s_n\}_n$ es una sucesión convergente, existe un valor tal que $s_n\to l$, esto significa que existe un $j$ tal que $n,m\geq j$ naturales se cumple que $d(s_n,l)\lt\epsilon/2$ y $d(s_m,l)\lt\epsilon/2$, luego
$$d(s_n,s_m)\leq d(s_n,l)+d(l,s_m)\lt\epsilon/2+\epsilon/2=\epsilon.$$
Tomemos un $\epsilon\gt 0$ cualquiera, como $\{s_n\}$ es de Cauchy existe un $m$ tal que todos los $n\geq m$ cumplen que $d(s_n,s_m)\lt\epsilon$, luego podemos definir una cota por
$$C=\max\{\epsilon,d(s_0,s_m),\dots,d(s_{m-1},s_m)\}.$$
\end{proof}
\begin{thm}
Sean $\{s_n\}_n$ y $\{r_n\}_n$ sucesiones de Cauchy, entonces, $\{s_n+r_n\}_n$ y $\{s_nr_n\}_n$ son sucesiones de Cauchy.
\end{thm}
\begin{proof}
La suma se demuestra por la inecuación:
$$|s_n+r_n-(s_m+r_m)|\leq|s_n-s_m|+|r_n-r_m|$$
Luego, como $\{s_n\}$ y $\{r_n\}$ son de Cauchy ambas podemos suponerlas menores que un $\epsilon/2$ y, por tanto, el todo es menor que un $\epsilon$.

El producto se demuestra por la inecuación:
$$|s_nr_n-s_mr_m|\leq|s_n||r_n-r_m|+|r_m||s_n-s_m|$$
Luego, como son secuencias de Cauchy, son acotadas y podemos asumir que $C$ es la cota mayor entre ambas tal que $|s_n|,|r_n|\leq C$ y $|s_n-s_m|,|r_n-r_m|\lt \epsilon/2C$, por tanto, el todo es menor que un $\epsilon$.
\end{proof}
\begin{mydef}[Subsecuencia]
Sea $s:\N\rightarrow R$ una secuencia cualquiera y $n:\N\rightarrow\N$ otra secuencia estricta creciente (cuyos términos denotaremos como $n_k$), la composición $n\circ s$ o $\{s_{n_k}\}_k$ es una subsecuencia de $\{s_n\}_n$.
\end{mydef}
Para dar un ejemplo tomemos la secuencia $s=\{1/n\}_{n=1}^\infty$:
$$\left\{1,\frac 12,\frac 13,\frac 14,\cdots\right\}$$
La secuencia $\{1/n^2\}_{n=1}^\infty$ es subsecuencia de $s$:
$$\left\{1,\frac 14,\frac 19,\frac{1}{16},\cdots\right\}.$$
Sin embargo, las secuencias $\{1,1,\frac 12,\frac 13,\dots\}$ y $\{\frac 12,1,\frac 13,\frac 14,\dots\}$ no son subsecuencias de $s$.
\begin{thm}
Sea $\{s_n\}_n$ una secuencia, las siguientes expresiones son equivalentes:
\begin{enumerate}[(1)]
\item $\{s_n\}_n$ es convergente en un límite $l$.
\item Toda subsecuencia de ella converge en un límite $l$.
\end{enumerate}
\end{thm}
\begin{proof}
Veamos que $(1)\implies(2)$. Por definición de límite debe cumplirse que
$$\forall\epsilon\gt 0\exists n_0\forall n\gt n_0\;d(s_n,l)\lt\epsilon.$$
Como $n_k$ es estricta creciente, veamos que para todo $k$ se cumple $n_k\geq k$, por tanto, $n_{n_0+1}\geq n_0+1\gt n_0$, por tanto, se cumple la definición de límite para $\{s_{n_k}\}_k$ general.

Luego $(2)\implies(1)$ es trivial puesto que si tomamos $n_k=k$ entonces obtenemos que $\{s_n\}_n$ es su propia subsecuencia, como todas las subsecuencias de sí convergen a $l$, también lo hace \textit{per se}.
\end{proof}
Quiero destacar una consecuencia inmediata del teorema que es su negación: si existe alguna subsecuencia que no converja a $l$ (digamos a otro valor $L$) entonces la secuencia no converge a $l$ y viceversa.

Al igual que en la sección anterior desde aquí en adelante estudiaremos los límites bajo la visión del análisis no estándar.

Una definición un tanto más apropiada y, relativamente simple, de convergencia es la siguiente:
\begin{thm}[Convergencia no estándar]\label{thm:non-std-lim}
Sea $\{s_n\}_n$ una sucesión cualquiera. Es convergente en un límite $\lim_n s_n=L$ syss para todo $n\in\N$ ilimitado se cumple que $s_n\simeq L$.
\end{thm}
\begin{proof}
La definición formal de límite puede decribirse así:
$$\lim_n s_n=L\iff\forall\epsilon\gt 0\exists n_0\forall n\geq n_0\;|s_n-L|\lt\epsilon.$$
Luego, por (T) podemos ver que la definición se aplica si $\epsilon\gt 0$ es estándar. Si $s_n\simeq L$ entonces $|s_n-L|\lt\epsilon$ (por la definición de infinitesimal). Si $n$ es ilimitado y $s_n\not\simeq L$ entonces su diferencia es apreciable, por tanto su inverso lo es, lo que significa que existe un $m\in{^SR}$ tal que $|s_n-L|^{-1}\lt m$, por tanto, $|s_n-L|\gt 1/m$ con $1/m$ estándar y positivo, es decir, tomando $\epsilon=1/m$ nuestra definición no funcionaría, veamos que por (T) si funciona para cualquier $n_0$ (estándar o no) debe funcionar para cualquier $n_0$ estándar, luego limitado; si no funciona para un $n_0$ ilimitado, no lo hace para un $n_0$ limitado como se debe, por tanto, la condición es suficiente y necesaria\footnote{Se dice así para señalar que $(a)\implies(b)$ y $(b)\implies(a)$ en una demostración.}.
\end{proof}
\begin{mydef}[Divergencia infinita]
Supongamos que $\{s_n\}_n$ es una secuencia divergente, diremos que tiende a infinito o posee un límite infinito si para todo $n$ ilimitado, $s_n$ es ilimitado. En particular si $s_n\gt 0$ se escribe que $s_n\to\infty$, si $s_n\lt 0$ se escribe que $s_n\to-\infty$.
\end{mydef}
Bajo esta definición es fácil ver que ciertos límites como $\{1/n\}_{n=1}^\infty$ tienden a 0, por que si $n$ es ilimitado, $1/n$ es infinitesimal, es decir, $1/n\simeq 0$. También podemos ver que $\lim_n n^c=\infty$ con $c\geq 1$ entero.
\begin{thm}
Una sucesión estándar es acotada syss para todo $n$ ilimitado, $s_n$ es limitado.
\end{thm}
\begin{proof}
Como la sucesión es estándar, para todo $N$ limitado (luego estándar) se obtiene un $s_N$ estándar (luego limitado), por tanto, sea $\{s_n\}_n$ la sucesión hasta $N$ entonces su cota sería
$$C=\max\{s_n\}_n$$
Por (T) podemos asegurar que la cota es estándar, luego limitada, por tanto, $s_n$ debe ser limitado independiente de si $n$ es limitado o no. Como dijimos $s_n$ sólo puede ser ilimitado cuando $n$ es ilimitado, por tanto, $\{s_n\}_n$ es acotado syss $s_n$ es limitado con $n$ ilimitado como se quería probar.
\end{proof}
\begin{thm}
Sean $\{s_n\}_n$ y $\{r_n\}_n$ dos sucesiones \textbf{convergentes} con $\lim_n r_n=0$, entonces $\lim_n (s_nr_n)=0$.
\end{thm}
\begin{proof}
Si $\{s_n\}_n$ es convergente, es acotado, por tanto, para un $n$ ilimitado $s_n$ es limitado, como el límite de $\{r_n\}_n$ es nulo, $r_n\simeq 0$, como $s_n$ es limitado, puede ser apreciable o nulo, en ambos casos $s_nr_n\simeq 0$, por tanto $\lim_n(s_nr_n)=0$.
\end{proof}
\begin{thm}[Sucesión de Cauchy]
Una sucesión estándar es de Cauchy si para todo $n$ y $m$ ilimitados se cumple que $s_n\simeq s_m$.
\end{thm}
\begin{proof}
La demostración es análoga a la del teorema~\ref{thm:non-std-lim}.
\end{proof}
\begin{thm}
Si $\{s_n\}_n$ es una sucesión estándar convergente entonces es de Cauchy.
\end{thm}
\begin{proof}
Esto es trivial, porque gracias a nuestra definición no estándar de convergencia entonces $s_n\simeq l\simeq s_m$, luego $s_n\simeq s_m$.
\end{proof}

\section{Construcción de $\R$}
Iniciamos el capítulo señalizando que nuestro conjunto de números racionales es \textit{incompleto} (por la falta de $\sqrt{2}$, por ejemplo), por tanto, aún nos falta construir un conjunto que no carezca de ``agujeros'', este conjunto lo llamaremos \textit{reales} y lo denotaremos como $\R$, pero antes de formalizarlo hemos de entender que le falta a $\Q$.

Sabemos que $\Q$ posee agujeros vacíos, es decir, carece de números en lugares fijos, esto podemos describirlo formalmente con el concepto de sección o partición:
\begin{mydef}[Sección, corte o partidura]
Corresponde a una $n$ tupla ordenada $(A_1,A_2,\dots,A_n)$ de conjuntos tales que $\{A_n\}_{i=1}^n$ son subconjuntos disjuntos (entre sí) de $B$ que satisfacen $\bigcup_{i=1}^n A_n=B$. Además todo elemento de $A_i$ es menor que todo elemento de $A_{i+1}$ y $A_{i+1}$ no puede poseer un elemento mínimo. Si $A_i$ no posee máximo, entonces se dice que la partición es \textit{estricta}.
\end{mydef}
Veamos que si consideramos los siguientes conjuntos:
$$a=\{r\in\Q:r\lt 0\vee r^2\leq 2\},\; b=\{r\in\Q:r\gt 0\wedge r^2\gt 2\}$$
Se cumple que $(a,b)$ es un corte, en particular, estricto.

Ahora, $\sqrt{2}\notin\Q$, pero $\lfloor\sqrt{2}\rfloor=1\in\Q$ y de hecho, $\lfloor 10\sqrt{2}\rfloor/10=1.4\in\Q$, en general, podemos especificar una sucesión
$$s_n=\frac{\lfloor 10^n\sqrt{2}\rfloor}{10^n}$$
que es de Cauchy, sin embargo, es divergente en $\Q$, a pesar de que todo $s_n\in\Q$. De hecho este problema es muy similar a la sucesión $\{1/n\}_{n=1}^\infty$ que es divergente en $\Q_0$, sin embargo, es de Cauchy y si tuvieramos acceso al $0$ en $\Q_0$ notaríamos que es evidentemente convergente, pero su \textit{carencia de elementos} nos obliga a creer que es divergente.
\begin{mydef}[Complitud conjuntivista]
Se dice que un conjunto numérico es \textit{completo} cuando toda sucesión de Cauchy dentro de ese conjunto es convergente.
\end{mydef}
Con estos datos se nos dan dos formas de construir los reales, una es a través de los \textit{cortes de Dedekind}, donde se definen los reales como todos los posibles cortes o secciones de $\Q$, aquí si $x\in\Q$ entonces $x\in\R$ es $(\{r\in\Q:r\leq x\},\{r\in\Q:r\gt x\})$, mientras que los irracionales son los cortes estrictos.
\begin{figure}
\centering
\begin{subfigure}{\textwidth}
\centering
\begin{tikzpicture}[very thick,scale=1.5]
\draw[<-,nicered] (-3.5,0) node[above left]{$A$} -- (0,0);
\foreach \x in {-3,...,0}
	\draw[nicered] (\x,.1) -- ++(0,-.2) node[below]{$\x$};
\draw[<-,nicegreen] (3.5,0) node[above right]{$B$} -- (0,0);
\foreach \x in {1,2,3}
	\draw[nicegreen] (\x,.1) -- ++(0,-.2) node[below]{$\x$};
\fill[nicered] (0,0) circle (.05);
\end{tikzpicture}
\caption{Corte común.}
\end{subfigure}
\begin{subfigure}{\textwidth}
\centering
\begin{tikzpicture}[very thick,scale=1.5]
\draw[<-,nicered] (-3.5,0) node[above left]{$A$} -- ({sqrt(2)},0);
\foreach \x in {-3,...,1}
	\draw[nicered] (\x,.1) -- ++(0,-.2) node[below]{$\x$};
\draw[<-,nicegreen] (3.5,0) node[above right]{$B$} -- ({sqrt(2)},0);
\foreach \x in {2,3}
	\draw[nicegreen] (\x,.1) -- ++(0,-.2) node[below]{$\x$};
\draw ({sqrt(2)},.1) -- ++(0,-.2) node[below]{$\sqrt{2}$};
\filldraw[fill=white] ({sqrt(2)},0) circle (.05);
\end{tikzpicture}
\caption{Corte estricto.}
\end{subfigure}
\caption{Secciones en $\Q$.}
\label{fig:dedekind-cut}
\end{figure}

En la figura~\ref{fig:dedekind-cut} se debe interpretar el punto rojo como que el punto 0 está contenido en $A$, cuando se punta un punto con un interior blanco se refiere a que ese punto está de alguna forma ``vacío''. Esta interpretación también deberá aplicarse en gráficos.

El otro método, más útil para definir relaciones sobre $\R$ es definir los números como sucesiones, para ello nos basaremos en la idea general: Sea $M$ un espacio métrico, todas las sucesiones posibles están contenidas en $M^\N$, definimos $C_M$ como el subconjunto que posee solamente las sucesiones de Cauchy en $M$. Luego definimos una relación $\sim$ tal que $\{s_n\}_n\sim\{t_n\}_n$ syss $\lim_n d(s_n,t_n)=0$ o equivalentemente que para todo $n$ ilimitado se cumple que $s_n\simeq t_n$ (en NSA). Evidentemente se cumple la reflexividad y simetría, la transitividad es trivial en NSA, pero puede tomarla como ejercicio su demostración estándar o clásica; esto demuestra que $\sim$ es una relación de equivalencia. Finalmente se define la \textit{compleción} de $M$, que denotaremos como $\overline{M}$ como el conjunto cociente $(C_M\times C_M)/\sim$. En particular, definimos $\R\equiv\overline{\Q}$.
\begin{thm}
$(\R,+,\cdot,\leq)$ es un cuerpo totalmente ordenado.
\end{thm}
\begin{proof}
Comencemos por demostrar que $(\R,+,\cdot)$ es un cuerpo. Sean $a=[\{s_n\}_n]$ y $b=[\{t_n\}_n]$ dos números reales, entonces definimos la suma y el producto como
$$a+b=[\{s_n+t_n\}_n],\quad ab=[\{s_nt_n\}_n],$$
de aquí se demuestra sencillamente la conmutatividad, asociatividad, los inversos son $-a=[\{-s_n\}_n]$ y $a^{-1}=[\{s_n^{-1}\}_n]$ respectivamente, y los elementos neutro son $0=[\{0\}_n]$ y $1=[\{1\}_n]$.

Ahora nos corresponde demostrar que $\leq$ es una relación de orden total. Definimos que $a\leq b\iff a=b\vee a\lt b$. $a=b$ syss para todo $\epsilon\gt 0$ existe un $m\in\N$ tal que para todo $n\gt m$ se cumple $d(s_n,t_n)\lt\epsilon$, para NSA significa que para todo $n$ ilimitado, $s_n\simeq t_n$. $a\lt b$ syss existe algún $m\in\N$ tal que todo $n\gt m$ satisface que $s_n\lt t_n$, para NSA significa que para todo $n$ ilimitado se cumple $s_n\ll t_n$.
\end{proof}
\begin{thm}[Densidad de $\Q$ en $\R$]\label{thm:rational-inside}
Dados dos reales $r,s\in\R$ tales que $r\lt s$, existe un racional $q\in\Q$ tal que $r\lt q\lt s$.
\end{thm}
\begin{proof}
Como $\R$ es un cuerpo totalmente ordenado arquimediano para todo $r$ se cumple que $t=\lfloor r\rfloor\leq r\lt t+1$ con $t\in\Q$. Luego podemos definir una secuencia
$$t_i=t+\frac{i}{n},\quad 0\leq i\leq n$$
con la que identificamos $t=t_0$ y $t+1=t_n$. Evidentemente existe un único $i$ tal que $t_i\leq r\lt t_{i+1}$, luego si $n\to\infty$ se cumple $t_{i+1}-t_i=1/n\simeq 0$, por tanto, $t_{i+1}\simeq r$, como $s\gt r$ se cumple $r\lt t_{i+1}\lt s$ y $t_{i+1}$ es evidentemente racional.
\end{proof}
En $\R$, los números satisfacen la siguiente regla: se define la función inyectiva identidad $i:\Q\rightarrow\R$ como aquella tal que $i(q)=[\{q\}_n]$, luego, un elemento general de $\R$ se define a partir del siguiente teorema:
\begin{thm}[Número real]
Sea $\{s_n\}_n$ una sucesión de Cauchy en $\Q$, se define un real $r=[\{s_n\}_n]\in\R$ tal que
$$\lim_n i(s_n)=r.$$
\end{thm}
\begin{proof}
Supongamos, por contradicción, que no es así, entonces existe algun $\epsilon$ tal que $|s_n-r|\lt\epsilon$, si $s_n\lt r$ entonces $s_n\lt r-\epsilon$. Por el teorema~\ref{thm:rational-inside} existe un $q$ tal que $r-\epsilon\lt q\lt r$, por tanto, $s_n\lt q\lt r$. Pero por definición $r=[\{s_n\}_n]\lt[\{q\}_n]=q$, lo que es un absurdo $r\lt q\lt r$.
\end{proof}
\begin{thm}[Propiedades de $\infty$]
Sea $c\in\R$ finito y considere ``ind'' como abreviación de ``indeterminado'':
\begin{enumerate}[$a$)]
\item $$c\cdot\infty=\begin{cases}
\phantom{-}\infty, &c\gt 0\\
-\infty, &c\lt 0
\end{cases}$$
\item $\infty+c=\infty$.
\item $c/\infty=0$.
\item $\infty-\infty=\rm ind$.
\item $c/0=\rm ind$.
\item $0/0=\rm ind$.
\item $\infty/\infty=\rm ind$.
\item $0\cdot\infty=\rm ind$.
\item $1^\infty=\rm ind$.
\end{enumerate}
\end{thm}
\begin{proof}
Las demostraciones se harán con la definición de reales, es decir, utilizaremos sucesiones que converjan a $c$ e $\infty$, en general, $c=[\{s_n\}_n]$ e $\infty=[\{t_n\}_n]$. Para demostrar las indeterminaciones nos dignaremos a encontrar dos \textit{valores posibles} para su convergencia.
\begin{enumerate}[$a$)]
\item Es trivial, puesto que por definición, para todo $n$ ilimitado $s_n\simeq c$, a su vez, $t_n$ es ilimitado. El producto de un ilimitado por un apreciable (pues $c$ dijimos es finito y no nulo, si fuera infinitesimal, su sucesión convergería en cero) es ilimitado y propiedades de signo ya fueron demostradas en la sección 2.2.
\item Es trivial puesto que la suma de un ilimitado por un limitado es ilimitado.
\item Si para todo $n$ ilimitado, $t_n$ ilimitado, entonces $t_n^{-1}$ es infinitesimal, el producto de un limitado por un infinitesimal es infinitesimal, por tanto, converge a 0.
\item Supongamos que ambos infinitos son límites de la misma sucesión, entonces su diferencia sería 0. En cambio si el primer infinito es límite de $s_n=n^2$ y el segundo es límite de $t_n=n$, entonces, su diferencia tiende a $\infty$.
\item Sea 0 el límite de $s_n=1/n$ entonces $c/0=\infty$, en cambio sea el límite de $t_n=-1/n$ entonces $c/0=-\infty$.
\item Sean ambos ceros límites de la misma sucesión entonces $0/0=1$. En cambio sea el primer cero límite de $s_n=1/n$ y el segundo límite de $t_n=1/n^2$ entonces $0/0=\infty$.
\item Es análogo a $d$).
\item Sea 0 límite de $s_n=1/n$ e $\infty$ límite de $t_n=n$ entonces $0\cdot\infty=1$. Sea 0 límite de $s_n=0$ entonces $0\cdot\infty=0$.
\item Sea 1 límite de $s_n=1$ e $\infty$ límite de $t_n=n$ entonces $1^\infty=1$. Sea 1 límite de $s_n=1+1/n$ entonces $1^\infty=e$.
\end{enumerate}
\end{proof}
\begin{mydef}[Sombra]
Sea $r\in R$ un número limitado cualquiera (estándar o no), su \textbf{sombra} es el único estándar $\sh r$ tal que $r\simeq\sh r$.
\end{mydef}
\begin{thm}
Para todo $r\in\R$ existe un único $\sh r\in\R$.
\end{thm}
\begin{proof}
Para todo $r$ se cumple que $s=\lfloor r\rfloor\leq r\lt s+1$. Luego definimos la secuencia
$$s_i=s+\frac{i}{n},\quad 0\leq i\leq n,$$
tal que existe algún $i$ que satisface $s_i\leq r\lt s_{i+1}$, debido a eso definimos $x_n=s_i$ e $y_n=s_{i+1}$. Para $n$ ilimitado $y_n-x_n=1/n\simeq 0$, luego $x_n-1/n\lt x_n\leq r\lt x_n+1/n=y_n$, por tanto, $|r-x_n|\lt1/n=\epsilon$, es decir, $\lim_n x_n=\sh r$, como $y_n=x_n+1/n$, $\lim_n y_n=\sh r$.

Nótese que si $r$ es no estándar, tanto $x_n$ como $y_n$ tienden a él, sin embargo, la misma definición de límite especifica que el valor sea estándar, puesto que $\sh r\simeq r$.
\end{proof}
\begin{thm}
Para todo $r$ y $s$ limitado se cumple:
\begin{enumerate}[$a$)]
\item $\sh(r+s)=\sh r+\sh s$.
\item $\sh(rs)=\sh r\cdot\sh s$.
\item $r\leq s\implies\sh r\leq\sh s$.
\end{enumerate}
\end{thm}
\begin{proof}
Tomemos $*r=\sh r$ y $*s=\sh s$, a su vez, $\epsilon=r-*r$ y $\delta=s-*s$.
\begin{enumerate}[$a$)]
\item $\sh(*r+*s+(\epsilon+\delta))=*r+*s$.
\item $\sh((*r+\epsilon)(*s+\delta))=\sh(*r*s+*r\delta+*s\epsilon+\epsilon\delta)={*r}{*s}$.
\item La expresión de izquierda es equivalente a $\Delta=s-r\geq 0$, luego si $\Delta\simeq 0$ entonces $*r=*s$, si $\Delta$ es apreciable, entonces $\sh\Delta\neq 0$ y como $\sh s-\sh r=\sh(s-r)$, se demuestra que $*r\lt*s$. La reciproca es trivial.
\end{enumerate}
\end{proof}
Debido a la definición de $\R$ sabemos que toda sucesión de Cauchy en $\Q$ es convergente en $\R$, pero ¿toda sucesión de Cauchy en $\R$ es convergente en $\R$? En otras palabras, ¿es $\R$ completa, o su propia compleción?
\begin{thm}[Compleción de $\R$]
Toda sucesión de Cauchy converge en $\R$.
\end{thm}
\begin{proof}
Sea $\{s_n\}_n$ una sucesión de Cauchy, luego acotada, por tanto, para un $n$ ilimitado $r=\sh s_n\simeq s_n$, como es de Cauchy podemos tomar cualquier otro $m$ y se cumple lo mismo, es decir, $r=\lim_n s_n$.
\end{proof}

\section{Propiedades de $\R$}
\begin{mydef}[Supremo e ínfimo]
Sea $X$ un subconjunto de un espacio métrico. Decimos que es:
\begin{enumerate}[i)]
\item \textbf{Limitado superiormente} si existe un $r$ cualquiera tal que sea mayor o igual que todos sus elementos, a $r$ se le llamara \textit{cota superior}.
\item \textbf{Limitado inferiormente} si existe un $r$ cualquiera tal que sea menor o igual que todos sus elementos, a $r$ se le llamara \textit{cota inferior}.
\item \textbf{Limitado}, si lo es superior e inferiormente.
\end{enumerate}
A su vez, decimos que un real $r$ es su:
\begin{itemize}
\item Supremo: si es mayor que todo $x\in X$ pero menor o igual a toda cota superior. Se le denotará por $\sup X$.
\item Ínfimo: si es menor que todo $x\in X$ pero mayor o igual a toda cota inferior. Se le denotará por $\inf X$.
\end{itemize}
\end{mydef}
Nótese que a diferencia del máximo y mínimo, introducidos en el capítulo anterior, estos no tienen que necesariamente estar contenidos en $X$.
\begin{thm}
Sea $M$ un espacio métrico y $X\subset M$ no vacío, las siguientes expresiones son equivalentes:
\begin{enumerate}[$a$)]
\item $M$ es completo.
\item Si $X$ es limitado superiormente posee supremo (axioma del supremo).
\item Si $X$ es limitado inferiormente posee ínfimo.
\end{enumerate}
\end{thm}
\begin{proof}
Comenzaremos por demostrar que $a)\implies b)$. Como $X$ es no vacío asumiremos que $x\in X$: supongamos que $x+1$ es una cota superior, entonces definimos $x_i=x+i/n$, por tanto, para todo $n$ natural no nulo existe un $i$ tal que $x_i\in X$ pero $x_{i+1}\notin X$ luego $s_n=x_i$ y $t_n=x_{i+1}$. Como $M$ es completo $s_n$ posee límite, el mismo que $t_n$ (pues están a $1/n$ de distancia) y es $\sup X$. Luego, para todo $x\in X$ se cumple que $t_n\gt x$ y sabemos que son la mínima cota superior pues si suponemos que $u$ es una cota superior de $X$ no puede darse $u\lt s_n$ puesto que $\forall n\;s_n\in X$, lo que llevaría a una contradicción.

Luego, demostraremos que $b)\implies c)$. Como $X$ es no vacío asumiremos que existe un $x\in X$, como esta limitado inferiormente supondremos que $m$ es una cota inferior y definiremos el conjunto $Y=\{y\in M:\forall x\in X, y\lt x\}$ que es no vacío pues $m\in Y$ y es limitado superiormente por la cota $x$, por tanto, existe $\sup Y$. Podemos ver que por definición $X$ es un conjunto de cotas superiores de $Y$ por tanto $\sup Y\leq x$, mientras que $Y$ es el conjunto de todas las cotas inferiores de $X$, y por definición del supremo $\forall y\in Y\;y\leq\sup Y\leq x$, por tanto, $\sup Y=\inf X$.

Finalmente, $c)\implies a)$. Supongamos que tenemos una secuencia $\{s_n\}_n$ de Cauchy, para demostrar que converge utilizaremos otra secuencia $\{t_n\}_n$ que es estricta decreciente tal que $\lim_n d(s_n,t_n)=0$. Si $t$ es de Cauchy es acotada (tanto inferior como superiormente) y, por definición es decreciente, por tanto, existe $\inf(\Img t)=l$. Ahora procederemos a demostrar que es el límite, por definición de ínfimo, como $t_n$ es de Cauchy consideremos dos números $n,m_0$ tal que $n\lt m_0$ y por tanto $t_{m_0}\lt t_n$, luego definamos un $\epsilon=t_n-t_{m_0}$ de forma que para todo $m$ mayor a $m_0$ se cumpla $-\epsilon\lt t_m-t_{m_0}\lt t_{m_0}-t_m\lt\epsilon$, sumando $t_
{m_0}$ se obtiene que $m=t_{m_0}-\epsilon\lt t_m$, por tanto $m$ es cota inferior de $\Img t$, es decir, $m\lt l\leq t_m\lt t_n$, nótese que $t_n=t_{m_0}+\epsilon$, de forma que $t_{m_0}-\epsilon\lt l\lt t_m+\epsilon$, por tanto, $l$ es límite de $t_n$ y $s_n$.
\end{proof}
Nosotros hemos construido $\R$ a partir de las sucesiones de Cauchy, sin embargo, una forma equivalente por el teorema anterior es a través del axioma del supremo, aun que una desventaja es que se acompleja la demostración de que $\R$ es un cuerpo totalmente ordenado arquimediano.
\begin{thm}
Sea $\{s_n\}_n$ una sucesión monótona creciente (resp. decreciente) acotada entonces converge al supremo (resp. ínfimo) de su imagen.
\end{thm}
\begin{proof}
Sea $\{s_n\}_n$ una sucesión monótona creciente y $S=\Img(s_n)$, luego como $S$ es no vacío y acotado posee supremo, llamemosle $M$, y $\{s_n\}_n$ converge a $l$. Evidentemente $l\not\gt M$ (si lo fuera podemos escoger $\epsilon$ como la mitad de la distancia entre ambos y los términos de $s_n$ serían mayores que su cota, contradicción). Probaremos que $\lim_n s_n\not\lt M$, sino podríamos ver que habría un $\epsilon$ igual a la mitad de la distancia entre $l$ y $M$, luego habrían puntos entre $l+\epsilon$ y $M$ que serían cotas, contradicción. Finalmente, por tricotomía $l=M$. Es análogo para $\{s_n\}_n$ decreciente convergiendo a su ínfimo.
\end{proof}
\begin{thm}
Todo conjunto finito de números reales posee máximo y mínimo.
\end{thm}
\begin{proof}
Veamos que si $A$ es un conjunto finito, de cardinal $N$, entonces existe una biyección
\begin{align*}
a:I_N&\longrightarrow A\\
a(n)&\longmapsto a_n,
\end{align*}
tal que podemos definir dos secuencias como prosigue:
$$m_{n+1}=\min\{a_{n+1},m_n\},\quad M_{n+1}=\max\{a_{n+1},M_n\}.$$
Se considera que $m_0=M_0=a_0$ y $m_n=m_N,M_n=M_N$ cuando $n\gt N$. Veamos que $\{m_n\}_n$ y $\{M_n\}_n$ son secuencias convergentes a $m_N$ y $M_N$ respectivamente, luego definimos $\min A=m_N$ y $\max A=M_N$, puesto que ambos son elementos de $a$.
\end{proof}
Cabe decir que este es el algoritmo en la programación para determinar el mínimo y máximo de un conjunto.
\begin{thm}[Bolzano-Weierstrass]
Toda secuencia acotada en un conjunto completo posee una subsecuencia convergente.
\end{thm}
\begin{proof}
Sea $\{s_n\}_n$ nuestra secuencia de cotas $m$ y $M$ respectivamente y definamos
$$B_0=[m,M]=L_0\cup R_0,$$
como observamos en la sección de cuerpos métricos podemos encontrar un centro y un radio para $B_0$ de manera que si $O(B_0)$ es su centro entonces $L_0=[m,O(B_0)]$ y $R_0=[O(B_0),M]$, como es de Cauchy, alguno de los dos intervalos posee infinitos elementos, digamos que es $B_1$ el cual contiene al término $s_{n_1}$ donde $n_1$ es el menor término posible, repitamos la técnica y escojamos un $B_2$ y un $s_{n_2}\in B_2$ y así sucesivamente, cumpliendo siempre que $B_0\supset B_1\supset B_2\supset\cdots$.

Definamos una función longitud para subconjuntos $X$ de $R$ tal que sea $|X|=d(\inf X,\sup X)$, entonces, para todo $n$ se cumple $|B_n|=2^{-n}(M-m)$, por tanto, $\lim_j |B_j|=0$, es decir, para todo $\epsilon\gt 0$ se cumple $|B_j|\lt\epsilon$, para $j\gt j_0$; si $k\gt j_0$ entonces $s_{n_j},s_{n_k}\in B_j$ por tanto, $d(s_{n_j},s_{n_k})\leq|B_j|\lt\epsilon$. Por lo tanto, $s_{n_j}$ es de Cauchy y como $R$ es completo, es convergente.
\end{proof}
\begin{mydef}[Raíz positiva]
Sea $x$ un número real positivo y $n$ un natural, existe un número real positivo $y$ que satisface $y^n=x$, el cuál denotaremos como $y=\sqrt[n]{x}$ y llamaremos \textit{$n$-ésima raíz positiva}.
\end{mydef}
\begin{thm}
La raíz positiva de un número es única.
\end{thm}
\begin{proof}
Consideremos la $n$-ésima raíz positiva de $x$, entonces comenzamos por construir un conjunto $X=\{y\in\R:0\lt y^n\lt x\}$, luego considere el elemento $r=\frac{x}{x+1}$, es evidente que $0\lt r\lt 1$ y que $r^n\lt r\lt x$, por tanto, $X$ no es un conjunto vacío, luego, al ser limitado, existe $\sup X$.

Ahora procedemos a demostrar que $\sqrt[n]{x}=\sup X=y$. De lo contrario, por tricotomía, $y\lt\sup X$, por tanto, $y\in X$, luego $y^n\lt x$. El otro caso es que $y\gt\sup X$, como sabemos que $y\not\lt\sup X$, sabemos que para todo $z\in X$ se cumple $z^n\lt x\leq(\sup X)^n\lt x$ lo que es una contradicción. Por tanto, queda demostrado.
\end{proof}
\begin{thm}[Densidad de $\Q^*$ en $\R$]
Sean $r\lt s\in\R$ un par de reales, entonces existe $t\in\Q^*$ tal que $r\lt t\lt s$.
\end{thm}
\begin{proof}
Nótese que por densidad de $\Q$ en $\R$ existe $q\in\Q$ tal que $r\lt q\lt s$, en particular $\frac{s-q}{2}\gt 0$, por propiedad arquimediana, existe $n\in\N$ tal que $\frac{s-q}{2}\gt\frac{1}{n}$, despejando te queda que
$$r\lt q\lt q+\frac{\sqrt{2}}{n}\lt q+\frac{\sqrt{4}}{n}\lt s,$$
con el término del medio siendo irracional.
\end{proof}
\begin{thm}[Desigualdad (discreta) AM-GM]
Para todo $0\lt x\lt y\in\R$ se cumple que
$$x\lt\sqrt{xy}\lt\frac{x+y}{2}\lt y$$
\end{thm}
\begin{proof}
Es sencillo probar que para todo $x\lt y$ positivo la primera (usualmente abreviada como GM) y la segunda desigualdad (usualmente abreviada AM\footnote{\textit{AM} de Arithmetic Medium o Media Aritmética y \textit{GM} de Geometric Medium o Media Geométrica.}) se mantienen, por lo que probaremos solamente que $\rm AM\gt GM$.

Tomemos las desigualdades y elevémoslas al cuadrado, pues ambos términos son positivos:
$$xy\lt\left(\frac{x+y}{2}\right)^2=xy+\frac{x^2+y^2}{4}$$
el término de la derecha es evidentemente mayor que cero, luego está demostrado.
\end{proof}

\section{Axioma de elección y cardinales grandes}\label{sec:big-cardinals}
Veamos que la teoría ZF, es bastante completa hasta el momento y nos servirá para casi todos los teoremas que queramos demostrar (excepto unos pocos, como el de la hipótesis del continuo). Sin embargo, para liberar su \textit{máximo potencial}, aún podemos introducir un último axioma:
\begin{axiom}[de Elección (AC)]
Supongamos que $A$ es una familia de conjuntos tal que $\emptyset\notin A$, entonces
$$\exists(f:A\rightarrow\bigcup A):\forall a\in A, f(a)\in a.$$
\end{axiom}
En resumidas cuentas dice que si $A$ posee un conjunto de conjuntos $a_1,a_2,\dots$, entonces existe una función que llamaremos \textit{de elección} tal que toma un elemento de cada conjunto. Esto puede ser trivial para $A$ finito, pero es indemostrable para $A$ infinito (al menos no en ZF). La teoría de los axiomas de Zermelo-Fraenkel más el axioma de elección es abreviada como ZFC. Igualmente, cabe decir que usualmente se utiliza el axioma para construir $\Img f$ en realidad.

Historicamente, este axioma lleva una importancia crucial en los anales de las matemáticas, fue originalmente propuesto en 1904 por Ernest Zermelo para su \textit{principio del buen ordenamiento}, sin embargo, las consecuencias de este axioma tienden a ser ambiguas, pues si bien expresiones como el lema de Zorn y otros que veremos más adelante, es también responsable por la \textit{paradoja de Tanach-Barski}, que afirma que un cuerpo sólido puede descomponerse en un número finito de partes para reensamblarse en dos copias idénticas al original.

Más tarde en 1938, Kurt Gödel, famoso por sus teoremas en teorías aritméticas de primer orden, demostró que si ZF es consistente (aún sin demostrar) entonces ZFC también lo es. Esto involucra mucho los \textit{teoremas de incomplitud de Gödel}, que señalan que una teoría matemática es o incompleta (que no toda expresión lógica es afirmable o negable) o inconsistente (que sus expresiones son contradictorias, o que en algún punto una expresión es tanto verdadera como falsa).

Además, Paul Cohen entre 1963 y 1964 demostró que el axioma AC es independiente del resto de la teoría ZF, además demostró que la hipótesis del continuo era indemostrable en ZFC. Esto último ha levantado sospechas sobre la aplicación de ZFC, sugiriendo entre otras cosas, la teoría conjuntivista de Von Neumann-Bernays-Gödel como alternativa efectiva.

Antes de comenzar con las consecuencias del axioma AC, hay que introducir una serie de conceptos básicos para comprender y realizar demostraciones.
\begin{mydef}[Cadena]
Sea $(X,R)$ un conjunto ordenado. Un subconjunto $Y\subseteq X$ es una cadena si $(Y,R|_{Y\times Y})$ es un conjunto \textbf{totalmente} ordenado.
\end{mydef}
\begin{mydef}[Elemento minimal/maximal]
Sea $(X,R)$ un conjunto ordenado, entonces $x$ es un elemento:
\begin{description}
\item[\bf Minimal] Si para todo $y\in X$ tal que $yRx\implies y=x$.
\item[\bf Maximal] Si para todo $y\in X$ tal que $xRy\implies y=x$.
\end{description}
\end{mydef}
Nótese que hay diferencia entre un elemento \textbf{mínimo} y \textbf{minimal}. El primero implica ser un elemento que es comparable con todo $X$ del conjunto (requiere del principio de la comparabilidad), a su vez es un elemento minimal y es único. El segundo es \textit{inferior} con los elementos que es comparable.

Por ejemplo, supongamos que tenemos el conjunto parcialmente ordenado $(\P(X)\setminus\emptyset=Y,\subseteq)$, aquí, para todo $x\in X$ se cumple que $\{x\}$ es minimal en $Y$. De incluir a $\emptyset$, este elemento sería un mínimo.
\begin{mydef}[$\varphi$-torre]
Sea $\mathcal{F}\subseteq\P(X)$, es una $\varphi$-torre con una función $\varphi:\mathcal{F}\rightarrow X$ si cumple con los siguientes axiomas:
\begin{enumerate}[(1)]
\item $\emptyset\in\mathcal{F}$.
\item Si $\{A_i:i\in I\}$ es una cadena de $(\mathcal{F},\subseteq)$ entonces $\bigcup_{i\in I}A_i\in\mathcal{F}$.
\item Si $A\in\mathcal{F}$ entonces $A\cup\{\varphi(A)\}\in\mathcal{F}$.
\end{enumerate}
\end{mydef}
Nótese que en este contexto, $\varphi$ es siempre una función de elección. Sea $\mathcal{G}$ una $\varphi$-torre de $X$ contenida en otra $\mathcal{F}$, entonces se dice que $\mathcal{G}$ es sub-$\varphi$-torre de $\mathcal{F}$. Sea $\{\mathcal{F}_i:i\in I\}$ el conjunto de $\varphi$-torres de $X$, entonces $\mathcal{M}\equiv\bigcap_{i\in I}\mathcal{F}_i$ es la sub-$\varphi$-torre mínima.

Veamos que $\mathcal{M}$ puede tener un mínimo de 2 elementos: $\emptyset$ y $\varphi(\emptyset)$ en caso de que $\varphi\left(\{\varphi(\emptyset)\}\right)=\varphi(\emptyset)$. De lo contrario podemos construir una especie de función recursiva $\Phi_0 = \emptyset$ y $\Phi_{n+1} = \Phi_n\cup\{\varphi(\Phi_n)\}$, tal que, $\mathcal{M}=\{\Phi_i\}_{i\in I}$.

Además, si un elemento $M\in\mathcal{F}$ es totalmente comparable, es decir para todo $M'\in\mathcal{F}$ se cumple $M'\subseteq M$ o $M\subseteq M'$ entonces le llamamos \textit{elemento medio}.
\begin{lem}\label{lem:self-contained-phi-tower}
Sea $\mathcal{M}$ la sub-$\varphi$-torre mínima y $\mathcal{F}$ una $\varphi$-torre de $X$, entonces:
\begin{enumerate}[$a)$]
\item Sea $M\in\mathcal{M}$ elemento medio, entonces para todo $M'\in\mathcal{M}$ se cumple $M'\subseteq M$ o $M\cup\{\varphi(M)\}\subseteq M'$.
\item $\mathcal{M}$ es cadena de $(\mathcal{F},\subseteq)$.
\item Existe un $A\in\mathcal{F}$ tal que $\varphi(A)\in A$.
\end{enumerate}
\end{lem}
\begin{proof}
En general, el enunciado será una especie de lema (¿de segundo grado?) para probar el enunciado $b)$.
\begin{enumerate}[$a)$]
\item Esto se realizará, probando que
$$\mathcal{F}_M=\{M'\in\mathcal{M}:M'\subseteq M\vee M\cup\{\varphi(M)\}\subseteq M'\}$$
es una $\varphi$-torre. Evidentemente se cumplen los principios (1) y (2). Demostraremos el (3), si $M\cup\{\varphi(M)\}\subseteq M'$ entonces es inmediato. Definamos $\overline{M'}\equiv M'\cup\{\varphi(M')\}$, veamos que si $M'\in\mathcal{M}$, entonces $\overline{M'}\in\mathcal{M}$ y por propiedad de ser $M$ medio es comparable con $\overline{M'}$, luego $\overline{M'}\subseteq M$ o $M\subseteq\overline{M'}$, en el segundo caso $M'=M$, cualquiera sea el resultado $\overline{M'}\in\mathcal{F}_M$.
\item Esto equivale a decir que todos los elementos en $\mathcal{M}$ son medios, o que
$$\overline{\mathcal{F}}=\{M\in\mathcal{M}:M\text{ medio}\}$$
es una $\varphi$-torre. Las propiedades (1) y (2) son nuevamente triviales. Supongamos que $M\in\mathcal{M}$ es medio, si $M'\subseteq M$ entonces $M'\subseteq\overline{M}$, de lo contrario, $\overline{M}$ sigue siendo comparable por la propiedad $a)$.
\item Esto equivale a que en $\mathcal{M}$ exista tal $A$. Definamos $A\equiv\bigcup_{M\in\mathcal{M}}M$, entonces, $A$ es máximo en tal conjunto, luego $A\cup\{\varphi(A)\}\in\mathcal{M}$ por axioma (3) de las $\varphi$-torres, por tanto, $\varphi(A)\in A$.
\end{enumerate}
\end{proof}
\begin{thm}
En ZF, son equivalentes:
\begin{description}
\item[\color{thm}\sffamily\itshape Axioma de elección (AC).]
\item[\color{thm}\sffamily\itshape Lema de Zorn (ZL):] Cada conjunto $(X,\leq)$ (parcialmente) ordenado no vacío, con la propiedad de que cada cadena posea cota superior, posee elemento maximal.
\item[\color{thm}\sffamily\itshape Principio maximal de Hausdorff (HMP):] Todo conjunto parcialmente ordenado posee una cadena maximal (respecto a $\subseteq$).
\item[\color{thm}\sffamily\itshape Teorema del buen ordenamiento de Zermelo (WOT):] Todo conjunto admite un buen ordenamiento.
\end{description}
\end{thm}
\begin{proof}
$\rm AC\implies ZL$. Definamos $\mathcal{F}$ como el conjunto de cadenas de $(X,\leq)$, a su vez, para cada $A\in\mathcal{F}$ existe una cota $M_A$ y un conjunto
$$T_A=\{x\in X:(M_A\leq x)\wedge\neg(x\leq M_A)\}.$$
Luego, hay que probar que existe un $A$ tal que $T_A=\emptyset$, para ello supongamos por contradicción que $T_A\neq\emptyset$, luego debe existir una función
$$\varphi:\mathcal{F}\rightarrow\bigcup_{A\in\mathcal{F}}T_A$$
de elección, es decir que $\varphi(A)\in T_A$. Veamos que $\mathcal{F}$ es una $\varphi$-torre. Las propiedades $a)$ y $c)$ son inmediatas, por construcción. La propiedad $b)$ indica que si $\{A_i:i\in I_{n+1}\}$ es una cadena de $(\mathcal{F},\subseteq)$, luego debe existir una biyección $s_i:I_{n+1}\rightarrow I_{n+1}$ tal que $A_{s_0}\subseteq A_{s_1}\subseteq\cdots\subseteq A_{s_n}$, entonces $\bigcup_{i\in I_{n+1}}A_{s_i}=A_{s_n}\in\mathcal{F}$. Por el lema~\ref{lem:self-contained-phi-tower} se tiene que existe $\varphi(A)\in A$, luego $\varphi(A)\leq a_A$, contradicción.

$\rm ZL\implies HMP$. Sea $X$ dicho conjunto, tal que $\mathcal{F}\subseteq\P(X)$ es el conjunto de todas las cadenas de $(X,\leq)$. Luego $\mathcal{C}$ es una cadena de $(\mathcal{F},\subseteq)$, tal que definimos $A=\bigcup_{C\in\mathcal{C}} C$. Veamos que $A$ es cadena de $(X,\leq)$, para ello, consideremos un par $x\in C_1\in\mathcal{C}$ e $y\in C_2\in\mathcal{C}$, como $\mathcal{C}$ es cadena según inclusión de conjuntos podemos suponer que $C_1\subseteq C_2$, por tanto, $x,y\in C_2$, como $C_2$ pertenece a $\mathcal{F}$ es cadena de $(X,\leq)$ y podemos suponer que $x\leq_{C_2}y$, por tanto, $x\leq_A y$. Luego $A\in\mathcal{F}$ y es cota de $\mathcal{C}$, aplicando el lema de Zorn, existe $B\in\mathcal{F}$ que es maximal.

$\rm HMP\implies ZL$. Sea $X$ un conjunto parcialmente ordenado tal que cada cadena posea cota superior. Por HMP existe $M$ cadena maximal y por construcción posee cota superior $m$, luego $M\cup\{m\}$ es cadena, por lo tanto, $m\in M$. Supongamos que existe $x\in X$ tal que $m\leq x$, luego $M\cup\{x\}$ es cadena, luego $x\in M$ y $x\leq m$, es decir, $x=m$, $m$ es maximal.

$\rm ZL\implies WOT$. Recordemos que \textit{buen ordenamiento} equivale a decir que todo conjunto con un orden total, satisface que todo subconjunto posee elemento mínimo. Consideremos $\mathcal{W}$ el conjunto de todos los buenos ordenamientos de $X$. Definimos un orden parcial $\preceq$ tal que para dos pares $(A,\leq_A)$ y $(B,\leq_B)$ en $\mathcal{W}$:
$$(A,\leq_A)\preceq(B,\leq_B)\iff\begin{cases}
A\subseteq B\\
\leq_B\cap(A\times A)=\leq_A\\
\forall a\in A\wedge b\in B\setminus A\;a\leq_B b
\end{cases}$$
Es evidente que $\preceq$ es un orden parcial en $\mathcal{W}$. Sea $C$ una cadena de $(\mathcal{W},\preceq)$. Tal que definimos $E=\bigcup_{C\in\mathcal{C}}C$, donde para un par $x,y\in E$ se cumple $x\leq_E y$ syss $x,y\in C_i\in E$ y $x\leq_{C_i}y$. Veamos que $E$ está bien ordenado, si $A\subseteq E$ podemos ver que si $x\in A$ existe $C_i\in\mathcal{C}$ tal que $x\in C_i$, luego $A\cap C_i$ tiene mínimo por ser $C_i$ bien ordenado, este elemento es mínimo de $A$ por tercera propiedad. Luego $E$ es cota superior de $\mathcal{C}$, aplicando lema de Zorn existe un maximal $\overline{E}$ y probaremos que $X=\overline{E}$. Supongamos, por contradicción, que existe $x_0\in X\setminus\overline{E}$, entonces podríamos definir $E'=\overline{E}\cup\{x_0\}$ bien ordenado, tal que $E'\preceq\tilde{E}$, por tanto, $\overline{E}=E'$.

$\rm WOT\implies AC$. Supongamos que $X$ es una familia de conjuntos sin el conjunto vacío con $\leq$ un buen orden, entonces podemos ver que una función de elección sería considerar el mínimo de cada conjunto contenido en $X$.
\end{proof}
\begin{thm}
Existe $f:A\rightarrow B$ inyectiva syss existe $g:B\rightarrow A$ suprayectiva.
\end{thm}
\begin{proof}
Supondremos que la función no es biyectiva, de lo contrario sería trivial.

Sea $f:A\rightarrow B$ inyectiva, entonces definimos la relación $f^{-1}$, sabemos que no todo $b\in B$ posee preimagen, luego consideremos una función de elección para obtener un $a_0\in A$. Finalmente definimos:
$$g=\begin{cases}
f^{-1}(b), &\text{si posee preimagen}\\
a_0, &\text{si no lo posee}
\end{cases}$$
que es suprayectiva pues como todo $a$ existe $f(a)=b$, entonces existe un $b$ tal que $g(b)=a$.

Sea $f:A\rightarrow B$ suprayectiva, entonces definimos la relación $f^{-1}$, sabemos que para todo $b\in B$ existe al menos una preimagen, luego definimos una función tal que $h(b)=\{a\in A:f(a)=b\}$ y una segunda $i:\{h(b)\}_{b\in B}\rightarrow A$ que es una función de elección. Finalmente $g=h\circ i$ es evidentemente inyectiva pues todo $a$ posee una única imagen $f$.
\end{proof}
Ahora, antes de introducirnos en este profundo y complejo tema que son los cardinales de conjuntos infinitos\footnote{También llamados \textit{cardinales grandes}.}, debemos primero introducir la noción de la clase de \textit{ordinales}.
\begin{mydef}
Diremos que un conjunto $x$ es \textit{transitivo} si todo elemento de él $y\in x$ es subconjunto propio de él, $y\subset x$.

Un \textit{ordinal} es un conjunto bien ordenado (por pertenencia ``$\in$'') que es \textbf{hereditariamente transitivo}, es decir, $x$ es ordinal si es transitivo y todo $y\in x$ también lo es.

Un ordinal será llamado \textit{sucesor} syss posee un elemento maximal por $\in$ (o es el cero), de lo contrario será llamado \textit{límite}.
\end{mydef}
Veamos que, por ejemplo, todo número natural (en forma conjuntivista) es su propio ordenal sucesor, es decir:
\begin{align*}
1&=\{0\}\\
2&=\{0,1\}\\
&\vdots\\
n&=\{0,1,\dots,n-1\}
\end{align*}
Definiremos $\omega_0$ como el primer ordinal límite transfinito\footnote{Se le dice a los números cuyo valor es mayor o igual a $\omega_0$. Se les asigna dicho nombre especial pues no son infinitos en el sentido de que existen números mayores a ellos, pero son más grandes que todos los números ``finitos'' conocidos.}, el cual es equivalente al conjunto de las naturales:
$$\omega_0=\{0,1,2,3,\dots\},$$
luego, podemos definir el primer ordinal sucesor transfinito por medio del siguiente conjunto
$$\omega_0+1=\{0,1,2,\dots,\omega_0\},$$
y notamos que el conjunto de ordinales es, por el momento,
$$0,1,2,\dots,\omega_0,\omega_0+1,\omega_0+2,\dots,\omega_0\cdot 2,\omega_0\cdot 2+1,\dots\omega_0\cdot 3,\dots,\omega_0^2,\dots$$
con $\omega_0\cdot\alpha$ siendo siempre un ordinal límite, para cualquier $\alpha$ ordinal no nulo. Nótese que si seguimos esta secuencia obtendremos aquella de potencias de $\omega_0$ la que tiene como ``límite'':
$$0,\dots,\omega_0,\dots,\omega_0^2,\dots,\omega_0^{\omega_0},\dots,$$
a este número $\omega_0^{\omega_0}\equiv\omega_1$, en general, $\omega_{n+1}=\omega_0^{\omega_n}$.

Entre ordinales definimos operaciones aritméticas por medio de sus representaciones conjuntivistas, por ejemplo, sean $n,m$ ordinales, tales que
$$n=\{0,1,\dots,n-1\},\quad m=\{0,1,\dots,m-1\},$$
luego $n+m$ es un ordinal que representa el conjunto,
$$n+m=\{0,1,\dots,n-1,0',1',\dots,(m-1)'\},$$
como todo ordinal está bien ordenado por <, llegamos a que
$$0<1<\cdots<n-1<0'<1'<\cdots<(m-1)'.$$
Esto es fundamental, pues demuestra que la suma no es conmutativa en todos los casos, y tampoco lo es la multiplicación, por ejemplo, si $n$ es un ordinal finito, $n+\omega_0=\omega_0$, mientras que $\omega_0+n\neq\omega_0$. Asimismo, $2\cdot\omega_0=\omega_0$ y $\omega_0\cdot 2\neq\omega_0$.

Si $x$ es un ordinal, escribiremos $x\in\Or$. De todo lo ya enseñado sacaremos un principio fundamental para las demostraciones siguientes:
\begin{thm}[Principio de inducción transfinita]
Sea $\phi(n)$ una propiedad para los ordinales, funcionará para todo ordinal $\alpha$ syss el que funcione para todo ordinal $\beta\lt\alpha$ implique que funcione para $\alpha$:
\begin{equation}
\forall\alpha\in\Or\;\left(\forall\beta\in\Or\;\beta\lt\alpha\implies\phi(\beta)\right)\implies\phi(\alpha).
\end{equation}
\end{thm}

Similar, pero no igual, definimos los cardinales transfinitos como números $\aleph$ (léase ``álef'') tal que $\aleph_{n+1}$ es el $n$-ésimo cardinal infinito más pequeño de un conjunto bien ordenado. Por lo tanto, $\aleph_0$ es el cardinal infinito más pequeño y le sigue $\aleph_1$. Luego $|\N|=\aleph_0$. Por definición todo $\aleph_\alpha$ equivale a un ordinal, en particular, uno de tipo límite.
\begin{thm}[Paradoja del hotel de Hilbert]
Si $n\in\N$ (y es finito), entonces:
\begin{enumerate}[$a$)]
\item $\aleph_0+n=\aleph_0$.
\item $n\aleph_0=\aleph_0$ (con $n\neq 0$).
\item $\aleph_0^n=\aleph_0$ (con $n\neq 0$).
\end{enumerate}
\end{thm}
\begin{proof}
\begin{enumerate}[$a$)]
\item Veamos que ``sumar'' cardinales requiere de la aplicación del teorema~\ref{thm:card-sum}, por tanto, escogeremos un conjunto $A$ finito y otro $B$ infinito pero enumerable, ambos disjuntos, tales que sus propiedades son probadas por las biyecciones $a:I_n\rightarrow A$ y $b:\N\rightarrow B$, entonces definimos una nueva función
$$f(m)=\begin{cases}
a_m, &0\leq m\lt n\\
b_{m-n}, &\phantom{0\lt}\;m\geq n
\end{cases}$$
que es evidentemente una biyección a $A\cup B$ y demuestra que es enumerable.
\item Supongamos que tenemos $n$ conjuntos $A_0,A_1,\dots,A_{n-1}$ enumerables disjuntos, tales que poseen biyecciones $a_0:\N\rightarrow A_0,\dots,a_{n-1}:\N\rightarrow A_{n-1}$, se demuestra que
$$A=\bigcup_{i=0}^{n-1} A_i$$
es enumerable a través de la función
$$a_m=\begin{cases}
{a_0}_i &m=in\\
{a_1}_i &m=in+1\\
\vdots\\
{a_{n-1}}_i &m=in+(n-1)
\end{cases}$$
Esta función debe pensarse que en cada intervalo $\left[kn,(k+1)n\right)$, donde $k$ es un entero, va tomando todos los valores desde ${a_0}_k$ hasta ${a_{n-1}}_k$ para luego pasar a la siguiente ronda, así es inyectiva y sobreyectiva.
\item Esta demostración la haremos a partir de que $\aleph_0^2=\aleph_0$, de forma que luego, las potencias finitas serán sólo el resultado de la multiplicación binaria del mismo cardinal cuyo resultado ya se ha demostrado ser $\aleph_0$.

Esta demostración será un tanto complicada: primero comenzamos por tomar dos conjuntos enumerables $A,B$ con biyecciones $a:\N\rightarrow A,b:\N\rightarrow B$, luego definimos $c_{i,j}=(a_i,b_j)$. Consideremos la función $K_m(n)=c_{n,m-n}$, además de la serie estricta creciente
$$S(n)=\sum_{i=0}^n i,$$
de forma que finalmente, nuestra función inyectiva es
$$f(n)=K_j(n-S(j)):S(j)\leq n\lt S(j+1).$$
Veamos esto a través de un ejemplo, como para $n=0$, nótese que $S(0)=0\lt S(1)=1$ de forma que $f(0)=K_0(0)=c_{0,0}$; para $n=1$ se da que $S(1)=1\lt S(2)=3$ de forma que $f(1)=K_1(0)=c_{0,1}$; para $n=2$ se da que $S(1)\lt 2\lt S(2)$ tal que $f(2)=K_1(1)=c_{1,0}$ y así sucesivamente. El método descrito es una formalización de las diagonales de Cantor.
\end{enumerate}
\end{proof}
Nótese que se puede generalizar para todo $r$ real (finito y apreciable) con el uso de desigualdades, por ejemplo, como la propiedad arquimediana para la suma, la multiplicación se puede demostrar a través de la igualdad
$$a\aleph_0=b\aleph_0\implies \frac{a}{b}\aleph_0=\aleph_0,$$
y nótese que para todo $r$ real (finito y apreciable) existen $p,q$ racionales tales que $p\leq r\lt q$. La potencia es análoga.

Aquí, la parte más importante, es la parte $c$), pues ella abre paso al siguiente corolario:
\begin{cor}
Los enteros $\Z$ y los racionales $\Q$ son enumerables.
\end{cor}
\begin{proof}
Veamos que según nuestra construcción, tanto los enteros como los racionales son conjuntos de pares ordenados de $\N^2$, en particular son \textit{cortes} o \textit{particiones}, lo que significa que si un par aparece en un entero o racional $r$ no aparecerá en ningún otro. Veamos que debido a esto sabemos que el máximo número de particiones es al crear crear conjuntos con un sólo par dentro, de forma que poseería el mismo cardinal que $\N^2$, el mínimo cardinal es 1, pues sería el conjunto $\{\N^2\}$, es decir que $1\leq|\Z|,|\Q|\leq\aleph_0$. Sabemos que $\Z$ y $\Q$ son infinitos, por tanto, deben ser enumerables.

Si se quiere otra prueba, puede notarse que $\Z=2\aleph_0=\aleph_0$, y para $\Q$ puede utilizar las diagonales de Cantor.
\end{proof}
Pero por el momento todos los conjuntos parecen ser enumerables, ¿hay conjuntos no-numerables en primer lugar? Pues si que los hay, pero deben de ser gigantescos y no tan fáciles de encontrar. Nuestro primer ejemplo será el conjunto potencia de un enumerable, pues:
\begin{thm}[Teorema (conjuntivista) de Cantor]
Sea $A$ un conjunto (finito o no), no existe relación alguna $f:A\rightarrow\P(A)$ tal que sea biyectiva. En particular $|A|\lt|\P(A)|$.
\end{thm}
\begin{proof}
Supongamos, por contradicción que existe $f:A\rightarrow\P(A)$ tal que es biyectiva, sin embargo, podemos construir un conjunto
$$B=\{a\in A:a\notin f(a)\}$$
Por otro lado podemos ver que $f(a)=\{a\}$ es una función inyectiva, de forma que se demuestra que $|A|\lt|\P(A)|$.
\end{proof}
\begin{thm}
Supongamos que $|A|=n$ sea finito, entonces $|\P(A)|=2^n$.
\end{thm}
\begin{proof}
Veamos que se puede demostrar con inducción:

Si $|A|=0$ entonces $A=\emptyset$ y $\P(A)=\{\emptyset\}$.

Si $|A|=n$ por hipótesis $|\P(A)|=2^n$, ahora definamos $B=A\cup\{b\}$ donde $b\notin A$, vemos que $\P(A)\subset\P(B)$, supongamos que $\P(A)=\{P_1,P_2,\dots\}$, sabemos que para todo $i$ se cumple $b\notin P_i$, ahora construiremos un conjunto $\P'(A)=\{P_1\cup\{b\},P_2\cup\{b\},\dots\}$ con cardinal $2^n$ y vemos que $\P(B)=\P(A)\cup\P'(A)$, como son disjuntos $\P(B)=2^n+2^n=2\cdot2^n=2^{n+1}$.
\end{proof}
Utilizando ambos teoremas podemos ver que $\P(\N)$ es no-numerable, y posee cardinal $2^{\aleph_0}\equiv\aleph_1$.
\begin{thm}
$$|\R|=\aleph_1.$$
\end{thm}
\begin{proof}
Para esta prueba demostraremos que existen inyecciones $f:\R\rightarrow A$ (1) y $g:B\rightarrow\R$ (2) donde $A,B$ poseen cardinales $\aleph_1$.
\begin{enumerate}[(1)]
\item Sea $A=\P(\Q)$, vemos que la función
$f(r)=\{q\in\Q:r\leq q\},$
es inyectiva; si $r\notin\Q$ sabemos que el conjunto carecerá de mínimo.
\item Sea $B=\{0,2\}^\N$ (el conjunto de todas las secuencias con los elementos $0$ o $1$), sabemos que una sucesión $s=(s_1,s_2,\dots)\in B$, luego definimos la función
$$g(s)=\sum_{i=1}^\infty s_i 3^{-i}$$
que es evidentemente inyectiva.
\end{enumerate}
Finalmente por el teorema de Cantor-Schröder-Bernstein queda demostrado.
\end{proof}
Cabe destacar que la función utilizada en el paso (2) está inspirada en el conjunto de Cantor que es aquel tal que para $f(0)=[0,1]$, luego en cada $f(n+1)$ se le quita el tercio central a los intervalos restantes. La función esencialmente toma el cota inferior de cada intervalo con cada nuevo término, denotaremos los posibles valores de dicha función con un punto lleno y aquellos que no son posibles (al menos no con dicha cantidad de términos) con un punto vacío (ver fig.~\ref{fig:cantor-set}).
\begin{figure}
\centering
\begin{tikzpicture}
\draw[|-|] (0,0) node[left]{0} -- (9,0) node[right]{1};
\draw[nicered,very thick] (0,0) -- (3,0) (6,0) -- (9,0);
\fill[nicered] (0,0) circle (.075) (6,0) circle (.075);
\filldraw[fill=white,draw=nicered,very thick] (3,0) circle (.075) (9,0) circle (.075);
\begin{scope}[shift={(0,-.75)}]
\draw[|-|] (0,0) node[left]{0} -- (9,0) node[right]{1};
\draw[nicered,very thick] (0,0) -- (1,0) (2,0) -- (3,0) (6,0) -- (7,0) (8,0) -- (9,0);
\fill[nicered] (0,0) circle (.075) (2,0) circle (.075) (6,0) circle (.075) (8,0) circle (.075);
\filldraw[fill=white,draw=nicered,very thick] (1,0) circle (.075) (3,0) circle (.075) (7,0) circle (.075) (9,0) circle (.075);
\end{scope}\begin{scope}[shift={(0,-1.5)}]
\draw[|-|] (0,0) node[left]{0} -- (9,0) node[right]{1};
\draw[nicered,very thick] (0,0) -- (1/3,0) (2/3,0) -- (1,0) (2,0) -- (7/3,0) (8/3,0) -- (3,0) (6,0) -- (19/3,0) (20/3,0) -- (7,0) (8,0) -- (25/3,0) (26/3,0) -- (9,0);
\fill[nicered] (0,0) circle (.075) (2/3,0) circle (.075) (2,0) circle (.075) (8/3,0) circle (.075) (6,0) circle (.075) (20/3,0) circle (.075) (8,0) circle (.075) (26/3,0) circle (.075);
\filldraw[fill=white,draw=nicered,very thick] (1/3,0) circle (.075) (1,0) circle (.075) (7/3,0) circle (.075) (3,0) circle (.075) (19/3,0) circle (.075) (7,0) circle (.075) (25/3,0) circle (.075) (9,0) circle (.075);
\end{scope}
\end{tikzpicture}
\caption{Conjunto y función de Cantor.}
\label{fig:cantor-set}
\end{figure}

Para finalizar, veamos que el último teorema indica que los reales son no-numerables, de ahora en adelante llamaremos a los conjuntos de cardinal $\aleph_1$ como \textit{continuos}; pero tal vez, e inclusive aún más impresionante es la siguiente propiedad:
\begin{thm}
Todo intervalo abierto $(a,b)$ en los reales es continuo.
\end{thm}
\begin{proof}
Esencialmente lo que nos pide el enunciado es demostrar que existe una función que es biyectiva entre algún conjunto continuo y un intervalo abierto cualquiera, en particular veremos una biyección $f:\R\rightarrow(a,b)$ a la que llamaremos la \textit{proyección psuedo-estereográfica} (veremos más adelante a que se refiere). Definamos un centro $o=\frac{a+b}{2}$ y un radio $r=\frac{b-a}{2}$. Entonces en el punto $o$ de nuestra recta real construiremos un semicírculo con centro $(o,r)$, en el punto $(a,r)$ escribiremos el valor $a$ y en el punto $(b,r)$ el valor $b$ de forma que la sección angular es el intervalo querido. La función es así, considera un real $x$, trazamos una línea desde $(x,0)$ hasta $(o,r)$, el valor obtenido será aquel en el intervalo semicircular cortado.
\begin{figure}
\centering
\begin{tikzpicture}[scale=1.33]
\draw[<->] (-3,0) -- (3,0);
\draw[nicered,thick] (0,1) arc (-180:0:1) (0,0) -- (2,0);
\draw[nicered,dashed] (0,1) -- node[above]{$r$} (1,1) -- node[above]{$r$} (2,1) (1,0) -- (1,1);
\draw (-2,0) node[below]{$x$} -- (1,1);
\fill[nicered] (1,0) circle (.05) node[below]{$o$} (1,1) circle (.05) ++({atan(-3)-90}:1) circle (.05)  (-2,0) circle (.05);
\filldraw[fill=white,draw=nicered,very thick] (0,0) circle (.05) node[below]{$a$} (2,0) circle (.05) node[below]{$b$} (0,1) circle (.05) node[above]{$a$} (2,1) circle (.05) node[above]{$b$};
\end{tikzpicture}
\caption{Proyección pseudo-estereográfica.}
\end{figure}
\end{proof}
Finalmente veamos unas propiedades curiosas del cardinal del continuo y otros infinitos:
\begin{thm}
Dado un par de cardinales $\mu,\kappa$ no-nulos con alguno infinito, entonces
\begin{align*}
\kappa+\mu&=\max\{\kappa,\mu\}\\
\kappa\cdot\mu&=\max\{\kappa,\mu\}
\end{align*}
\end{thm}
\begin{proof}
Supongamos que $\kappa\geq\mu$ con $\kappa$ infinito, 
\end{proof}
\begin{thm}
Defínase la siguiente proposición:
\begin{description}
\item[\color{thm}\itshape\sffamily Hipótesis del continuo generalizada (GCH):] Para todo conjunto infinito $A$ no existe un conjunto $B$ tal que
$$|A|\lt|B|\lt|\P(A)|.$$
\end{description}
Veremos que $\rm GCH\implies AC$.
\end{thm}
Esta demostración es bastante larga y requiere de una serie de teoremas y lemas de antemano, de manera que, como no la requerimos en estricto rigor en nuestro curso de análisis la ignoraremos, por lo que recomiendo consultar el artículo \url{http://math.bu.edu/people/aki/7.pdf} para más información.

Veamos que GCH es indemostrable en ZFC, su ``independencia'' fue probada por Gödel y Cohen en el siglo XX (demostrando que ZFC es consiste con GCH y con su contradicción). Para tener una teoría donde fuese un teorema, deberíamos trabajar en la teoría de Von Neumann-Bernays-Gödel (NBG) dónde se introduce la noción de \textit{clase} que refiere a conjuntos que no pueden estar contenidos en otros conjuntos. Las ventajas de NBG son tremendas, se puede demostrar la existencia de clases como un universo (conjunto que contiene todo), la de los no-estándar y la de los ordinales; además es finitamente axiomatizable, sin embargo, sus esquemas son mucho más complejos y formales, sin mencionar la popularidad de ZFC.

\part{Cálculo de una variable}
\chapter{Topología}
Es difícil introducir a alguien al mundo de la topología, podemos describir la aritmética como la parte de las matemáticas dedicadas a la descripción discreta de propiedades sobre números enteros, el álgebra como la generalización de la aritmética y la inclusión de las funciones, la geometría como el estudio de propiedades sobre puntos, y el análisis como un poco de todo ello para lograr la deducción de herramientas más potentes en técnicas numéricas generales, como la derivada o la integral. La topología consiste en el estudio de las propiedades de cuerpos ante transformaciones, es decir, podemos ver que es una ramificación de la geometría, pero más abstracta.

Para poder aproximar al lector al concepto de topología recomiendo ver alguna demostración sencilla en esta rama como, por ejemplo, una de las cuatro formas de dar vuelta una esfera desde dentro hacia afuera o como un torus (donut o rosquilla) es equivalente a una taza, aun que esta última es la mayor parte del tiempo tomada como una broma entre matemáticos más que una bella demostración de la potencia de la topología por si misma.

La topología, si bien un tanto desconocida, puede llamarle la atención a los jóvenes matemáticos, al igual que el cálculo, corresponde a una idea bastante reciente y quienes la impulsan son conocidos científicos que, a su vez, impulsan herramientas potentes del cálculo a su paso. Su origen puede trazarse a G. Leibniz, aun que el primero en utilizar dicho nombre y reconocerlo como una nueva rama de las matemáticas es J. Listing; L. Euler fue quién pone de moda el tema con la elegante solución al problema de los puentes de Königsberg, quién rápidamente inspiró a A. Lhulier; A. Möbius es quién descubre tal vez el cuerpo más conocido de la topología (la banda de Möbius), aun que el más exótico definitivamente es la botella de F. Klein, a todo esto le agregamos el aporte de las superficies de B. Riemann. Esto corresponde a un breve repaso sobre la historia de la topología, probablemente alguno de estos matemáticos le suene al lector, y sino, lo invitamos a leer sobre estos descubrimientos para \textit{agarrarle el gusto} y motivarse con las páginas que le siguen.

Como nota adicional, recomiendo fuertemente que si le cuesta revise las lecturas de Frederic Schuller en el tema, puede encontrar su videos en la web y son perfectamente entendibles con las propiedades demostradas hasta ahora.

\section{Espacios topológicos}
\begin{mydef}[Espacio normado]
Sea $E$ un espacio vectorial sobre un espacio métrico $M$ con $u,v\in E$ y $\alpha\in M$, definimos una norma como una aplicación $\Vert\;\Vert:E\rightarrow [0,\infty)$ que satisface los siguientes axiomas:
\begin{enumerate}[(1)]
\item $\Vert v\Vert=0\iff v=0$.
\item $\Vert u+v\Vert\leq\Vert u\Vert+\Vert v\Vert$.
\item $\Vert\alpha v\Vert=|\alpha|\Vert v\Vert$.
\end{enumerate}
Todo espacio métrico puede definir su distancia como $d(u,v)=\Vert u-v\Vert$.
\end{mydef}
En particular se destaca la norma $L_p$ para $\R^n$ la cual define
$$\Vert\vec{v}\Vert_p=\sqrt[p]{\sum_{i=0}^n|x_i|^p},$$
por lo cuál, vemos los casos discretos $\Vert\vec{v}\Vert_1=\sum_{i=0}^n|x_i|$ (norma del plano de taxi), $\Vert\vec{v}\Vert_2=\sqrt{\sum_{i=0}^n|x_i|^2}$ (norma del plano euclideo) y $\Vert\vec{v}\Vert_\infty=\max\{x_i\}_{i=0}^n$.

Además existe una función distancia muy popular llamada \textit{distancia discreta} que es aquella tal que:
$$d(x,y)=\begin{cases}
0, &x=y\\
1, &x\neq y
\end{cases}$$
\begin{mydef}[Bolas]
Sea $M$ un espacio métrico, $x\in M$ y $\epsilon\gt 0$ se define
$$B_\epsilon(x)=\{y\in M:d(x,y)\lt\epsilon\},\quad B'_\epsilon(x)=\{y\in M:d(x,y)\leq\epsilon\},$$
donde $B_\epsilon(x)$ es una bola abierta y $B'_\epsilon(x)$ una bola cerrada, ambas de centro $x$ y radio $\epsilon$.
\end{mydef}
A la hora de graficar bolas en un plano $\R^2$ utilizaremos una linea punteada para graficar las bolas abiertas. En $\R$ una bola abierta se dibuja con un punto blanco en los extremos (como con los cortes estrictos) y puntos coloreados en las cerradas.
\begin{figure}
\centering
\begin{subfigure}{.55\textwidth}
\centering
\begin{tikzpicture}[scale=3]
\draw[<->] (.5,0) -- (2.5,0) node[above right]{$\R$};
\draw[very thick,nicered] (1,0) -- (2,0);
\filldraw[thick,draw=nicered,fill=white] (1,0) circle (.023) (2,0) circle (.023);
\fill[nicered,thick] (1.5,0) circle (.023) node[below]{$x$};
\draw[|->|] (1.5,.1) -- node[fill=white]{$\epsilon$} ++(.5,0);
\end{tikzpicture}
\caption{Bola abierta en $\R$.}
\end{subfigure}
\begin{subfigure}{.4\textwidth}
\centering
\begin{tikzpicture}[scale=1.5]
\filldraw[very thick,dashed,draw=niceorange,fill=niceorange!75] (0,0) circle (1);
\filldraw[very thick,draw=nicered,fill=nicered!75] (0,-1) -- (1,0) -- (0,1) -- (-1,0) -- cycle;
\draw[<->] (-1.2,0) -- (1.2,0) node[right]{$x$};
\draw[<->] (0,-1.2) -- (0,1.2) node[right]{$y$};
\end{tikzpicture}
\caption{La naranja es una bola abierta con $\Vert\;\Vert_2$, la roja es cerrada con $\Vert\;\Vert_1$; ambas en $\R^2$.}
\end{subfigure}
\caption{Bolas topológicas}
\end{figure}
\begin{mydef}[Espacio topológico]
Es un par ordenado $(X,\tau)$, donde $\tau$ es un conjunto de subconjuntos de $X$ tal que sus elementos son llamados \textit{abiertos} y satisface las propiedades:
\begin{enumerate}[(1)]
\item $\emptyset,X\in\tau$.
\item $S\subseteq\tau\implies \bigcup S\in\tau$.
\item $U,V\in\tau\implies U\cap V\in\tau$.
\end{enumerate}
Usualmente, llamaremos \textit{espacio topológico} a $X$ y \textit{topología} (o \textit{estructura topológica}) a $\tau$.
\end{mydef}
Quiero darme un rato para explicar el axioma (2) de los espacios topológicos, si $S$ es subconjunto de $\tau$ entonces posee elementos arbitrarios de $\tau$, por tanto, se puede interpretar como que la unión (finita o no) de elementos de $\tau$ es también contenido en $\tau$. En cambio el axioma (3), hace referencia a una intersección finita.

Nótese que $\{\emptyset,X\}$ es una topología, llamada \textit{trivial} o \textit{caótica}. Además, sabemos que $\P(X)$ es también una topología, llamada \textit{discreta}.
\begin{thm}
Sea $(M,\tau)$ un espacio topológico y sea $N\subset M$, definimos
$$\tau_N=\{U\cap N:U\in\tau\},$$
tal que es una topología en $N$.
\end{thm}
\begin{proof}
$\emptyset,N\in\tau_N$ es trivial. Para el segundo axioma utilizaremos el hecho de que $\tau\subseteq\P(M)$, por tanto, tomemos $U\subseteq\P(N)\subset\P(M)$ de forma que $\bigcup U\in\tau$ y $\bigcup U\subseteq N$, de forma que $\bigcup U\in\tau_N$. El tercer axioma consiste en ver que si $U,V\in\tau$ entonces $U\cap V\in\tau$, luego $(U\cap V)\cap N\in\tau_N$ y $(U\cap V)\cap N=(U\cap N)\cap(V\cap N)$.
\end{proof}
Puede notar que la noción de ``ser abierto'' depende exclusivamente de la topología, pero podemos hacer el proceso al revés, definir el ``ser abierto'' para obtener la topología. Diremos que un espacio métrico $M$ posee un subconjunto abierto $G\subset M$ si para todo $x\in G$ existe al menos un $\epsilon\gt 0$ tal que $B_\epsilon(x)\subset G$. Nótese que para todo espacio métrico $M$, podemos definir una topología $\tau$ que consista en sus subconjuntos abiertos, le llamamos \textit{topología inducida por la métrica}.
\begin{figure}
\centering
\begin{tikzpicture}[dashed,body]
\filldraw[rounded corners=25pt] (0,2.1) -- ++(-2,.1) -- ++(-1.6,-1.8) -- (-3,-1) -- (0,-1.2) -- (3,0) -- ++(.5,1.5) -- ++(-1.5,1.7) node[niceorange,above]{$G$} -- cycle;
\filldraw (2,2.5) circle (.3);
\end{tikzpicture}
\caption{Demostración de un conjunto abierto.}
\end{figure}
\begin{mydef}[Conjunto cerrado]
Sea $X$ un espacio topológico, diremos que un subconjunto $G\subseteq X$ de él es \textit{cerrado} syss, su complemento $\complement_X G$ es abierto, es decir, pertenece a la topología de $X$.
\end{mydef}
Bajo esta definición se nota que $[a,b]$, $[a,b)$ y $(a,b]$ no son abiertos (en la topología inducida por la métrica), en los primeros dos se confirma puesto que no existe $\epsilon\gt 0$ tal que $B_\epsilon(a)$ sea su subconjunto, para el tercero lo mismo pero en el punto $b$. Luego, podemos ver que $[a,b]$ es cerrado, pero $[a,b)$ y $(a,b]$ no son ni abiertos ni cerrados.
\begin{thm}
Las bolas abiertas son conjuntos abiertos.
\end{thm}
\begin{proof}
Sea $B_\epsilon(x)$ una bola cualquiera, tomemos un punto $y$ contenido en si mismo, por definición $d(x,y)\lt\epsilon$, luego $0\lt\delta\lt\epsilon-d(x,y)$ y procedemos a demostrar que $B_\delta(y)\subset B_\epsilon(x)$. Consideremos un $z\in B_\delta(y)$, por definición, $d(y,z)\lt\delta$, luego $d(x,z)\leq d(x,y)+d(y,z)\lt\epsilon$, por tanto, $z\in B_\epsilon(x)$.
\end{proof}
\begin{thm}
Sea $X$ un espacio topológico:
\begin{enumerate}[$a$)]
\item $\emptyset,X$ son cerrados.
\item La intersección de cerrados es un cerrado.
\item La unión finita de cerrados es un cerrado.
\end{enumerate}
\end{thm}
\begin{proof}
La $a$) es trivial y el resto derivan de las siguientes reglas: $\complement_X G=X\setminus G$, $X\setminus(A\cup B)=(X\setminus A)\cap(X\setminus B)$ y $X\setminus(A\cap B)=(X\setminus A)\cup(X\setminus B)$.
\end{proof}
Aquí, sin embargo, hay un problema, ¿qué ocurriría si $X$ fuera un espacio arbitrario, sin una función distancia definida? Entonces, el concepto de ``bola abierta'' carecería de sentido y no podríamos hablar de conjuntos abiertos. Para arreglar esta problemática introduciremos otro concepto:
\begin{mydef}[Base]
Una base para una topología en $X$ es un conjunto $\mathcal{B}$ tal que:
\begin{enumerate}[(1)]
\item Para todo $x\in X$ existe $B\in\mathcal{B}$ tal que $x\in B$.
\item Si existen $B_1,B_2\in\mathcal{B}$ tal que $x\in B_1\cap B_2$ entonces existe un $B_3\in\mathcal{B}$ tal que $x\in B_3\subset B_1\cap B_2$.
\end{enumerate}
Los elementos de una base se llaman \textit{básicos}.
\end{mydef}
Entonces un subconjunto $U$ de $X$ es ``abierto'' si para todo $x$ existe un básico que es un subconjunto proprio de $U$ que lo contenga. De igual manera, podemos definir una topología que consista en todos los subconjuntos abiertos de $X$, a esta le llamamos \textit{topología inducida por la base}.
\begin{figure}
\centering
\begin{tikzpicture}[dashed,very thick]
\begin{scope}[opacity=.5]
\fill[nicered] (0,0) circle (2);
\fill[niceblue] (45:2) circle (1);
\fill[nicepurple] (45:1.5) circle (.45);
\end{scope}
\draw[nicered] (0,0) circle (2) ++(135:2.2) node{$B_1$};
\draw[niceblue] (45:2) circle (1) ++(45:1.2) node{$B_2$};
\draw[nicepurple] (45:1.5) circle (.45) ++(45:.65) node{$B_3$};
\fill (45:1.5) circle (.05) node[below]{$x$};
\end{tikzpicture}
\caption{Axiomas para una base cuyos elementos son bolas abiertas.}
\end{figure}

Observese que podríamos definir una base $\mathcal{B}=\{\{x\}:x\in X\}$ en cuyo espacio topológico todo conjunto sería abierto \textbf{y} cerrado (advertencia: que un conjunto sea abierto no implica que sea cerrado, ambos conceptos son independientes uno de otro).
\begin{thm}\label{thm:topological-bases}
Sea $(X,\tau)$ un espacio topológico inducido por una base $\mathcal{B}$:
\begin{enumerate}[$a$)]
\item Entonces $\tau$ es igual a todas las posibles uniones en $\mathcal{B}$.
\item Sea $\mathcal{C}$ un conjunto de conjuntos abiertos de $X$ tal que para todo abierto $U\in X$ se cumpla que para todo $x\in U$ exista $C\in\mathcal{C}$ tal que $x\in C\subset U$, entonces $\mathcal{C}$ es la base de $\tau$.
\end{enumerate}
\end{thm}
\begin{proof}
\begin{enumerate}[$a$)]
\item Por definición, todo abierto $G\in\tau$ satisface que para todo $x\in G$ existe una base $B_x$ tal que $x\in B_x\subset G$, por tanto, $G=\bigcup\{B_x:x\in G\}$.
\item Veamos que el primer axioma de la base esta cumplido, mientras que el segundo es instantaneo puesto que si $x\in C_1\subset U$ y $x\in C_2\subset V$ con $U,V\in\tau$, $x\in C_1\cap C_2\subset U\cap V$ como $C_1,C_2\in\tau$ (construcción) $C_1\cap C_2\in\tau$ por tanto $x\in C_3\subset C_1\cap C_2$.
\end{enumerate}
\end{proof}
Nótese que por el teorema~\ref{thm:topological-bases}~(a) todo básico es abierto.

Cabe destacar que la topología inducida por la métrica es aquella inducida por la base que contiene a todas las bolas abiertas en $M$.
\begin{mydef}[Vecinidad o entorno]
Sea $x\in X$, diremos que $U$ es una vecinidad o entorno de $x$ si existe un abierto $G$ tal que $x\in G\subset U$.
\end{mydef}
Veamos que por esta definición todos los elementos $x$ de un abierto $G$ poseen al menos un entorno $x\in U\subset G$.
\begin{thm}
Sea $X$ un espacio toplógico y $E_x$ una colección de entornos abiertos de $x$, entonces $\mathcal{B}=\bigcup_{x\in X}E_x$ es una base de $\tau$.
\end{thm}
\begin{proof}
Veamos que (1) es trivial, puesto que para todo $x\in X$, existe un entorno abierto tal que $x\in U$ y $U\in E_x\subseteq\mathcal{B}$. Supongamos que $z\in U_x\cap U_y$ (donde $U_x,U_y$ son entornos abiertos cualesquiera de $x$ e $y$ respectivamente), como son abiertos la intersección es abierta y por tanto existe un básico tal que $z\in B\subset U_x\cap U_y$, como $B$ es abierto existe al menos un entorno $U_z$ tal que $z\in U_z\subset B$.
\end{proof}
\begin{mydef}[Subbase]
$\mathbb{S}$ es una subbase del espacio topológico $X$ si todas las posibles intersecciones finitas de sus elementos conforman una base de $X$.
\end{mydef}
\begin{thm}
Sea $S$ una colección de subconjuntos de $X$, entonces existe una única topología para la cuál $S$ es subbase.
\end{thm}

\section{Subespacios y otras definiciones}
\begin{mydef}[Proyección]
Sea $X$ el producto cartesiano $X=X_1\times\cdots\times X_n=\prod_{i=1}^n X_i$, definimos la función proyección $p_i:X\rightarrow X_i$ tal que a cada vector $\vec{v}$ (o punto) le otorga su $i$-ésima coordenada, que denotaremos como $p_i(\vec{v})=v_i$. Llamaremos $p_i^{-1}[G]$ al conjunto preimagen tales que sus proyecciones en el eje $x_i$ son elementos del abierto $G$.
\end{mydef}
Un ejemplo discreto sería considerar el plano $\R^2$ y considerar $p_1^{-1}[(1,2)]$.
\begin{figure}
\centering
\begin{tikzpicture}[scale=1.75]
\begin{scope}[draw=nicered,fill=nicered!50,very thick]
\fill (1,-.5) -- (1,3) -- (2,3) -- (2,-.5) -- cycle;
\draw[dashed] (1,-.5) -- (1,3) (2,-.5) -- (2,3) node[nicered,right]{$p_1^{-1}[(1,2)]$};
\end{scope}
\draw[->] (-.5,0) -- (3,0) node[right]{$x$};
\draw[->] (0,-.5) -- (0,3) node[right]{$y$};
\draw[very thick,nicered] (1,0) -- (2,0);
\filldraw[very thick,draw=nicered,fill=white] (1,0) circle (.05) node[below left]{1} (2,0) circle (.05) node[below right]{2};
\end{tikzpicture}
\caption{Gráfico de la proyección.}
\end{figure}
\begin{thm}
Sea $X=\prod_{i=1}^n X_i$ un producto cartesiano, tal que $\{X_i\}_{i=1}^n$ son espacios topológicos de bases $\mathcal{B}_i$ respectivamente, entonces
$$\mathcal{B}=\left\{\prod_{i=1}^n B_i:B_i\in\mathcal{B}_i\right\}$$
es una base de $X$.
\end{thm}
\begin{proof}
Consideremos un punto $\vec{r}=(x_1,\dots,x_n)$, como $\mathcal{B}_i$ son bases, existen $U_i\in\mathcal{B}_i$ tal que $x_i\in U_i$, por tanto, definimos $U=\prod_{i=1}^n U_i$ tal que $\vec{r}\in U$. El segundo axioma es igualmente simple, consideremos $\vec{r}\in U\cap V$, entonces existe un $W=\prod_{i=1}^n W_i$ tal que $x_i\in W_i\subset U_i\cap V_i$ que satisface que $\vec{r}\in W\subset U\cap V$.
\end{proof}
\begin{thm}
Sea $Y$ un subconjunto de un espacio topológico $X$, entonces definimos
$$\tau_Y=\{G\cap Y:G\in\tau\}$$
como la \textit{topología del subespacio $Y$}.
\end{thm}
\begin{proof}
Veamos que $\tau_Y$ sea efectivamente una topología, el primer axioma es trivial pues $X\cap Y=Y$ y $\emptyset\cap Y=\emptyset$. Supongamos un $C\subseteq\tau_Y$, entonces debe existir un $D\subseteq\tau$ tal que $C=\{G\cap Y:G\in D\}$, luego $\bigcup C=\left(\bigcup D\right)\cap Y\in\tau_Y$ porque $\bigcup D\in\tau$. El tercer axioma igual es sencillo puesto que si $U,V\in\tau$ entonces $(U\cap Y),(V\cap Y)\in\tau_Y$, como $U\cap V\in\tau$ ocurre que $(U\cap V)\cap Y\in\tau_Y$ y $(U\cap Y)\cap(V\cap Y)=(U\cap V)\cap Y$.
\end{proof}
\begin{cor}
Sea $Y$ subespacio de un espacio topológico $X$. Si $U$ es abierto en $Y$ e $Y$ es abierto en $X$, entonces $U$ es abierto en $X$.
\end{cor}
\begin{proof}
Es trivial puesto que por construcción $Y\in\tau$ y $U\in\tau_Y\implies U=G\cap Y:G\in\tau$, como $Y$ es abierto, la intersección es también abierta, por tanto $U\in\tau$.
\end{proof}
\begin{thm}
Sean $A$ subespacio de $(X,T)$ y $B$ subespacio de $(Y,\tau)$, entonces la topología producto de $A\times B$ es la misma que la topología subespacio de $(X\times Y,t)$.
\end{thm}
\begin{proof}
Los elementos de $T_A$ son $U\cap A$ y los de $\tau_B$ son $V\cap B$. Por otra parte, los elementos de $t_{A\times B}$ son $(U\times V)\cap(A\times B)$, sin embargo
$$(U\times V)\cap(A\times B)=(U\cap A)\times(V\cap B),$$
por lo tanto, ha quedado demostrado.
\end{proof}
\begin{thm}
Sea $X$ un espacio topológico con subespacios $A$ y $B$ tales que $A\subseteq B$, entonces $\tau_A=(\tau_B)_A$.
\end{thm}
\begin{proof}
Veamos que si $U\in\tau_A\implies U=G\cap A:G\in\tau$. Como $A\subseteq B$ entonces $A\cap B=A$, entonces $U=G\cap(A\cap B)=(G\cap B)\cap A$.
\end{proof}
\begin{mydef}[Clausura e interior]
Sea $A$ subconjunto de un espacio topológico $X$, se define el \textit{interior} de $A$ como la unión de todos los subconjuntos abiertos de $A$ (abiertos según $\tau$, no $\tau_A$), lo denotaremos como $\Int A$ y la clausura se define como la intersección de todos los superconjuntos cerrados de $A$, la denotaremos como $\overline{A}$.

Los puntos contenidos en $\Int A$ se llaman \textit{interiores} en $A$, mientras que los contenidos en $\overline{A}$ son \textit{adherentes} en $A$.
\end{mydef}
Consideremos el espacio topológico $\R$ inducido por la métrica $d(x,y)=|x-y|$, aquí vemos que $\Int(0,1]=(0,0)$ y $\overline{(0,1]}=[0,1]$.

Antes de escribir nuestro teorema involucrando clausura, debemos hacer una breve definición: diremos que dos conjuntos $A$, $B$ se intersectan cuando $A\cap B\neq\emptyset$.
\begin{thm}
Sea $A$ subconjunto del espacio topológico $X$. Todo punto adherente a $A$ es aquel tal que todos sus entornos intersectan a $A$.
\end{thm}
\begin{proof}
Veamos que este teorema afirma equivalencia entre pertenecer a $\overline{A}$ y poseer entornos que le intersecten, por tanto, demostraremos esta relación lógica a través de su negación. Si $x\notin\overline{A}$ entonces $x\in U=\complement_X\overline{A}$ donde $U$ es un entorno de $x$ que no intersecta a $A$ (como se quería). Recíprocamente, si existe algún entorno $U\supset G$ donde $G$ es un abierto que posee a $x$, entonces $\complement_X G$ es un cerrado superconjunto de $A$ y, por definición, de $\overline{A}$, mostrando que $x\notin \overline{A}$.
\end{proof}
Otra forma de describir esto es a través de la introducción de un nuevo concepto:
\begin{mydef}[Punto de acumulación]
Sea $S$ un subconjunto de un espacio topológico $X$, decimos que un $x$ es un \textit{punto límite}, \textit{de acumulación} o \textit{de acoplación} si todo entorno de $x$ posee al menos un elemento de $S$ diferente de $x$. Definimos también el \textit{conjunto derivado de $S$} como aquel que posee todos sus puntos límite, lo denotaremos como $S'$.
\end{mydef}
Nótese que el límite de una secuencia convergente es un punto de acumulación de la imagen de la secuencia.
\begin{thm}
$$\overline{A}=A\cup A'.$$
\end{thm}
\begin{proof}
Esto es inmediato puesto que si $x\in A'$ entonces, por definición, todo entorno de $x$ intersecta a $A$.
\end{proof}
Veamos que en los casos más comunes, los conjuntos abiertos son aquellos que carecen de ``borde'', esto es, desgraciadamente, una expresión informal, de modo que para volverla valida podemos definir los límites de un conjunto como prosigue:
\begin{mydef}[Frontera]
Se llama \textit{borde} o \textit{frontera} de un subconjunto $A$ de un espacio topológico $X$ al conjunto $\partial A=\overline{A}\cap\overline{X\setminus A}$.
\end{mydef}
Bajo esta definición, todo $A$ es abierto si no contiene puntos de frontera, esto ya lo hemos hecho visible en previas figuras con la línea cortada.
\begin{thm}
Sean $A$ y $B$ subconjuntos de un espacio topológico $X$, entonces:
\begin{enumerate}[$a$)]
\item $\Int A\subseteq A\subseteq\overline{A}$.
\item Si $A\subseteq B$ entonces $\Int A\subseteq\Int B$ y $\overline{A}\subseteq\overline{B}$.
\item $\Int(A\cap B)=\Int A\cap\Int B$ y $\overline{A\cup B}=\overline{A}\cup\overline{B}$.
\item $A=\Int A$ si es abierto y $A=\overline{A}$ si es cerrado.
\item $\Int(X\setminus A)=X\setminus\overline{A}$ y $\overline{X\setminus A}=X\setminus\Int A$.
\end{enumerate}
\end{thm}
\begin{proof}
\begin{enumerate}[$a$)]
\item Por definición $\Int A=\bigcup\{U:U\in\tau\wedge U\subset A\}$, por tanto, $\Int A\subseteq A$ es trivial y por el teorema anterior se demuestra la otra relación.
\item Veamos que $G=\Int A\subseteq B$, por tanto $G$ es un subconjunto abierto de $B$, es decir que $\Int B=G\cup\cdots$, por definición. La demostración para la clausura es análoga.
\item Por $a$), $A\cup B\subseteq\overline{A}\cup\overline{B}$, el segundo conjunto es cerrado, por tanto, $\overline{A\cup B}\subseteq\overline{A}\cup\overline{B}$, por otra parte, $\overline{A}\subseteq\overline{A\cup B}$ y $\overline{B}\cup\overline{A\cup B}$, por $b$), por lo tanto, $\overline{A}\cup\overline{B}\subseteq\overline{A\cup B}$. La con interiores es análoga.
\item Si $A$ es abierto, entonces pertenece a $\tau$, es a su vez, entorno de todos sus elementos, por tanto, para todo $a\in A$ existe un $G\subset A\in\tau$ tal que $a\in G$, por lo tanto, $A=\bigcup\{G:G\subset A\in\tau\}=\Int A$. Si $A$ es cerrado, entonces $A\supseteq A$, luego, todo otro superconjunto $G$ de $A$ satisface $A\subset G$, es decir que $A=\bigcap\{G:A\subset G\in\tau\}=\overline{A}$.
\item Se sabe que $A\subseteq\overline{A}$ por tanto $X\setminus\overline{A}\subseteq X\setminus A$, el primero es un abierto, por tanto, $X\setminus\overline{A}\subseteq\Int(X\setminus A)$. Por otra parte, $\Int(X\setminus A)\subseteq X\setminus A$, por tanto, $A\subseteq X\setminus\Int(X\setminus A)$, el segundo es un cerrado, por lo tanto, $\overline{A}\subseteq X\setminus\Int(X\setminus A)$, es decir, $\Int(X\setminus A)\subseteq X\setminus\overline{A}$. La otra es análoga.
\end{enumerate}
\end{proof}
\begin{mydef}[Densidad]
Sea $S$ subconjunto de un espacio topológico $X$, se dice que $S$ es \textit{denso} en $X$ syss $\overline{S}=X$.
\end{mydef}
Bajo esta definición podemos ver que $\Q$ y $\R\setminus\Q$, puesto que cada entorno de un racional contiene un irracional y viceversa.
\begin{mydef}[Espacio de Hausdorff]
Es un espacio topológico $X$ tal que para todo $x\neq y\in X$ se cumple que $U_1,U_2$ son entornos disjuntos respectivos de dichos elementos.
\end{mydef}
\begin{thm}
Se cumple que:
\begin{enumerate}[$a$)]
\item Todo subconjunto de un espacio de Hausdorff con una cantidad finita de puntos es cerrado.
\item Todo subespacio de un espacio de Hausdorff es de Hausdorff.
\item Todo espacio métrico es de Hausdorff.
\item La topología producto de espacios de Hausdorff es de Hausdorff.
\end{enumerate}
\end{thm}
\begin{proof}
\begin{enumerate}[$a$)]
\item Sólo nos basta probar que $\{x\}$ es cerrado en un espacio de Hausdorff. Todo entorno de $x$ efectivamente intersecta al conjunto descrito. (Podemos ver que toda topología no satisface esta expresión, pues no en toda topología todo elemento posee un entorno)
\item Es trivial, puesto que si $x,y\in G$ entonces $U_x\cap G=U'_x$ y $u_y\cap G=U'_y$ son entornos en el subespacio $G$, como $U_x\cap U_y=\emptyset$ entonces $U'_x\cap U'_y=\emptyset$.
\item Las bolas $B_\epsilon(x)$ y $B_\epsilon(y)$ con $\epsilon=d(x,y)/2$ satisfacen la definición de espacio de Hausdorff.
\item Supongamos que tenemos un espacio $H=\prod_{i=1}^n H_i$ y consideramos dos elementos $x,y\in H$ tal que existe al menos un índice $i_0$ tal que $x_{i_0}\neq y_{i_0}$ y por tanto, en $H$ se cumple que $U,V$ son los entornos disjuntos en $H_{i_0}$. Luego las proyecciones $p_{i_0}^{-1}[U]$ y $p_{i_0}^{-1}[V]$ son entornos en $H$ disjuntos.
\end{enumerate}
\end{proof}

\section{Continuidad}
En el análisis la noción de \textit{función continua} es fundamental, tal como la mecánica del cuerpo rígido depende de la definición de este. Al igual que con la matemática no estándar, existen dos definiciones, pero la segunda depende (aun que no explicitamente) de la primera:
\begin{mydef}[Función continua]
Sea $f:X\rightarrow Y$ una aplicación con $X$ e $Y$ siendo espacios topológicos, decimos que es una continua en $x$ si y sólo sí para todo entorno $U$ de $f(x)$, $f^{-1}[U]$ es un entorno de $x$. Decimos que es continua si lo es en todo punto de su dominio.
\end{mydef}
\begin{thm}[Continuidad (en espacios métricos)]
Sea $f:M\rightarrow N$ una aplicación con $M$ y $N$ espacios métricos (con topologías inducidas por la métrica), es continua en $x\in M$ syss para todo $\epsilon\gt 0$ existe $\delta\gt 0$ tal que $d(x,y)\lt\delta$ implica $d(f(x),f(y))\lt\epsilon$.
\end{thm}
\begin{proof}
Si $M,N$ son espacios métricos, sus básicos son bolas abiertas (y, por tanto, entornos), entonces, para todo entorno $B_\epsilon(f(x))$, existe un $\delta$ tal que $B_\delta(x)\implies B_\epsilon(f(x))$ con $f[B_\delta(x)]\subseteq B_\epsilon(f(x))$.
\end{proof}
Esta última es lo que llamamos una definición auxiliar de ``continua'', que es aquella que poseen la mayoría de libros (pues la definición principal otorgada es muy abstracta).
\begin{thm}
Sea $f:X\rightarrow Y$ una aplicación con $X$ e $Y$ espacios topológicos. Son equivalentes:
\begin{enumerate}[$a$)]
\item $f$ es continua.
\item Para todo $A\subset X$ se cumple $f[\overline{A}]\subseteq\overline{f[A]}$.
\item Para todo $B\subset Y$ se cumple $\overline{f^{-1}[B]}\subseteq f^{-1}[\overline{B}]$.
\item Para todo $B\subset Y$ se cumple $f^{-1}[\Int B]\subseteq\Int(f^{-1}[B])$.
\end{enumerate}
\end{thm}
\begin{proof}
$a)\implies b)$. Si $y\in f[\overline{A}]$ entonces $y=f(x)$ con $x\in\overline{A}$, si $U$ es entorno de $y$, entonces $f^{-1}[U]$ es entorno de $x$ (por def.), es decir, $f^{-1}[U]\cap A\neq\emptyset$, por tanto, $U\cap f[A]\neq\emptyset$, es decir, $x\in\overline{f[A]}$.

$b)\implies c)$. Evidentemente $f^{-1}[B]\subseteq X$, por tanto, $f[\overline{f^{-1}[B]}]\subseteq\overline{f[f^{-1}[B]]}\subseteq\overline{B}$, es decir, $\overline{f^{-1}[B]}\subseteq f^{-1}[\overline{B}]$.

$c)\implies d)$.
\begin{align*}
f^{-1}[\Int B]&=f^{-1}[Y\setminus(Y\setminus\Int B)]=X\setminus f^{-1}[Y\setminus\Int B]\\
&=X\setminus f^{-1}[\overline{Y\setminus B}]\subseteq X\setminus\overline{f^{-1}[Y\setminus B]}\\
&=\Int(X\setminus f^{-1}[Y\setminus B])=\Int f^{-1}[B].
\end{align*}

$d)\implies a)$. Sea $U$ un entorno abierto de $f(x)$ entonces $f^{-1}[U]=f^{-1}[\Int U]\subseteq\Int f^{-1}[U]\subseteq f^{-1}[U]$, es decir, $f^{-1}[U]=\Int f^{-1}[U]$, por tanto es abierto y satisface la definición de continuo.
\end{proof}
\begin{thm}
Se cumple que:
\begin{enumerate}[1)]
\item La función identidad $f(x)=x$ es continua.
\item La función constante $f(x)=c$ es continua.
\item Sea $A$ un subespacio de $X$, entonces la función inclusión $i(x)=x$ con $i:A\rightarrow X$ es continua.
\item La función proyección $p_i:\prod_{j=1}^n X_j\rightarrow X_i$ es continua.
\item Sean $f:X\rightarrow Y$ y $g:Y\rightarrow Z$ funciones continuas, $f\circ g:X\rightarrow Z$ es continua.
\end{enumerate}
\end{thm}
\begin{proof}
\begin{enumerate}[1)]
\item Es trivial, puesto que $f^{-1}[U]=U$.
\item Si el entorno abierto $U$ contiene a $c$ entonces $f^{-1}[U]=X$ y $X\in\tau$, de lo contrario $f^{-1}[U]=\emptyset$ y $\emptyset\in\tau$.
\item Consideremos un abierto $U$ en $X$ entonces los elementos de $A$ que poseera dicho conjunto son, por definición, $U\cap A$ lo que es abierto en $A$.
\item Es trivial, pues ya habíamos definido las proyecciones $p_i^{-1}[U_i]$ que sean básicos de la topología producto.
\item Para que $g$ sea continuo todo conjunto $U$ abierto en $Z$ debe satisfacer que $V=g^{-1}[U]$ sea abierto en $Y$, para que $f$ sea continuo todo abierto $V$ en $Y$ debe satisfacer que $f^{-1}[V]$ sea abierto en $X$. Por tanto todo conjunto $U$ abierto en $Z$ satisface que $f^{-1}[g^{-1}[U]]=(f\circ g)^{-1}[U]$ es abierto en $X$, por tanto, $f\circ g$ es continuo.
\end{enumerate}
\end{proof}
\begin{cor}
Sea $X$ un espacio topológico con un subespacio $G$, si $f:X\rightarrow Y$ es continua entonces $f|_G:G\rightarrow Y$.
\end{cor}
\begin{proof}
Hay varias demostraciones posibles, la más sencilla es ver que la función inclusión $i:G\rightarrow X$ es continua, por tanto, $f|_G=i\circ f$ y la composición es continua.
\end{proof}
\begin{cor}
La aplicación
\begin{align*}
f:X&\longrightarrow\prod_{i=1}^n X_i\\
f(x)&\longmapsto(f_1(x),\dots,f_n(x))
\end{align*}
es continua, syss cada aplicación $f_i:X\rightarrow X_i$ es continua.
\end{cor}
\begin{proof}
Si $f$ es continua entonces $f_i=f\circ p_i$ es continua. Y si alguna $f_i$ no es continua entonces $f$ debe no serlo, pues $p_i$ es continua en todo caso.
\end{proof}
\begin{cor}
Sean $f_1:X_1\rightarrow Y_1,\dots,f_n:X_n\rightarrow Y_n$ funciones continuas, entonces
\begin{align*}
f:\prod_{i=1}^n X_i&\longrightarrow\prod_{i=1}^n Y_i\\
f(x_1,\dots,x_n)&\longmapsto(f_1(x_1),\dots,f_n(x_n))
\end{align*}
es continua.
\end{cor}
\begin{proof}
Veamos que $f_i=f\circ p_i$, como $f_i$ es continuo, $f$ debe serlo en cada coordenada, es decir, $f$ es continuo para todo punto.
\end{proof}
\begin{mydef}[Propiedad de Lipschitz]
Sean $E$, $F$ espacios normados sobre un cuerpo métrico $R$. Se dice que una función $\vec{f}:E\rightarrow F$ posee la propiedad de Lipschitz si existe un $c\in R$ tal que para todo par de vectores $\vec{u},\vec{v}\in E$ se cumpla que $\Vert\vec{f}(\vec{v})-\vec{f}(\vec{u})\Vert\leq c\Vert\vec{v}-\vec{u}\Vert$.
\end{mydef}
\begin{thm}
Las aplicaciones con la propiedad de Lipschitz son continuas.
\end{thm}
\begin{proof}
Veamos que si consideramos una función como la anterior con un par $\vec{u},\vec{v}$ tal que $\Vert\vec{v}-\vec{u}\Vert\lt\delta$, luego definimos un $\epsilon=\delta/c$ de tal forma que se cumple que $\Vert\vec{f}(\vec{v})-\vec{f}(\vec{u})\Vert\leq c\Vert\vec{v}-\vec{u}\Vert$ por propiedad de Lipschitz y, evidentemente, $\Vert\vec{f}(\vec{v})-\vec{f}(\vec{u})\Vert\lt\epsilon$.
\end{proof}
\begin{thm}
Sea $E$ un espacio normado sobre un espacio metrico $K$, son continuas:
\begin{enumerate}[(1)]
\item La suma $+:E\times E\rightarrow E$.
\item El producto $\cdot:K\times E\rightarrow E$.
\item El inverso multiplicativo $1/x:K_0\rightarrow K$.
\item La raiz cuadrada $\sqrt{x}:[0,\infty)\rightarrow[0,\infty)$.
\end{enumerate}
\end{thm}
\begin{proof}
\begin{enumerate}[(1)]
\item La suma posee propiedad de Lipschitz, esto se demuestra asumiendo que $E\times E$ posee norma $L_1$ y considerando dos pares $(a,b),(u,v)$ tal que:
\begin{align*}
\Vert(u+v)-(a+b)\Vert&=\Vert(u-a)+(v-b)\Vert\leq\Vert u-a\Vert+\Vert v-b\Vert\\
&=\Vert(u-a,v-b)\Vert=\Vert(u,v)-(a,b)\Vert
\end{align*}
\item Consideremos que en $K\times E$, con norma $L_\infty$, hay un punto inicial $(\Lambda,y)$ y otro cualquiera $(\lambda,x)$ a menos de $\delta$ de distancia, donde
$$\delta=\frac{\epsilon}{|\lambda|+\Vert y\Vert+1}\leq\epsilon,$$
por definición, entonces $\Vert(\Lambda,y)-(\lambda,x)\Vert=\max\{|\Lambda-\lambda|,\Vert y-x\Vert\}\lt\delta$. Luego vemos que
\begin{align*}
\Vert\Lambda y-\lambda x\Vert&=\Vert\Lambda y-\lambda y+\lambda y-\lambda x\Vert\\
&\leq|\Lambda-\lambda|\Vert y\Vert+|\lambda|\Vert y-x\Vert\\
&\lt \Vert y\Vert\delta+|\lambda|\delta\lt\epsilon
\end{align*}
\item Como $x\neq 0$ podemos tomar $\delta=|x|/2\gt 0$. Veamos que como $|x|-|y|\leq||x|-|y||\leq|x-y|\lt\delta$ obtenemos que $|y|\gt|x|-\delta=\delta$. Definamos un $\delta'\lt\delta,\delta'\lt\delta|x|\epsilon$ que $|y-x|\lt\delta'$, luego, es fácil ver que
$$|\frac{1}{y}-\frac{1}{x}|=\frac{|y-x|}{|y||x|}\lt\frac{\delta|x|\epsilon}{\delta|x|}=\epsilon.$$
\item Consideremos un conjunto imagen $(a,b)$, entonces $a\lt\sqrt{x}\lt b$, como $a,b$ son no-negativos, se cumple que $a^2\lt x\lt b^2$, y $(a^2,b^2)$ es un conjunto preimagen abierto.
\end{enumerate}
\end{proof}
Al pensar en ``continuidad'', pensamos primero en la gráfica de una función, la cual definimos como
\begin{mydef}[Gráfica de $f(x)$]
Es un diagrama en el cual se considera un pequeño intervalo $D\subset\R$ y se dibujan los puntos de un conjunto al que llamaremos \textit{gráfica} $G$:
$$G=\{(x,f(x)):x\in D\}$$
\end{mydef}
\begin{figure}
\begin{center}
\begin{tikzpicture}
\begin{axis}[demo,
	enlargelimits = .05,
	samples = 50,
	width=8cm,
	xlabel = {$x$}, ylabel = {$f(x)$}
]
\addplot[niceblue,domain=-1:1,smooth,thick] {2*(x-.5)*x*(x+.5)+.5};
\end{axis}
\end{tikzpicture}
\caption{Gráfico de una función cualquiera\textsuperscript{a}.}
\end{center}
\noindent\hrulefill

\footnotesize\textsuperscript{a} Cabe destacar que los gráficos son, por el momento, elaborados por computadoras evaluando la función en un número grande de puntos (por ejemplo 50) y redondeando los bordes, para parecer más precisa.
\end{figure}
Las previas demostraciones pueden (y son) extremadamente más complicadas que el concepto que parece describir, en la práctica simplemente solemos ver la gráfica de una función para determinar si es o no continua, esto lo podemos expresar matemáticamente en la teoría NSA a través de la siguiente definición auxiliar:
\begin{thm}[Continuidad (no estándar)]\label{thm:continuity-nsa}
Sea $f:D\subseteq\R\rightarrow\R$ una función, se dice que es estándar en $x_0$ si para todo $x\simeq x_0$ se cumpla que $f(x)\simeq f(x_0)$.
\end{thm}
\begin{proof}
Veamos que la definición de ``entorno'' de $x_0$ en $\R$ implica que el conjunto $U(x_0)$ contengan a todos los no estándares infinitamente cercanos a $x_0$, esto se debe a que todo abierto básico va en la forma $B_\delta(x_0)$, y $d(x,x_0)=\epsilon$ donde $\epsilon$ es un infinitesimal que, por definición, es más pequeño que todo $\delta$ estándar.
\end{proof}
\begin{mydef}
Sean $f,g:D\subseteq\R\rightarrow\R$, definimos
\begin{enumerate}[$a)$]
\item $(f\pm g)(x)=f(x)\pm g(x)$.
\item $(f\cdot g)(x)=f(x)\cdot g(x)$.
\item $(f/g)(x)=f(x)/g(x)$.
\end{enumerate}
\end{mydef}
Técnicamente es un teorema pues debe demostrarse que esta definición auxiliar es consistente con la definición original. En la práctica, este teorema nos ayudará en muchas demostraciones de continuidad como la siguiente:
\begin{cor}\label{cor:sum-prod-continous}
Sean $f,g:D\subseteq\R\rightarrow\R$ funciones continuas, entonces $(f\pm g)(x)$ y $(f\cdot g)(x)$ son continuas. Al igual que si definimos $G=\{x\in D:g(x)=0\}$, entonces $(f/g):D\setminus G\rightarrow\R$ continua.
\end{cor}
\begin{proof}
Veamos que ambos son consecuencia inmediata de los teoremas~\ref{thm:continuity-nsa} y \ref{thm:inf-close-nsa}.
\end{proof}
\begin{thm}
Veamos que si poseemos dos funciones $f:D\subseteq\R\rightarrow E\subseteq\R$ y $g:E\rightarrow\R$ tal que $f$ es continua en $x_0$ y $g$ es continua en $f(x_0)$, entonces $f\circ g$ es continua en $x_0$.
\end{thm}
\begin{proof}
Por definición, si $x\simeq x_0$ entonces $f(x)\simeq f(x_0)$ y
$$(f\circ g)(x)=g(f(x))\simeq g(f(x_0))=(f\circ g)(x_0).$$
\end{proof}
Nótese que la continuidad total en $D$ es consecuencia inmediata de este teorema.
\begin{mydef}[Función polinómica]
Se dice que una función es polinómica y de grado $n$ cuando está escrito en forma
$$p_n(x)=c_0+c_1x+c_2x^2+\cdots+c_nx^n=\sum_{k=0}^n c_kx^k,$$
con $c_0,c_1,\dots,c_n\in\R$ y $c_n\neq 0$.
\end{mydef}
Gracias al corolario~\ref{cor:sum-prod-continous} vemos que toda función polinómica es continua.
\begin{thm}[Primer teorema de Weierstrass]
Sea $f:[a,b]\rightarrow\R$ una función continua, entonces, posee un máximo y un mínimo.
\end{thm}
\begin{proof}
Veamos que esta demostración se realiza con el axioma de idealización de IST: considera un conjunto estándar y finito $F$, entonces para todo $x\in F$ (estándar) existe un $y\in [a,b]$ tal que $f(y)\geq f(x)$ y un $z\in [a,b]$ tal que $f(z)\leq f(x)$ (son los máximos y mínimos de $F$ respectivamente), luego, existen aquellos tales que se cumple siempre. Se demuestra que los máximos y mínimos son $M=\sh y$ y $m=\sh z$ respectivamente, ya que en caso contrario existiría un estándar $M'\in[a,b]$ tal que $f(M')\gt f(M)$, pero ello implica que $f(M')\gt f(y)$, lo que es imposible. El caso para $m$ es análogo.
\end{proof}
\begin{thm}[Segundo teorema de Weierstrass]
Sea $f:[a,b]\rightarrow\R$ una función continua, entonces toma todos los valores entre $f(a)$ y $f(b)$.
\end{thm}
\begin{proof}
Asumamos que $f(a)\lt f(b)$ (pues $f(a)=f(b)$ sería trivial), entonces hemos que demostrar que existe un $c\in[a,b]$ tal que $f(a)\lt f(c)\lt f(b)$.

Fijemos un $n\in\N$ ilimitado para definir $x_i=a+i/n$. Evidentemente $x_{n^2}$ es ilimitado y por tanto $x_{n^2}\gt b$, por tanto, existe un $k$ tal que $x_k\leq b\lt x_{k+1}$, luego vemos que $f(x_0)\lt y$ y $f(x_k)\gt y$, por tanto, debe haber un $j$ tal que $f(x_j)\leq y\lt f(x_{j+1})$. Finalmente por continuidad, sabemos que $c\simeq x_j$, por tanto, $c=\sh x_j$.
\end{proof}
\begin{figure}
\centering
\begin{tikzpicture}
\begin{axis}[demo,
	samples = 50,
	xmin = .5, xmax = 3.5, ymin = 0, ymax = 3.7,
	xlabel = {$x$}, ylabel = {$f(x)$},
	ticks = major, xtick = {1.07,2.93}, xticklabels = {$a$,$b$}, ytick = {1.5,2.5}, yticklabels = {$f(a)$,$f(b)$}
]
\addplot[domain=1.07:1.873,smooth] {-4*(x-3)*(x-2)*(x-1)+2};
\addplot[niceblue,very thick,domain=1.873:2.127,smooth] {-4*(x-3)*(x-2)*(x-1)+2};
\addplot[domain=2.127:2.93,smooth] {-4*(x-3)*(x-2)*(x-1)+2};
\addplot+[only marks,niceblue,mark=*] coordinates {(1.07,1.5) (2.93,2.5)};
\addplot[dashed,domain=0:2.93] {1.5};
\addplot[dashed,domain=0:2.93] {2.5};
\addplot[dashed,domain=0:2.5] (1.07,x);
\addplot[dashed,domain=0:2.5] (2.93,x);
\end{axis}
\end{tikzpicture}
\caption{Demostración gráfica del segundo teorema de Weierstrass.}
\end{figure}

Al segundo teorema de Weierstrass se le suele llamar \textit{teorema de los valores intermedios}. Veamos que usualmente en el análisis estándar suelen utilizar de lema para el segundo teorema de Weierstrass el siguiente:
\begin{thm}[Teorema de Bolzano-Cauchy]
Sea $f:[a,b]\rightarrow\R$ continua, con $f(a)$ de distinto signo que $f(b)$. Luego existe $x_0\in[a,b]$ tal que $f(x_0)=0$.
\end{thm}
\begin{mydef}[Homeoformismo]
Una aplicación $f:X\rightarrow Y$ es un \textit{homeoformismo}, syss, es biyectiva y tanto ella como su inversa son continuas. Dos conjuntos son homeoformos si existe por lo menos un homeoformismo entre ambos.
\end{mydef}
La idea detrás del homeoformismo es, por ejemplo, tomar un cuerpo (conjunto abierto) y deformarlo en otro, pero bajo la condición de que después de $n$ transformaciones, podemos reinvertir el proceso y obtener el cuerpo original.
\begin{figure}
\centering
\begin{tikzpicture}[scale=.75]
\draw[gray] (0,0) grid (4,4) (7,0) grid ++(4,4);
\begin{scope}[niceorange,opacity=.5]
\fill (2,2) circle (1.5);
\fill[rounded corners=5] (8,1) -- (10,1) -- (10,3) -- (8,3) -- cycle;
\end{scope}
\draw[-latex] (4.5,2.5) to[out=30,in=150] ++(2,0);
\draw[latex-] (4.5,1.5) to[out=-30,in=-150] ++(2,0);
\draw (5.5,2.75) node[above]{$f$} (5.5,1.25) node[below]{$f^{-1}$};
\begin{scope}[niceorange,dashed,very thick]
\draw (2,2) circle (1.5);
\draw[rounded corners=5] (8,1) -- (10,1) -- (10,3) -- (8,3) -- cycle;
\end{scope}
\end{tikzpicture}
\caption{Ejemplo de homeoformismo.}
\end{figure}
\begin{prop}[Propiedades de los homeoformismos]
Sean $f:X\rightarrow Y$ y $g:Y\rightarrow Z$ homeoformismos, entonces:
\begin{enumerate}[$a$)]
\item $f^{-1}$ es un homeoformismo.
\item $f\circ g$ es un homeoformismo.
\end{enumerate}
\end{prop}

\section{Límites de funciones}
Ya introducimos la idea de límite de sucesiones en el capítulo~2, esta dependía del concepto de \textit{convergencia}, en paralelo, la noción del límite de función depende de la propiedad de ser \textit{continua}. Pensemos en, por ejemplo, la función
$$f(x)=\frac{x^2-1}{x-1},$$
su gráfica es la de la fig.~\ref{fig:generic-limits-example}.
\begin{figure}
\centering
\begin{tikzpicture}
\begin{axis}[2dgraph,
	xlabel = $x$,
	ylabel = $f(x)$
]
\addplot[niceblue,domain=0:4] {x+1};
\addplot+[niceblue, very thick, only marks, mark=*, mark options={fill=white}] coordinates {(1,2)};
\end{axis}
\end{tikzpicture}
\caption{Gráfica de $f(x)=\frac{x^2-1}{x-1}$.}
\label{fig:generic-limits-example}
\end{figure}

El gráfico presenta un punto en blanco que corresponde un punto vacío puesto que en $x=1$, $f(x)=\rm Ind$; sin embargo, si vemos a los puntos al rededor, vemos que \textit{converge} a 2. ¿Pero como formalizar está idea más allá de la pista visual? Pues es evidente hacia adonde apuntan los tiros. Pensemos en lo siguiente: si una sucesión es convergente lo hace en un límite $l$ que está infinitamente cercano al término $s_N$ donde $N$ es ilimitado; de manera similar, si la función es continua en un punto $c$ posee límite $l$ que está infinitamente cercano al término $f(x)$ donde $x\simeq x_0$.
\begin{mydef}[Convergencia de funciones]
Sean $X,Y$ dos espacios topológicos y $f:D\subset X\rightarrow Y$ una función. Diremos que $f(x)$ \textit{converge} en $l$ cuando $x$ tiende a $x_0$ si para todo entorno $V$ de $l$ existe un entorno $U$ de $l$ tal que si $x\in U\cap D$ y $x\neq x_0$, entonces $f(x)\in V$.

Este límite lo denotaremos como
$$l=\lim_{x\to x_0} f(x).$$
\end{mydef}
\begin{thm}[Unicidad del límite]
Sea $f:X\rightarrow Y$ con $X$ un espacio topológico e $Y$ un espacio de Hausdorff. Vemos que si $f$ es convergente en $a\in X'$ entonces $\lim_{x\to a}f(x)$ es único.
\end{thm}
\begin{proof}
Supongamos, por contradicción que $b$ y $c$ son límites de $f(x)$, entonces para todo entornos disjuntos $V_b$ y $V_c$ de $b$ y $c$ respectivamente, existen $U_b,U_c$ entornos de $a$. Luego, podemos ver que $U_b\cap U_c$ es entorno de $a$ y luego $f(x)\in V_b\cap V_c$, lo que es ridículo.
\end{proof}
Esta es la definición general (y adecuada para la topología), pero en realidad, en la práctica utilizaremos dos definiciones auxiliares que son más comunes en los textos científicos:
\begin{thm}[Límites de funciones]
Sean $X,Y$ dos espacios métricos y $f:D\subset X\rightarrow Y$ una función. Diremos que $l$ es límite de $f(x)$ cuando $x$ tiende a $x_0$ syss:
	\begin{description}
	\item[\bf Def. estándar] Para todo $\epsilon\gt 0$ existe un $\delta\gt 0$ tal que $0\lt d(x,x_0)\lt\delta$ implica $d(f(x),l)\lt\epsilon$.
	\item[\bf Def. no estándar] Para todo $x\simeq x_0$ (distinto de $x_0$) se cumple que $f(x)\simeq l$.
	\end{description}
\end{thm}
\begin{proof}
Veamos que ambas definiciones auxiliares satisfacen la idea de los entornos a su manera (a través de bolas y de los infinitesimales al rededor de ellos).
\end{proof}
Veamos que por ambas definiciones podemos probar el ejemplo inicial, la más fácil es a través de métodos no estándares, puesto que si $x\neq 1$ entonces $f(x)=x+1$, si $x\simeq 1$, entonces $f(x)\simeq 2$, como se quería probar.
\begin{thm}
Sean $X,Y$ espacios y topológicos y $f:X\rightarrow Y$; $f$ es continua en $x_0$ syss $\lim_{x\to x_0} f(x)=f(x_0)$.
\end{thm}
\begin{proof}
Veamos que si $f(x_0)$ es el límite para todo entorno $V$ de él, existe un entorno $U$ de $x_0$ tal que sus imágenes pertenecen a $V$, satisfaciendo la definición de continuidad. Es trivial, utilizando cualquier otra definición auxiliar.
\end{proof}
\begin{thm}
Sean $f,g:D\subset X\rightarrow R$ funciones con $X$ un espacio topológico y $R$ un espacio métrico, si $\lim_{x\to a} f(x)=l$ y $\lim_{x\to a} g(x)=m$, entonces
\begin{enumerate}[$a$)]
\item $\displaystyle\lim_{x\to a}(f\pm g)(x)=l+m$.
\item $\displaystyle\lim_{x\to a}(f\cdot g)(x)=lm$.
\item $\displaystyle\lim_{x\to a}(f/g)(x)=l/m$ si $m\neq 0$.
\end{enumerate}
\end{thm}
\begin{proof}
Nótese que ya hemos demostrado que la suma, producto y división de funciones continuas es continua en dicho punto, por tanto, los límites deben ser iguales a las funciones en dicho punto, es decir, a $l$ y $m$ respectivamente.
\end{proof}
\begin{thm}
Sean $f:A\rightarrow B$ y $g:B\rightarrow C$ tal que $\lim_{x\to c}f(x)=l$ (con $a\in A'$) y $g$ es continua en $l$, entonces
$$g\left(\lim_{x\to c}f(x)\right)=\lim_{x\to c}g(f(x)).$$
\end{thm}
\begin{proof}
Sea $U$ un entorno de $g(l)$, tal que $g^{-1}[U]$ es entorno de $l$. Veamos que si $V$ es entorno de $c$ y $x\in V$ pero $x\neq c$, entonces $f(x)\in U$, por tanto, cumple la definición de límite.
\end{proof}
\begin{mydef}[Límites en $D$]
Sea $f:X\rightarrow Y$ con $X$ un espacio métrico e $Y$ un espacio topológico, si $D\subset X$ con $c\in D'$, entonces definimos
$$\underset{D}{\lim_{x\to c}}f(x)=\lim_{x\to c}\left.f\right|_D(x).$$
En particular, definimos los límites \textit{laterales} como
$$\lim_{x\to c^-}f(x)=\underset{(-\infty,c)}{\lim_{x\to c}}f(x),\quad\lim_{x\to c^+}f(x)=\underset{(c,\infty)}{\lim_{x\to c}}f(x);$$
deben leerse como \textit{límite por la izquierda} o \textit{por la derecha} respectivamente.
\end{mydef}
\begin{thm}
Sea $f:A\subseteq X\rightarrow Y$, con $A=\bigcup_{i=0}^n B_i$ donde $a$ es un punto de acumulación para todo $B_i$, entonces existe $\displaystyle\lim_{x\to a}f(x)$ syss existen y son iguales los límites $\displaystyle\underset{B_i}{\lim_{x\to a}}f(x)$.
\end{thm}
\begin{proof}
Veamos que $\implies$ es trivial.

$\Longleftarrow$. Supongamos que $l$ es el límite común en $B_i$, entonces debe darse que para todo entorno $V$ existe un entorno $U_i=U^*_i\cap B_i$ tal que $x\in U_i,x\neq a$ implica $f(x)\in V$. Luego, definimos $U=\bigcup_{i=0}^n U_i=\left(\bigcup_{i=0}^n U^*_i\right)\cap A$, evidentemente $U$ es entorno de $a$ y si $x\in U,x\neq a$ entonces $f(x)\in V$.
\end{proof}
Veamos que si definimos la función ``signo'' como
$$\sign x=\frac{x}{|x|},$$
entonces $\lim_{x\to 0}\sign x$ no existe, pues sus límites laterales $\lim_{x\to 0^-}\sign x=-1$ y $\lim_{x\to0^+}\sign x=1$ no concuerdan. En la práctica definimos $\sign 0=1$.
\begin{mydef}[Límites ``infinitos'']
Suponga una función $f(x)$ con recorrido en un espacio métrico
$$\lim_{x\to a}f(x)=+\infty$$
cuando:
\begin{description}
\item[\bf Def. estándar] Para todo $K\gt 0$ existe un $\delta\gt 0$ tal que $d(x,a)\lt\delta\implies f(x)\gt K$.
\item[\bf Def. no estándar] Para todo $x\simeq a$ se cumple que $f(x)$ es ilimitado positivo.
\end{description}
Además denotamos que $\lim_{x\to a}f(x)=-\infty$ cuando $\lim_{x\to a}-f(x)=+\infty$ y $\lim_{x\to a}f(x)=\infty$ cuando $\lim_{x\to a}|f(x)|=+\infty$.

Ahora suponga que $f$ posee como dominio un espacio métrico, decimos que
$$\lim_{x\to+\infty}f(x)=l$$
cuando:
\begin{description}
\item[\bf Def. estándar] Para todo $\epsilon\gt 0$ existe un $\delta\gt 0$ tal que $x\gt\delta\implies d(f(x),l)\lt\epsilon$.
\item[\bf Def. no estándar] Para todo $x$ ilimitado $f(x)\simeq l$.
\end{description}
Además denotamos que $\lim_{x\to-\infty}f(x)=\lim_{x\to+\infty}f(-x)$.
\end{mydef}
Formalmente se dice que para los primeros casos, la función $f$ diverge en el punto $a$, pero la \textit{convergencia infinita} debe interpretarse como un caso particular de divergencia.
\begin{thm}[Teorema del Sandwich]
Sea $f,g,h:A\subseteq\R\rightarrow\R$ tal que $\forall x\in B$ se cumpla $f(x)\leq g(x)\leq h(x)$, entonces si $b\in B'$ y $\lim_{x\to b}f(x)=\lim_{x\to b}h(x)=l$ entonces $\lim_{x\to b}g(x)=l$.
\end{thm}
\begin{proof}
Nótese que la definición de límite implica que para un $\epsilon\gt 0$ fijo existe un par de $\delta_1,\delta_2\gt 0$ tales que si $d(x,b)\lt\delta_1\implies f(x)\in B_\epsilon(l)$ y $d(x,b)\lt\delta_2\implies h(x)\in B_\epsilon(l)$; luego definamos $\delta=\min\{\delta_1,\delta_2\}$, entonces si $d(x,b)\lt\delta$ entonces $l-\epsilon\lt f(x)\leq g(x)\leq h(x)\lt l+\epsilon$, lo que satisface la definición estándar de límite.
\end{proof}
\begin{figure}
\centering
\begin{tikzpicture}
\begin{axis}[demo,
	domain= -1:1,
	xlabel = $x$, ylabel = {$f(x)$}
]
\addplot[niceblue, thick, smooth, samples = 300] {x*sin(180/pi/x)};
\begin{scope}[dashed, nicepurple, mark = none]
\addplot {x};
\addplot {-x};
\end{scope}
\end{axis}
\end{tikzpicture}
\caption{Teorema del Sandwich.}
\end{figure}

\subsection*{Cálculo de límites}
Veamos, que no es dificil probar que
$$\lim_{x\to+\infty}x^r=\begin{cases}
+\infty &r\gt 0\\
\phantom{+}1 &r=0\\
\phantom{+}0 &r\lt 0
\end{cases}$$
y que
$$\lim_{N\to+\infty}x^N=\begin{cases}
+\infty &\phantom{0\lt}\;x\gt 1\\
\phantom{+}1 &\phantom{0\lt}\;x=1\\
\phantom{+}0 &0\leq x\lt 1
\end{cases}$$
Otro ejemplo, es calcular los límites infinitos de funciones polinomiales:
$$\lim_{x\to+\infty}x^3-2x^2+7x-3=\lim_{x\to+\infty}x^3\left(1-\frac{2}{x}+\frac{7}{x^2}-\frac{3}{x^3}\right)=+\infty,$$
los cuales no siempre convergen a los mismos valores, en general
$$\lim_{x\to+\infty}\sum_{i=0}^n c_ix^i=\begin{cases}
+\infty &c_n\gt 0\\
-\infty &c_n\lt 0
\end{cases}$$
Nótese que también
\begin{equation}
\lim_{x\to\infty}\frac{\sum_{i=0}^n a_ix^i}{\sum_{i=0}^m b_ix^i}=\begin{cases}
+\infty &n\gt m\\
a_n/b_m &n=m\\
0 &n\lt m
\end{cases}
\end{equation}
Hablando de límites infinitos cabe notar que
\begin{equation}
\lim_{x\to 0^-}\frac{1}{x}=-\infty,\quad\lim_{x\to0^+}\frac{1}{x}=+\infty,
\end{equation}
lo que en cierta forma significa que la función no posee límite único, y en otra forma podemos decir que ``converge'' a $\infty$. Nótese que podemos deducir que
\begin{equation}
\lim_{x\to 0}\frac{1}{x^2}=+\infty.
\end{equation}
Además, procederemos a demostrar uno de los límites más importantes de todos (a veces llamado uno de los \textit{límites notables})
\begin{equation}
\lim_{x\to 0}\frac{\sin x}{x}=1,
\end{equation}
esta prueba posee un aviso de ``advertencia'', pues será una demostración que utilizará propiedades geométricas y trigonométricas. Para probarlo utilizaremos el teorema del sandwich, primero trazaremos desde el origen de $\R^2$, que llamamos $A$, una diagonal de largo 1 hasta el punto $B$ desde el cual trazaremos una recta paralela al eje $y$ hasta su intersección con el eje $x$, que llamamos $C$.
\begin{figure}
\centering
\begin{tikzpicture}[scale=5]
\clip (-.1,-.1) rectangle (1.3,1.2);
\draw[gray] (-1,-1) grid[step=.5] (1.5,1.5);
\draw[->] (0,-.5) -- (0,1.1) node[left]{$y$};
\draw[->] (-.5,0) -- (1.1,0) node[above]{$x$};
\draw (0,0) circle (1) -- node[sloped,above]{1} (30:1) (15:1) node[fill=white]{$x$};
\draw[dashed] (30:1) -- (1,{tan(30)});
\begin{scope}[very thick]
\draw[niceorange] (1,0) -- node[right]{$\tan x$} (1,{tan(30)});
\draw[nicered] ({cos(30)},0) -- node[left]{$\sin x$} ++(0,{sin(30)});
\draw[niceblue] (0,0) -- node[below]{$\cos x$} ({cos(30)},0);
\end{scope}
\end{tikzpicture}
\caption{Círculo unitario o goniométrico.}
\end{figure}

Nótese que el área del triángulo $\triangle ABC$ es $\frac{1}{2}x$, por lo cual, se nota claramente que
$$\frac{1}{2}\sin x\leq\frac{1}{2}x\leq\frac{1}{2}\tan x,$$
dividamos todo por $\frac{1}{2}\sin x$ e invertimos los signos:
$$\cos x\leq\frac{\sin x}{x}\leq 1.$$
Como ambas funciones tienden a 1 cuando $x\to 0$, por lo cual, utilizando el teorema del sandwich se deduce el límite ya mencionado.

Utilizando las desigualdades deducidas y el teorema del sandwich podemos probar que
$$\lim_{x\to 0}\sin x=0,\quad\lim_{x\to 0}\cos x=1,$$
con lo cuál podemos deducir que $\sin x$ y $\cos x$ son continuas (aplicando suma de ángulos). Demostrado ello podemos deducir que todo el resto de funciones trigonométricas lo son (exceptuando los puntos dónde sus denominadores equivalen a cero).

Otros límites trigonométricos notables son
\begin{align}
\lim_{x\to 0}\frac{1-\cos x}{x^2}&=\lim_{x\to 0}\frac{1-\cos x}{x^2}\frac{1+\cos x}{1+\cos x}\notag\\
&=\lim_{x\to 0}\frac{1-\cos^2 x}{x^2(1+\cos x)}\notag\\
&=\lim_{x\to 0}\frac{\sin^2 x}{x^2}\frac{1}{1+\cos x}=\frac 12.\label{eq:cosine-limit}
\end{align}
y
\begin{equation}
\lim_{x\to 0}\frac{\tan x}{x}=\lim_{x\to 0}\frac{\sin x}{x}\frac{1}{\cos x}=1.
\end{equation}
Aplicando la ec.~\ref{eq:cosine-limit} se deduce que
$$\lim_{x\to 0}\frac{1-\cos x}{x}=0.$$

\section{Espacios compactos}
\begin{mydef}[Cubrimiento abierto]
Sea $A$ un subconjunto de un espacio topológico $X$, decimos que una familia de abierto de $X$, llamada $\mathcal{F}$, es un \textit{cubrimiento abierto}, si
$$A\subseteq\bigcup_{U\in\mathcal{F}}U,$$
se dice que $\mathcal{G}$ es un \textit{subcubrimiento} si $\mathcal{G}\subset\mathcal{F}$ y $\mathcal{G}$ es un cubrimiento de $A$.
\end{mydef}
\begin{mydef}[Compacto]
Un subconjunto $A$ de un espacio de Hausdorff $X$ es \textit{compacto} si todo cubrimiento abierto de él posee un subcubrimiento finito. Se dice que $A$ es \textit{localmente compacto} si todo punto está contenido en algún abierto cuya clausura sea compacta.
\end{mydef}
Veamos que $\R$ no es compacto, pues nótese que si consideramos el cubrimiento abierto:
$$\mathcal{F}=\{(n,n+2):n\in\Z\},$$
este no posee ningún subcubrimiento finito.

Nótese que si $X$ es finito, evidentemente es compacto.
\begin{thm}
Se cumplen:
\begin{enumerate}[$a)$]
\item Todo subconjunto compacto de un espacio de Hausdorff $X$ es cerrado.
\item Todo subconjunto cerrado de un espacio compacto $C$ es compacto.
\item Todo subconjunto compacto de un espacio métrico $M$ está acotado.
\end{enumerate}
\end{thm}
\begin{proof}
\begin{enumerate}[$a)$]
\item Sea $K\subseteq X$ un conjunto compacto, debemos probar que $X\setminus K$ es abierto. Veamos que tomemos un par de puntos $x\in K$ e $y\in X\setminus K$, lo que implica la propiedad de ser de Hausdorff es que existen entornos (abiertos) $U_x,U_y$ de $x$ e $y$ que son disjuntos, obsérvese que
$$\mathcal{F}=\bigcup_{x\in K}\{U_x\}$$
es un cubrimiento de $K$ que no intersecta a ningún abierto $U_y$ de $y$. Entonces, vemos que
$$X\setminus K=\bigcup_{y\in X\setminus K}U_y,$$
luego es abierto.
\item Sea $\{U_i\}_i$ un cubrimiento abierto de un conjunto $K\subseteq C$ cerrado, luego
$$\mathcal{F}=\{U_i\}_i\cup\{C\setminus K\}$$
es un cubrimiento abierto de $C$, por lo tanto, $\mathcal{F}$ admite subcubrimiento finito $\{B_i\}_i$. Finalmente $\{B_i\}_i\setminus\{C\setminus K\}$ es un subcubrimiento finito de $\{U_i\}_i$ para $K$.
\item Sea $K\subseteq M$ compacto, luego sea $x\in M$ y $k\in K$, definimos $r_k=d(x,k)+1$, luego $\{B_{r_k}(x)\}_{k\in K}$ es un cubrimiento abierto de $K$, por tanto, admite subcubrimiento finito, pero las bolas abiertas son acotadas, luego la unión finita de conjuntos acotados es acotado, es decir, $K$ es acotado.
\end{enumerate}
\end{proof}
\begin{thm}
Un espacio métrico $M$ es compacto syss toda sucesión admite una subsucesión convergente.
\end{thm}
\begin{proof}
Supongamos que $M$ no fuese compacto. Luego existiría un cubrimiento de abiertos sin subcubrimiento finito.

Elíjase $\epsilon\gt 0$ y $s_0\in M$, luego si $B_\epsilon(s_0)\neq M$ existe $s_1$ tal que $d(s_0,s_1)\geq\epsilon$, luego si $B_\epsilon(s_0)\cup B_\epsilon(s_1)\neq M$ existe $s_2$ tal que está a mayor distancia y así sucesivamente. Si $M$ no pudiese cubrirse con un número finito de bolas abiertas podríamos construir una sucesión de esta forma tal que no converge, pues para $\epsilon/2$ no existe $L$ tal que contenga más de un $s_i$ simultáneamente.

Para todo $\epsilon\gt 0$ obtendremos un conjunto de bolas de dicho radio que cubre a $M$.

Tomemos $\epsilon=1$, si el conjunto fuera finito, entonces existe (al menos) una bola $B_1(s_i)$ tal que no es cubrible con finitos abiertos $U_i$. Tomemos $\epsilon=1/2$ y por el mismo razonamiento existe $B_2(s_j)$ tal que no es cubrible con finitos abiertos $U_i$.

Continuando con dicho patrón construimos una sucesión de puntos $\{t_i\}_i$ (con $t_k$ siendo el punto no cubrible de radio $1/(k+1)$) del que extraeremos un punto de acumulación $l$ (que sería límite de alguna subsecuencia). Existe al menos un abierto $U_i$ tal que lo contiene, luego existe $k$ natural tal que $B_{2/(k+1)}(l)\subseteq U_i$, también existe $n\gt k$ natural tal que $d(t_n,l)\lt 1/(k+1)$ (por ser punto límite), luego $B_{1/(n+1)}(t_n)\subseteq B_{2/(k+1)}(l)$ contradiciendo el que $t_n$ era cubrible por finitos abiertos $U_i$.
\end{proof}
Aquí vamos a introducir una noción que podría sonar anti-intuitiva o casi \textit{ilegal} en más de un sentido para lo que hemos desarrollado. Definimos el conjunto \textit{extendido de los reales} como $\overline{\R}\equiv\R\cup\{\pm\infty\}$. Veamos que por teoremas, toda secuencia posee una subsucesión monótona y en $\overline{\R}$ son acotadas por $\pm\infty$, finalmente, son convergentes; por teorema anterior, $\overline{\R}$ es compacto.
\begin{thm}[Teorema de Heine-Borel]
Un subconjunto de $\R$ es compacto syss es cerrado y acotado.
\end{thm}
\begin{proof}
Veamos que todo subconjunto cerrado y acotado (en $\R$) de $\overline{\R}$ es compacto, luego posee subsecuencia convergente, pero como es acotado no converge a $\pm\infty$, es decir, converge a un real, por lo tanto, es compacto.
\end{proof}
Considere un conjunto localmente compacto $X$ no compacto. Definimos $X^\infty=X\cup\{\infty_X\}$, donde $\infty_X$ es un punto externo al conjunto. Aquí definimos un conjunto de subbásicos de $X^\infty$ de la forma $U=\{X\setminus C\}\cup\{\infty_X\}$ donde $C$ son conjuntos compactos de $X$. De esta forma $X^\infty$ es un conjunto compacto, a esta técnica le llamamos \textbf{extensión de Alexandroff} o \textbf{compactificación de un sólo punto}.

De hecho, es posible demostrar que $\R^\infty$ y $(\R^2)^\infty$ son homeomorfas a un círculo y a una esfera respectivamente a través de una función llamada \textit{proyección estereográfica}\footnote{El término usualmente refiere a un homeoformismo entre un espacio $\R^n$ y una $n+1$-esfera, usualmente colocando el centro de la esfera en el origen del espacio.}.
\begin{figure}
\centering
\begin{subfigure}{.7\textwidth}
\centering
\begin{tikzpicture}[thick]
\draw[<->] (-3,0) -- (3,0) node[above]{$\R$};
\begin{scope}[nicered]
\draw (0,0) circle (1) (143:1) -- (-2,0);
\draw[dashed, thin] (0,1) -- (143:1) (0,1) -- (0,-1) (0,1) -- (1,0);
\fill (0,1) circle (.05) node[above]{$f(o)=\infty$} (143:1) circle (.05) node[left]{$p$} (-2,0) circle (.05) (0,0) circle (.05) (0,-1) circle (.05) node[below]{$-o$} (1,0) circle (.05);
\end{scope}
\draw (-2,0) node[below] {$f(p)$} (0,0) node[below left]{0} (1,0) node[below right]{1};
\end{tikzpicture}
\caption{}
\end{subfigure}
\begin{subfigure}{.7\textwidth}
\begin{tikzpicture}[scale=1.3,line join=bevel,tdplot_main_coords, fill opacity=.7]
\begin{scope}
\path[clip] (-3,-3) -- (-3,3) -- (3,3) -- (3,-3) -- cycle;
\draw \foreach \t in {5,...,12} {({\t * 360/16}:1) -- ({\t * 360/16}:{{3*sqrt(2)}})};
\draw \foreach \r in {1.2185, 1.496, 1.870, 2.414, 3.296} {(0,\r) arc (90:270:\r)};
\end{scope}
\begin{scope}[draw opacity=.5,very thin]
\tdplotsphericalsurfaceplot[parametricfill]{36}{16}%
{1}{black}{\tdplottheta}%
   {}%
   {}%
   {}%
\end{scope}
\begin{scope}
\path[clip] (-3,-3) -- (-3,3) -- (3,3) -- (3,-3) -- cycle;
\draw[dashed, opacity=.7] \foreach \t in {0,...,15} {(0,0) -- ({\t * 360/16}:1)};
\draw \foreach \t in {13,...,20} {({\t * 360/16}:1) -- ({\t * 360/16}:{{3*sqrt(2)}})};
\draw \foreach \r in {1.2185, 1.496, 1.870, 2.414, 3.296} {(0,-\r) arc (-90:90:\r)};
\end{scope}
\draw (-3,2.3) node {$\R^2$};
\end{tikzpicture}
\caption{}
\end{subfigure}
\caption{Proyección estereográfica}
\end{figure}

\begin{lem}
Sea $K$ un conjunto compacto e $y$ un elemento no contenido en $K$ en un espacio de Hausdorff $X$. Entonces existen entornos disjuntos $U$, $V$ tal que $K\subset U$ y $y\in V$.
\end{lem}
\begin{proof}
Como $X$ es de Hausdorff y $K$ es compacto, entonces es cerrado. Veamos que, todos los puntos adherentes de $K$ están contenidos en si mismo, luego existe $V$ entorno de $y$ que no le intersecta, y $U$ es la unión de entornos disjuntos para cada $x\in K$ con $y$.
\end{proof}
\begin{thm}
Sea $f:X\rightarrow Y$ continua, con $X$ compacto, entonces $f[X]$ es compacto en $Y$.
\end{thm}
\begin{proof}
Como $f$ es continua, si $A$ es un abierto en $Y$, $f^{-1}(A)$ es abierto en $X$. Como $X$ es compacto debe existir un conjunto finito $\{f^{-1}[A_i]\}_{i\in I}$ tal que es un cubrimiento finito de $X$, luego, $\{A_i\}_{i\in I}$ es un cubrimiento finito de $f[X]$.
\end{proof}
Veamos que esta es una versión más fuerte (es decir, general) del \textit{primer teorema de Weierstrass}.
\begin{mydef}
Una familia de conjuntos $\mathcal{F}$ se dice que posee la \textit{propiedad de intersección finita} cuando todo subconjunto finito $\mathcal{G}$ satisface
$$\bigcap\mathcal{G}\neq\emptyset.$$
\end{mydef}
\begin{lem}
Sea $X$ un espacio topológico, es compacto syss toda familia de cerrados que poseee la propiedad de intersección finita posee intersección no vacía.
\end{lem}
\begin{proof}
$\implies$. Sea $X$ un espacio topológico compacto y $E=\{E_i\}$ una familia de cerrados con intersección finita, entonces $\mathcal{F}=\{X\setminus E_i\}$ es una familia de abiertos. Veamos que sería un cubrimiento abierto si $\bigcap E=\emptyset$, luego como $X$ es compacto, debería existir un $\mathcal{G}$ tal que sería un subcubrimiento abierto y luego habría un subconjunto finito $D\subset E$ tal que $\bigcap D=\emptyset$, contradicción.

$\Longleftarrow$. Supongamos que $\mathcal{F}=\{U_i\}$ es un cubrimiento abierto de $X$ y sea $E=\{X\setminus U_i\}$. Veamos que si $\mathcal{F}$ no tuviese subcubrimientos finitos de $X$, entonces $E$ tendría la propiedad de intersección finita, luego tendría intersección no vacía (por tanto no sería un cubrimiento abierto), contradicción.
\end{proof}
\begin{lem}[Lema de Subbase de Alexander]
Deja que $X$ sea un espacio topológico con subbase $S$. Si toda colección de conjuntos de $S$ que cubre a $X$ tiene un subcubrimiento finito, entonces $X$ es compacto.
\end{lem}
\begin{proof}
Esta prueba requiere el lema de Zorn que como vimos en la sección~\ref{sec:big-cardinals} es equivalente al Axioma de Elección.

Supongamos por contradicción que $X$ no fuese compacto, por lo cuál habría una cubierta de abiertas $\mathcal{C}_0$ sin subcubierta finita. Construyamos una familia $\mathcal{F}$ de cubiertas sin subcubiertas finitas. En particular $\mathcal{F}$ es parcialmente ordenado por $\subseteq$, y toda cadena admite cota superior, luego por lema de Zorn existe un elemento maximal $\mathcal{C}$.

Como estamos tratando con subbases, conviene escribir un abierto $U_\alpha\in\mathcal{C}$ como $U_\alpha=\bigcap_{i\in I}S_{\alpha_i}$, donde $S_{\alpha_i}$ son subbases. Al menos algún $S_\alpha\in\mathcal{C}$, esto también lo demostraremos por contradicción.

Entonces para cada $S_{\alpha_i}\notin\mathcal{C}$ se da que $\mathcal{C}\cup\{S_{\alpha_i}\}\notin\mathcal{F}$, por lo tanto, tiene subcubierta finita de $X$, luego $\mathcal{C}$ tiene subcubierta finita de $X\setminus S_{\alpha_i}$. Nótese que
$$X\setminus U_\alpha=\bigcup_{i\in I}(X\setminus S_{\alpha_i}),$$
pero como $\mathcal{C}$ cubre finitamente todo $X\setminus S_{\alpha_i}$, entonces cubre finitamente $X\setminus U_\alpha$. Pero $X=(X\setminus U_\alpha)\cup U_\alpha$, luego $\mathcal{C}$ lo cubre finitamente.

Entonces para todo $U_\beta$ existe un subbásico $S_\beta\supseteq U_\beta$, entonces $\{S_\alpha\}$ es una cubierta de subbásicos que por construcción posee subcubierta finita, luego existe una cubierta finita de abiertos $\{U_\alpha\}$ para $X$, lo que implica que $\mathcal{F}$ debe ser vacío. Finalmente $X$ es compacto.
\end{proof}
\begin{thm}
En ZF son equivalentes:
\begin{description}
\item[\color{thm}\sffamily\itshape Axioma de Elección (AC).]
\item[\color{thm}\sffamily\itshape Teorema de Tychonoff (TT):] Sea $A=\{X_i\}_{i\in I}$ una familia de espacios compactos, entonces $X=\prod A=\prod_{i\in I}X_i$ es compacta.
\end{description}
\end{thm}
\begin{proof}
$\rm AC\implies TT$. Veamos que AC implica ZL lo que implica el lema de subbases de Alexander.

Como todo $X_\alpha$ es compacto, $\{U_{\alpha_i}\}$ es una cubierta abierta con subcubierta finita. Y $p_\alpha^{-1}$ (la inversa de la proyección) es continua y suprayectiva. Evidentemente $\{p_\alpha^{-1}(U):U\text{ abierto en }X_\alpha,\text{ para algún }\alpha\}$ es una subbase en $X$. Téngase que $\mathcal{U}$ es una cubierta de $X$, luego existe $\mathcal{U}_\alpha\subseteq\mathcal{U}$ tal que todo abierto ``inicial'' lo es en $X_\alpha$. Existe algún $\beta$ tal que $\mathcal{U}_\beta$ sea una cubierta de $X_\beta$. De lo contrario (si no existiese algún $\mathcal{U}_\beta$) existiría algún punto $x_0\in X_\beta$ no \textit{cubierto}, de forma que (o al menos algún punto de) $p_\beta^{-1}[x_0]\subseteq X$ no estaría cubierto por $\mathcal{U}$. Contradicción.

Luego, como $\mathcal{U}_\beta$ es la inversa de la proyección de abiertos $U$ que cubren $X_\beta$, por construcción, $X_\beta$ es compacto, por lo tanto, existe un subconjunto finito de $\mathcal{U}_\beta$ tal que cubre a $X_\beta$ (y por tanto a $X$), nótese que $\mathcal{U}_\beta$ era una colección de subbases, por lema de Alexander queda demostrado.

$\rm TT\implies AC$. Para aplicar el teorema de Tychonoff debemos sacar conjuntos compactos, suponga que tenemos una familia de conjuntos $\{X_i\}_{i\in I}$ no vacíos, luego construimos $Y_i=X_i\cup\{\infty_i\}$, donde $\infty_i$ es simplemente un elemento no incluido en $X_i$ (usualmente llamado aislado) y le otorgaremos la topología $\tau_i=\{\emptyset,\{\infty_i\},X_i,Y_i\}$. Como los abiertos son finitos, toda cobertura abierta es finita, luego todo $Y_i$ es compacto y $\prod_{i\in I}Y_i$ es compacto.
\end{proof}
Cabe destacar que hay varias demostraciones del Teorema de Tychonoff, todas dependen de AC para funcionar, sin embargo, hay un par de pseudo-demostraciones para casos particulares en donde $\mathcal{X}$ es numerable para los cuales no se requiere AC.
\begin{thm}
Supongamos que $f:X\rightarrow\R$ con $X$ un espacio compacto no vacío, existen $a,b\in X$ tales que para todo $x\in X$ $f(a)\leq f(x)\leq f(b)$.
\end{thm}
\begin{proof}
Definamos $Y=f[X]$. Como $f$ es continua y $X$ compacto, $Y$ es compacto en $\R$, luego es un cerrado acotado, por lo tanto, posee ínfimo $m$ y supremo $M$. Probaremos que $M\in Y$.

Tómese un $\epsilon\gt 0$, luego existe $y\in Y$ tal que $M-\epsilon\lt y$ (por definición del supremo), es decir, toda bola abierta $B_\epsilon(M)$ intersecta a $Y$. Luego $M\in\overline{Y}$ (clausura de $Y$), pero como $Y$ es cerrado, $M\in Y$. Es análogo para $m$.
\end{proof}
\begin{thm}
Todo subconjunto cerrado y acotado de $\R^n$ es compacto.
\end{thm}
\begin{proof}
La primera pregunta que debe acudir al lector es sobre ¿qué significa que un subconjunto de $\R^n$ sea acotado? Bueno, $\R$ posee una norma y en teoría, un elemento $M\in\R$ se considera cota de $A\subset\R$ syss $\forall a\in A, \Vert a\Vert\leq\Vert M\Vert$, asimismo se generaliza para $\R^n$. Tomemos la norma $\Vert\,\Vert_\infty$ para $\R^n$ (evidentemente $\Vert M\Vert$ es un real positivo).

Nótese que si tomásemos cualquier norma $L_p$ sabemos que $\Vert x\Vert_p\leq n\Vert x\Vert_\infty$.

Ademas que si para todo $x\in X\subset\R^n$ se cumple $\Vert x\Vert\leq M$ (por ser acotado) entonces para todo $x_i=p_i(x)$ se cumple que $x_i\in[-M,M]$, luego $X\subseteq[-M,M]^n$, por teorema de Tychonoff, $[-M,M]^n$ es compacto y un subconjunto cerrado de un compacto es compacto.
\end{proof}

\section{Espacios conexos}
Además de las distintas categorías en las que puede caer un conjunto por el momento, existe otra bastante diferente que no hemos tratado que es la idea de que un conjunto puede estar ``unido''. En esencia ello significa que si lo cortamos en un par (en el sentido formal de la palabra) estos terminan estando ``conectados'', o mejor dicho, no están separados. Veamos que $[0,1]$ cumple lo que deseamos y lo podemos cortar en $[0,1/2[$ y $[1/2,1]$. Por definición de corte, son disjuntos y su unión es el original; pero la clausura de uno intersecta al otro, a su vez queremos que esto sea independiente de a cual le apliquemos clausura:
\begin{mydef}[Espacio conexo]
Decimos que un par $A,B$ está \textit{separado} syss $A\cap\overline{B}$ o $\overline{A}\cap B$ son vacíos.

Decimos que $X$ es conexo si para todo corte en $A,B$ resultan no estar separados.
\end{mydef}
Otra definición equivalente para un espacio disconexo es un espacio topológico tal que existen un par de abiertos $U,V$ no vacíos disjuntos tal que su unión es $X$.
\begin{thm}
Veamos que un conjunto $I$ es conexo en $\overline{\R}$ syss es un intervalo.
\end{thm}
\begin{proof}
$\implies$. Sea $I$ un conjunto conexo de extremos $a,b$ (siendo su ínfimo y supremo respectivamente), luego para todo $x$ tal que $a\lt x\lt b$ entonces $x\in I$. De lo contrario, existirían $I\cap[-\infty, x)$ e $I\cap(x,\infty]$ abiertos disjuntos tales que su unión sería $I$.

$\Longleftarrow$.
\end{proof}
\begin{thm}
La imagen de un conjunto conexo es conexo a través de una aplicación continua.
\end{thm}
\begin{thm}
El producto cartesiano de conjuntos conexos es conexo.
\end{thm}

\section{Series infinitas}
\begin{mydef}[Serie]
Sea $\{a_n\}_n$ una secuencia de números, una serie es una secuencia de forma
$$s_n=\sum_{i=1}^n a_i=a_1+a_2+\cdots+a_n,$$
escribimos el límite como
$$s=\sum_{i=1}^\infty a_i.$$
\end{mydef}
El clásico ejemplo es la \textbf{serie geométrica}, que consiste en la siguiente, donde $|r|\lt 1$:
$$S_N=\sum_{k=0}^N r^k=1+r+r^2+\cdots+r^N,$$
para deducir a qué converge, podemos multiplicar la serie por $r$ para ver que
$$rS_N=r+r^2+\cdots+r^N+r^{N+1},$$
restando ambos obtenemos que
$$(1-r)S_N=1-r^{N+1}\iff S_N=\frac{1-r^{N+1}}{1-r},$$
finalmente, aplicamos límite cuando $N\to\infty$, $|r|\lt 1$ syss $\lim_N r^{N+1}=0$, por lo tanto
\begin{equation}
\sum_{k=0}^\infty r^k=1+r+r^2+\cdots=\frac{1}{1-r}.
\end{equation}
\begin{thm}
Sea $S_n=\sum_{k=0}^na_k$ una serie en un cuerpo métrico. Si $S_n$ es convergente, entonces $\lim_n a_n=0$.
\end{thm}
\begin{proof}
Es fácil probar que si $\lim_n S_n=L$ entonces $\lim_n S_{n+1}=L$, luego $\lim_n S_{n+1}-S_n=\lim_n a_{n+1}=\lim_n a_n=0$.
\end{proof}
Sin embargo, el recíproco no siempre es correcto. El mejor ejemplo es la \textbf{serie harmónica}, que diverge:
$$S_n=\sum_{k=1}^n\frac{1}{k}=1+\frac 12+\frac 13+\cdots,$$
para demostrarlo veamos que por desigualdades observamos el siguiente fenómeno
\begin{align*}
&S_1=1,\quad S_2=1+\frac{1}{2},\quad S_4=1+\frac{1}{2}+{\color{niceblue}\frac{1}{3}+\frac 14}\gt 1+\frac 12+2{\color{niceblue}\frac 14}=1+\frac{2}{2},\\
&S_8\gt 2+{\color{niceblue}\frac 15+\frac 16+\frac 17+\frac 18}\gt 2+4{\color{niceblue}\frac 18}=2+\frac 12=1+\frac{3}{2},
\end{align*}
el patrón es claro, para todo $S_{2^n}\geq 1+n/2$. Luego satisface la definición de divergente (a infinito).
\begin{thm}[Test de comparación]
Sean $S_n=\sum^n_{k=0}a_k,T_n=\sum^n_{k=0}b_k$ series tales que $0\leq a_n\leq b_n$ para todo $n$, luego si $T_n$ es convergente, $S_n$ lo es.
\end{thm}
\begin{proof}
Veamos que en realidad es trivial, puesto que como $a_n,b_n$ son términos no-negativos, las series son monótonas crecientes, si $T_n$ es convergente es una cota superior de $S_n$, luego es convergente.
\end{proof}
\begin{thm}[Test de la serie alternada o criterio de Leibniz]
Sea $a_n$ una secuencia decreciente de términos no-negativos. La serie $S_n=\sum_{k=0}^\infty(-1)^na_n$ y la serie $T_n=\sum_{k=0}^\infty(-1)^{n+1}a_n$ es convergente syss $\lim_n a_n=0$.
\end{thm}
\begin{proof}
$\implies$. Si la serie alternada es convergente entonces el argumento converge a cero, luego tomando valor absoluto el límite es inmediato.

$\Longleftarrow$. Veamos que
$$S_{2n}=(a_0-a_1)+\cdots+(a_{2n-2}-a_{2n-1})+a_{2n},$$
lo que resulta en que $S_{2n}$ es una sucesión monótona decreciente (pues $S_{2(n+1)}=S_{2n}+(-a_{2n+1}+a_{2n+2})\leq S_{2n}$) acotada por $a_0$ y 0, luego converge en un cierto valor $L$. Luego, la sucesión $S_{2n+1}=S_{2n}+a_{2n+1}$ es también convergente pues $\lim_n S_{2n+1}=L+\lim_n a_{2n+1}$. Luego es fácil ver que $S_n$ converge en $L$. Nótese que $T_n=-S_n$.
\end{proof}
Veamos que por ello, la serie $\sum_{k=1}^\infty (-1)^{n+1}/n$ es convergente.
\begin{thm}[Test de condensación de Cauchy]
Sea $a_n$ una secuencia monótona decreciente de términos no-negativos. La serie $S_n=\sum_{k=0}^n a_k$ converge syss $T_n=\sum_{k=0}^n 2^ka_{2^k}$ converge.
\end{thm}
\begin{proof}
Para todo $n$ fijo elíjase $k$ tal que $n\leq 2^k$, puede verse que
\begin{align*}
S_n&=a_1+(a_2+a_3)+\cdots+a_n\\
&\leq a_1+2a_2+\cdots+(a_{2^k}+\cdots+a_{2^{k+1}-1})\\
&\leq a_1+2a_2+\cdots+2^ka_{2^k}=T_k,
\end{align*}
luego $S_n$ está acotada por $T_k$, luego si $T_k$ converge $S_n$ lo hará.

Análogamente, sea $k$ fijo elíjase $n$ tal que $n\geq 2^k$, puede verse que
\begin{align*}
S_n&=a_1+a_2+(a_3+a_4)+\cdots+a_n\\
&\geq\frac 12a_1+a_2+2a_4+\cdots+(a_{2^{k-1}+1}+\cdots+a_{2^k})\\
&\geq\frac 12(a_1+2a_2+\cdots+2^ka_{2^k})=\frac 12T_k,
\end{align*}
luego $T_k$ está acotado por $S_n$, luego si $S_n$ converge $T_k$ lo hará.
\end{proof}
Similarmente podríamos elegir cualquier base mayor o igual a 2 para el test. Es trivial ver que la demostración de la divergencia de la serie harmónica es la inspiración de este test.
\begin{thm}[Criterio de d'Alambert]
Sea $S_n=\sum_{k=0}^n a_k$, tal que $a_n$ es un real no-negativo y $\lim_n a_{n+1}/a_n=L$ existe, luego
\begin{itemize}
\item Si $L\lt 1$ entonces $S_n$ converge.
\item Si $L\gt 1$ entonces $S_n$ diverge.
\end{itemize}
\end{thm}
\begin{proof}
Supongamos que $L\lt 1$, existe $\epsilon\gt 0$ tal que $L+\epsilon\lt 1$, a su vez, existe $n_0$ tal que para todo $n\geq n_0$ se da $a_{n+1}/a_n\lt L+\epsilon$, es decir, $a_{n+1}\lt a_n(L+\epsilon)$, en particular, $a_{n_0+1}\lt a_{n_0}(L+\epsilon)$, luego $a_{n_0+2}\lt a_{n_0+1}(L+\epsilon)\lt a_{n_0}(L+\epsilon)^2$, en general:
$$a_n\leq a_{n_0}(L+\epsilon)^{n-n_0}\implies S_n\leq\sum_{k=0}^{n_0}a_k+\frac{a_{n_0}}{(L+\epsilon)^{n_0}}\sum_{k=n_0+1}^n(L+\epsilon)^k.$$
Veamos que la última serie converge pues el primer término es finito y el segundo es una parte de una serie geométrica con razón menor a uno. Como los términos son no-negativos, la serie se comporta como una sucesión monótona creciente y acotada, luego es convergente.

En caso contrario, existe $\epsilon\gt 0$ tal que $L-\epsilon\gt 1$, análogamente vemos que existe un $n_0$ tal que para todo $n\geq n_0$:
$$a_n\geq a_{n_0}(L-\epsilon)^{n-n_0}\implies S_n\geq\sum_{k=0}^{n_0}a_k+\frac{a_{n_0}}{(L-\epsilon)^{n_0}}\sum_{k=n_0+1}^n(L-\epsilon)^k.$$
Pero el término de la derecha diverge pues es geométrica para razón mayor que uno.
\end{proof}
Nótese que hay un caso particular que ocurre cuando $L=1$, ahí, el criterio no otorga información, aun que veremos que no serán muchos los casos en que ello ocurra, la serie harmónica es un ejemplo.
\begin{thm}[Criterio de convergencia de Cauchy]
Una serie $\sum_{k=0}^\infty a_k$ converge en un espacio métrico $M$ completo syss para todo $\epsilon\gt 0$ existe $n_0$ natural tal que para todo $n\geq n_0$
$$\left\Vert\sum_{k=n_0+1}^na_k\right\Vert\lt\epsilon$$
\end{thm}
\begin{proof}
Veamos que como $M$ es métrico y posee norma $\Vert\,\Vert$, se define $d(a,b)=\Vert a-b\Vert$, luego, esta es la condición que demuestra que la serie es una secuencia o sucesión de Cauchy, pues es evidente que
$$\left\Vert\sum_{k=0}^na_k-\sum_{k=0}^{n_0}a_k\right\Vert=\left\Vert\sum_{k=n_0+1}^na_k\right\Vert,$$
luego, como $M$ es completo, converge.
\end{proof}
\begin{thm}[Convergencia absoluta]
Decimos que una serie $S_n=\sum_{k=0}^n a_k$ sobre un espacio métrico completo $M$ es convergente absolutamente syss la serie $T_n=\sum_{k=0}^n\Vert a_k\Vert$ converge.

Si una serie converge absolutamente entonces converge normalmente.
\end{thm}
\begin{proof}
Como es convergente absolutamente, por criterio de Cauchy vemos que para todo $\epsilon\gt 0$ existe $n_0$ natural tal que para todo $n\geq n_0$:
$$\Vert S_n-S_{n_0}\Vert\leq T_n-T_{n_0}\lt\epsilon.$$
\end{proof}
Si una serie converge pero no absolutamente, entonces decimos que converge \textit{condicionalmente}. Un ejemplo de serie condicionalmente convergente es $\sum_{k=1}^\infty(-1)^{k+1}/k$.
\begin{thm}[Producto de Cauchy]
Sean $A_n=\sum_{k=0}^n a_k,B_n=\sum_{k=0}^n b_k$ convergentes, alguna siéndolo absolutamente convergente, entonces
$$\lim_nA_n\cdot B_n=\sum_{k=0}^\infty\sum_{j=0}^k a_jb_{k-j}.$$
\end{thm}
\begin{proof}
Supongamos que $A_n$ converge absolutamente y llamemos $C_n$ al producto de Cauchy hasta el $n$-ésimo término, y $B$ al límite de $B_n$. También definamos $\beta_n=B_n-B$. Véase que
\begin{align*}
C_n&=a_0b_0+(a_0b_1+a_1b_0)+\cdots+(a_0b_n+a_1b_{n-1}+\cdots+a_nb_0)\\
&=a_0B_n+a_1B_{n-1}+\cdots+a_nB_0\\
&=a_0(B+\beta_n)+a_1(B+\beta_{n-1})+\cdots+a_n(B+\beta_0)\\
&=A_nB+(a_0\beta_n+a_1\beta_{n-1}+\cdots+a_n\beta_0),
\end{align*}
vemos que lo que hay que probar realmente es que el término de la derecha converge a cero, es decir que $\gamma_n=\sum_{k=0}^na_k\beta_{n-k}\to 0$. Veamos que como $\sum_{k=0}^\infty|a_k|=\alpha$ y $M\equiv\sup\{|\beta_n|\}$ (pues como $\beta_n\to0$ es acotada) entonces existe $n_0$ tal que para todo $n\geq n_0$ se da que $\sum_{k=n_0+1}^n|a_k|\lt\epsilon/2M$ y $|\beta_n|\lt\epsilon/2\alpha$, luego
\begin{align*}
\gamma_n&\leq\sum_{k=0}^n|a_kb_{n-k}|=\sum_{k=0}^{n_0}|a_kb_{n-k}|+\sum_{k=n_0+1}^n|a_kb_{n-k}|\\
&\lt\frac{\epsilon}{2\alpha}\sum_{k=0}^{n_0}|a_k|+M\sum_{k=n_0+1}^n|a_k|\lt\frac{\epsilon}{2\alpha}\alpha+M\frac{\epsilon}{2M}=\epsilon.
\end{align*}
Lo que satisface la definición de límite, por lo tanto, la demostración está completa.
\end{proof}
\begin{figure}
\centering
\begin{tabular}{c|cccc}
$\cdot$ & $b_0$ & $b_1$ & $b_2$ & $\cdots$ \\ \hline
$a_0$ & 1 & 2 & 3 & $\cdots$ \\
$a_1$ & 2 & 3 & 4 \\
$a_2$ & 3 & 4 & 5 \\
$\vdots$ & $\vdots$ & & & $\ddots$
\end{tabular}
\caption{Producto de Cauchy visualizado.}
\end{figure}
\begin{thm}
Sea $\sum_{k=0}^\infty a_k$ una serie que converge absolutamente y $\sigma:\N\rightarrow\N$ una biyección. Entonces $\sum_{k=0}^\infty a_{\sigma(k)}$ es absolutamente convergente y posee mismo límite.
\end{thm}
\begin{mydef}[Serie de potencias]
Es una serie en un espacio métrico $M$, de la forma:
$$\sum_{k=0}^\infty a_k(z-a)^k$$
Tales que $a$ y $a_k$ están en $M$, y $z$ puede tomar cualquier valor en $M$.
\end{mydef}
El producto de Cauchy está escrito específicamente para series de potencias, nótese que si $A=\sum_{k=0}^\infty a_kx^k$ y $B=\sum_{k=0}^\infty b_kx^k$, el producto es otra serie de potencias, es decir, $A\cdot B=\sum_{k=0}^\infty c_kx^k$.
\begin{mydef}[Límites superiores e inferiores]
Sea $\{s_n\}_n$ una sucesión de números sobre $\R$. Decimos que su \textit{límite superior} es
$$\limsup_ns_n=\inf\left\{\sup_{k\geq n}s_k:n\geq 0\right\},$$
análogamente, decimos que su \textit{límite inferior} es
$$\liminf_ns_n=\sup\left\{\inf_{k\geq n}s_k:n\geq 0\right\}.$$
\end{mydef}
\begin{figure}
\centering
\begin{tikzpicture}
\begin{axis}[demo,
	ymin=-2, ymax=5,
	samples=100,
	smooth,
	xlabel = $x$, ylabel = {$f(x)$}
]
\addplot[niceblue, domain=0:.9] {2+(x^2+x+1)/(2*x^2-2)*sin(deg(x^(1.6)))};
\addplot[niceblue, domain=1.1:12] {2+(x^2+x+1)/(2*x^2-2)*sin(deg(x^(1.6)))};
\addplot[nicered, domain=0:12] {2.5} node[above left, pos=1]{$\displaystyle\limsup_{x\to\infty}f(x)$};
\addplot[nicegreen, domain=0:12] {1.5} node[below left, pos=1]{$\displaystyle\liminf_{x\to\infty}f(x)$};
\end{axis}
\end{tikzpicture}
\caption{Ejemplo de $\limsup$ y $\liminf$.}
\end{figure}
\begin{thm}
Sea $M$ un cuerpo métrico completo y $S(z)=\sum_{k=0}^\infty a_k(z-a)^k$ con $a,a_k\in M$. Definamos $R=1/\limsup\sqrt[n]{a_n}$ (Si $R=1/0=+\infty$ y $R=1/\infty=0$). Entonces la serie converge absolutamente en todo compacto subconjunto de $B_R(a)$ y diverge en todo punto de $M\setminus B^\prime_R(a)$ (con $B_\infty(a)=M$).
\end{thm}
\begin{proof}

\end{proof}
Luego a $R$ --por razones obvias-- se le denomina radio de convergencia.

\chapter{Diferenciación}
La aplicación más común de los límites da paso a una de las herramientas más útiles y necesarias de toda la matemática: la derivada. En cierta forma, todos ya estamos familiarizados con la derivada, en el álgebra lineal a través de las rectas, en mecánica con la velocidad y la aceleración, hasta en programación con las redes neuronales, pero introducir a esta idea no es tan sencillo.

Para ello queremos comenzar por sintetizar la idea de lo que el ``límite'' de una función, significa. Esencialmente $\lim_{x\to c}f(x)=l$ significa que para todo punto (infinitamente) cercano de $c$ obtenemos una imagen (infinitamente) cercana a $l$. Esta idea es necesaria porque formaliza la continuidad y determina comportamientos de ``puntos faltantes''. La derivada es un tipo de límite, pero que no podemos incluir sin una introducción básica.

\section{Derivación}
\begin{mydef}[Ecuación de la recta]
Sea $f:\R\rightarrow\R$ una función, su gráfica será una recta si está escrita en forma
$$f(x)=mx+h,$$
donde $m,h$ son parámetros de la función (constantes ya definidas), tal que $f(0)=h$ y $f(-h/m)=0$. $m$ es llamado la \textit{pendiente} de la recta.
\end{mydef}
\begin{figure}
\centering
\begin{tikzpicture}
\begin{axis}[demo,
	ticks = major,
	xtick = {-4}, xticklabel = {$-\dfrac{h}{m}$},
	ytick = {2}, yticklabel = {$h$},
	xlabel = $x$, ylabel = {$f(x)$}
]
\addplot[niceblue,thick,domain=-6:6] {2+.5*x};
\end{axis}
\end{tikzpicture}
\caption{Gráfico de $f(x)$.}
\end{figure}

En general, si queremos que la recta contenga al punto $(a,f(a))$ y posea pendiente $m$, la ecuación será
\begin{equation}
f(x)=m(x-a)+f(a),
\end{equation}
finalmente, para despejar $m$, nótese que si sabemos que la recta contiene otro punto $(b,f(b))$, entonces
\begin{equation}
m=\frac{f(b)-f(a)}{b-a},
\end{equation}
también, otra forma que puede tener la ecuación es con un punto que está a $h$ unidades de $a$ en el eje $x$, es decir, un punto $(a+h,f(a+h))$, de forma que la pendiente es
\begin{equation}
m=\frac{f(a+h)-f(a)}{h}.
\end{equation}
Ahora, veamos que si tenemos una función cualquiera $f:D\subseteq\R\rightarrow\R$, podemos elegir un punto cualquiera de $a$ y utilizar nuestro conjunto de ecuaciones que pase por este y otro punto del gráfico, sin embargo, en el límite cuando este segundo punto $x\to a$ es cuando se forma una recta \textit{tangente}\footnote{Que sólo intersecta el gráfico en un punto localmente.} a la gráfica.
\begin{mydef}[Derivable]
Decimos que una función $f:D\subseteq\R\rightarrow\R$ es \textit{derivable} en un punto $a$ si existen ambos límites:
\begin{align}
f'(a)&=\lim_{\epsilon\to 0}\frac{f(a+\epsilon)-f(a)}{\epsilon}\\
&=\lim_{x\to a}\frac{f(x)-f(a)}{x-a}.
\end{align}
\end{mydef}
Nótese que por esta definición podemos admitir que existe una función llamada \textit{derivada} $f'(x)$ de $f$, tal que la imagen es el límite en dicho punto $x$.
\begin{thm}
Sea $f:D\subseteq\R\rightarrow\R$ y $\epsilon\gt 0$ un infinitesimal, decimos que la derivada en $a$ es el estándar $f'(a)$ tal que
$$\frac{f(a+\epsilon)-f(a)}{\epsilon}\simeq f'(a),$$
cabe decir que usualmente se utiliza una $h$, aunque prefiero la letra $\epsilon$ pues ya la hemos asociado a una cantidad pequeña.
\end{thm}
\begin{proof}
Veamos que esta propiedad es consecuencia directa a la definición no estándar de límite.
\end{proof}
\begin{figure}
\centering
\begin{tikzpicture}
\begin{axis}[demo,
	ymin = 2, ymax = 14,
	xlabel = $x$, ylabel = {$f(x)$}
]
\addplot[niceblue, domain = 0:12, very thick, smooth] {1/8*(x-2)*(x-6)*(x-9)+8};
\begin{scope}[nicered, dashed, domain = 0:12, mark = none]
\addplot {2.75*(x-8) + 6.5};
\addplot {1.5*(x-8) + 6.5};
\addplot {0.96875*(x-8) + 6.5};
\end{scope}
\addplot [nicepurple, domain = 0:12, thick] {.5*(x-8) + 6.5};
\end{axis}
\end{tikzpicture}
\caption{Comparación de la derivada}
\label{fig:derivative-comparasson}
\end{figure}

La figura~\ref{fig:derivative-comparasson} demuestra como se comporta la derivada ante una función y punto cualquiera, veamos que si tomamos la fórmula y escogemos valores arbitrarios para $h$ mientras más pequeño, más exacta se vuelve la recta, lo que corresponde a las rectas punteadas. La recta púrpura es completamente tangente a la función, es decir, sería aquella dada por la función
$$g(x)=f'(a)(x-a)+f(a).$$
\begin{thm}
Sea $f:D\subseteq\R\rightarrow\R$, si es derivable en $a$ entonces es también continua en $a$ (pero no necesariamente se cumple la inversa).
\end{thm}
\begin{proof}
Tanto la demostración estándar como no estándar son similares, así que utilizaremos el segundo método:

Veamos que si la función es derivable entonces
\begin{align*}
\frac{f(a+\epsilon)-f(a)}{\epsilon}&\simeq f'(a)\\
f(a+\epsilon)-f(a)&\simeq\epsilon\cdot f'(a)\simeq 0\\
f(a)&\simeq f(a+\epsilon),
\end{align*}
como se quería probar.
\end{proof}
\begin{thm}
Sean $f:D\subseteq\R\rightarrow\R$ y $g:E\subseteq\R\rightarrow\R$ derivables en $a$ con $r\in\R$, entonces
\begin{enumerate}[$a)$]
\item $(f\pm g)'(a)=f'(a)\pm g'(a)$.
\item $(r\cdot f)'(a)=r\cdot f'(a)$.
\item $(f\cdot g)'(a)=f'(a)g(a)+f(a)g'(a)$.
\item Si $g(a)\neq 0$, entonces:
$$(f/g)'(a)=\frac{f'(a)g(a)-f(a)g'(a)}{g^2(a)}.$$
\end{enumerate}
\end{thm}
\begin{proof}
\begin{enumerate}[$a)$]
\item Es trivial.
\item Es trivial.
\item
\begin{align*}
(f(a)g(a))'&=\lim_{\epsilon\to 0}\frac{f(a+\epsilon)g(a+\epsilon)-f(a)g(a)}{\epsilon}\\
&=\lim_{\epsilon\to 0}\frac{f(a+\epsilon)g(a+\epsilon)-f(a+\epsilon)g(a)+f(a+\epsilon)g(a)-f(a)g(a)}{\epsilon}\\
&=\lim_{\epsilon\to 0}f(a+\epsilon)\frac{g(a+\epsilon)-g(a)}{\epsilon}+g(a)\lim_{\epsilon\to 0}\frac{f(a+\epsilon)-f(a)}{\epsilon}
\end{align*}
Ahora, nótese que como $f$ es derivable en $a$, es continua en $a$ y por tanto, $\lim_{\epsilon\to 0}f(a+\epsilon)=f(a)$, por lo tanto
$$(f(a)g(a))'=f'(a)g(a)+f(a)g'(a).$$
\item Es análoga a $c)$.
\end{enumerate}
\end{proof}
\begin{thm}[Regla de la cadena]
Sea $f:A\subseteq\R\rightarrow\R$ y $g:B\subseteq\R\rightarrow\R$ con $B\supseteq\Img f$, $f$ derivable en $a$ y $g$ derivable en $b=f(a)$, entonces
$$(f\circ g)'(a)=g'(b)\cdot f'(a).$$
\end{thm}
\begin{proof}
Veamos que
\begin{align*}
(f\circ g)'(a)&=\lim_{\epsilon\to 0}\frac{g(f(a+\epsilon))-g(f(a))}{\epsilon}\\
&=\lim_{\epsilon\to 0}\frac{g(f(a+\epsilon))-g(f(a))}{f(a+\epsilon)-f(a)}\frac{f(a+\epsilon)-f(a)}{\epsilon}\\
&=f'(a)\cdot\lim_{b\to f(a)}\frac{g(b)-g(f(a))}{b-f(a)}\\
&=g'(f(a))\cdot f'(a),
\end{align*}
tal como queríamos probar.
\end{proof}
\begin{mydef}
Decimos que $f:D\subseteq X\rightarrow Y$ con $X,Y$ anillos ordenados, es monótona \textit{creciente} cuando para todo $x\lt y$ se cumple que $f(x)\leq f(y)$; es monótona \textit{decreciente} cuando para todo $x\lt y$ se cumple que $f(x)\geq f(y)$. Si las inecuaciones son estrictas se dice que $f$ también lo es.
\end{mydef}
\begin{thm}
Si $f:D\subseteq\R\rightarrow\R$ es inyectiva y continua, entonces es estrictamente monótona.
\end{thm}
\begin{proof}
Tomemos un par $a,b\in A$ tales que $a\lt b$ y, supongamos que $f(a)\lt f(b)$, si $x\in(a,b)$ entonces $f(a)\lt f(x)\lt f(b)$ ($f(x)\lt f(a)$ por ejemplo es un caso imposible por teorema de valores intermedios), luego introducimos otro valor $y\in(x,b)$ y vemos que $f(x)\lt f(y)\lt f(b)$. Y para probar que es monótona, veremos que si $a\lt b$ y $u\lt v$ tal que $f(a)\lt f(b)$ y $f(u)\gt f(v)$, luego elegimos los puntos máximos y mínimos, y terminamos viendo que el resultante intervalo es imposible por el ya dicho teorema.
\end{proof}
\begin{thm}[Teorema de la función inversa]
Sea $A$ un intervalo abierto tal que $f:A\rightarrow\R$ es una función derivable en $A$ cuya función derivada es nunca nula, entonces:
\begin{enumerate}[$a)$]
\item $f$ es estrictamente monótona.
\item Sea $f'(x)\gt 0$, entonces $f$ es estrictamente creciente.
\item Sea $f'(x)\lt 0$, entonces $f$ es estrictamente decreciente.
\item Existe un intervalo abierto $B$ tal que $f:A\rightarrow B$ es biyectiva.
\item $g=f^{-1}:B\rightarrow A$ es derivable, para todo $x\in A$ se da que $y=f(x)\in B$ y
\begin{equation}
g'(y)=\frac{1}{f'(x)}.
\end{equation}
\end{enumerate}
\end{thm}
\begin{proof}
\begin{enumerate}[$a)$]
\item Veamos que es corolario del teorema anterior.
\item Por $a)$ sabemos que $f$ es estrictamente monótona, por lo tanto, para todo $x\lt y$ se debe cumplir que $f(x)\lt f(y)$ o $f(x)\gt f(y)$, como
$$\frac{f(x+\epsilon)-f(x)}{\epsilon}\gt 0$$
para todo $\epsilon\gt 0$ infintesimal, entonces debe darse que $f(x)\lt f(y)$.
\item Es análogo a $b)$.
\item Como $A$ es intervalo abierto podemos decir que posee ínfimo $a$ y supremo $b$, de forma que $x\in A$ syss $a\lt x\lt b$. Por $a)$, podemos ver que $f(a)\lt f(x)\lt f(b)$ (o al revés) y por teorema de los valores intermedios, vemos que $B=(f(a),f(b))$.
\item Veamos que por $g$ es continua pues si $y=f(x)$ (de modo que $g(y)=x$) se ve que para todo entorno $U=B_r(x)\subseteq A$, $f[U]=g^{-1}[U]=V$ es un entorno de $y$ ya que por $a)$, asumimos que $f$ es creciente y $V$ es un intervalo abierto conteniendo a $y$.

La demostración de la fórmula de la derivada se basa en primero ver que $g(y+\epsilon)-g(y)=\delta\neq 0$ para todo $\epsilon\neq 0$ (pues es estrictamente monótona) y que $\delta\to 0$ si $\epsilon\to 0$ (pues $g$ es continua). Luego $g(y+\epsilon)=x+\delta$, es decir, $y+\epsilon=f(x+\delta)$, finalmente:
$$g'(y)=\lim_{\epsilon\to 0}\frac{g(y+\epsilon)-g(y)}{\epsilon}=\lim_{\delta\to 0}\frac{\delta}{f(x+\delta)-f(x)}=\frac{1}{f'(x)}.$$
\end{enumerate}
\end{proof}
\begin{mydef}[Máximo y mínimo local]
Sea $f:(a,b)\rightarrow\R$ derivable, decimos que $x_0$ es un \textit{máximo local}, si para todo $x\in U$ (donde $U$ es un entorno de $x_0$) se cumple $f(x_0)\geq f(x)$. En caso contrario se dice que es un \textit{mínimo local}. También se le agrega el sufijo \textit{estricto} si la inecuación lo es.
\end{mydef}
\begin{thm}[Teorema analítico de Fermat]\label{thm:local-min-max}
Sea $f:(a,b)\rightarrow\R$ derivable, si $x_0$ es un mínimo o máximo local, entonces $f'(x_0)=0$.
\end{thm}
\begin{proof}
Demostremos por contradicción, si $x\simeq x_0$, supongamos que $f'(x_0)\gt 0$ y que $x\gt x_0$, entonces evidentemente $f(x)\gt f(x_0)$; en caso contrario que $x\lt x_0$ vemos que $f(x)\lt f(x_0)$, probando que $x_0$ no es ni máximo ni mínimo local. El caso $f'(x_0)\lt 0$ es análogo.
\end{proof}
\begin{figure}
\centering
\begin{tikzpicture}
\begin{axis}[demo,
	xmin = 0, xmax = 7,
	ymin = 0, ymax = 10,
	ticks = major,
	xtick = {2.785, 4.549}, xticklabels = {$m$, $M$},
	ytick = {2.887, 5.631}, yticklabels = {$f(m)$, $f(M)$},
	xlabel = $x$, ylabel = {$f(x)$}
]
\addplot[niceblue, thick, smooth, domain=0:7] {5-(x-2)*(x-4)*(x-5)};
\addplot[nicered, domain=2.035:3.535] {2.887};
\addplot[nicered, domain=3.799:5.299] {5.631};
\begin{scope}[nicepurple, very thick]
\addplot[domain=2.34:3.324] {5-(x-2)*(x-4)*(x-5)};
\addplot[domain=4:5] {5-(x-2)*(x-4)*(x-5)};
\addplot[mark=*, only marks] coordinates {(2.785,2.887) (4.549,5.631)};
\end{scope}
\end{axis}
\end{tikzpicture}
\caption{Teorema \ref{thm:local-min-max}.}
\end{figure}

Nótese que en la figura $m$ es un mínimo local y $M$ un máximo local.
\begin{thm}[Teorema de Rolle]
Sea $f:[a,b]\rightarrow\R$, continua en $[a,b]$ y derivable en $(a,b)$, tal que $f(a)=f(b)$, entonces existe un $x_0\in(a,b)$ tal que $f'(x_0)=0$.
\end{thm}
\begin{proof}
Sabemos que todo intervalo $[a,b]$ es cerrado, por tanto compacto, y si $f$ es derivable es continua, luego $f[a,b]$ es compacto, luego poseen máximo y mínimo respectivamente. Supongamos que el máximo y mínimo son $f(a)=f(b)$, por tanto, $f$ es constante y luego la derivada es nula en todo punto. En caso contrario debe haber un punto $x_0\in(a,b)$ tal que $f(x_0)\neq f(a)$ es mínimo o máximo, por teorema anterior su derivada es nula.
\end{proof}
\begin{thm}[Teorema de Cauchy]
Sean $f,g:[a,b]\rightarrow\R$ continuas en $[a,b]$ y derivables en $(a,b)$, entonces existe un punto $x_0$ tal que
$$\frac{f'(x_0)}{g'(x_0)}=\frac{f(b)-f(a)}{g(b)-g(a)}.$$
\end{thm}
\begin{proof}
Considere la función
$$h(x)=g(x)\left(f(b)-f(a)\right)-f(x)\left(g(b)-g(a)\right),$$
evidentemente $h(a)=h(b)$. Luego se sabe que $h$ es continua en $[a,b]$ y derivable en $(a,b)$, por teorema de Rolle existe $x_0\in(a,b)$ tal que
$$h'(x_0)=g'(x_0)\left(f(b)-f(a)\right)-f'(x_0)\left(g(b)-g(a)\right)=0.$$
\end{proof}
La consecuencia más importante del teorema de Cauchy por el momento es el siguiente caso particular:
\begin{thm}[Teorema del valor medio]
Sea $f:[a,b]\rightarrow\R$ continua en $[a,b]$ y derivable $(a,b)$, entonces existe un punto $x_0$ tal que
$$f'(x_0)=\frac{f(b)-f(a)}{b-a}.$$
\end{thm}
\begin{figure}
\centering
\begin{tikzpicture}
\begin{axis}[demo,
	ymin = 0, ymax = 8,
	smooth, samples = 50,
	ticks = major, xtick = {2, 2.653, 4.68, 5.5}, ytick = {2, 3.969}, xticklabels={$a$, $x_1$, $x_2$, $b$}, yticklabels={$f(a)$, $f(b)$},
	xlabel = {$x$}, ylabel = {$f(x)$}
]
\addplot[niceblue, thick, domain=0:8] {.75*(x-2)*(x-4)*(x-5)+2};
\begin{scope}[nicered, mark=none]
\addplot[domain=2:5.5, dashed] {0.5625*(x-2)+2};
\addplot[domain=2.15:3.15] {0.5625*(x-2.653)+3.548};
\addplot[domain=4.2:5.2] {0.5625*(x-4.68)+1.563};
\end{scope}
\addplot[mark=*, nicepurple, only marks] coordinates {(2,2) (2.653,3.548) (4.68,1.563) (5.5,3.969)};
\end{axis}
\end{tikzpicture}
\caption{Teorema del valor medio.}
\end{figure}
\begin{thm}
Sea $f:[a,b]\rightarrow\R$ una función continua en $[a,b]$ y derivable en $(a,b)$ tal que $f'(x_0)=0$, entonces es constante.
\end{thm}
\begin{proof}
Tomemos $u\lt v\in(a,b)$, luego por teorema del valor medio existe $x_0\in(u,v)$ tal que
$$f'(x_0)=0=\frac{f(v)-f(u)}{v-u}\implies f(u)=f(v)$$
luego, se comprueba para todo par en $(a,b)$ y por continuidad también para $a$ y $b$.
\end{proof}
\begin{thm}
Sean $f,g:I\subseteq\R\rightarrow\R$ derivables en un intervalo $I$. $f'=g'$ syss $f=g+k$ con $k\in\R$.
\end{thm}
\begin{proof}
Nótese que $(f-g)'(x)=0$, luego $(f-g)(x)=k$ por el teorema anterior.
\end{proof}
\subsection*{Términos ``diferenciales''}
Curiosamente en muchos cursos de cálculo se utilizan los términos \textit{derivadas} y \textit{diferenciales} como si fueran intercambiables, cuando en realidad corresponden a ideas muy distintas, pero necesarias. Sea $f:D\subseteq\R\rightarrow\R$ una función, y en uso de la notación en física, definiremos $\Delta_{x_0}f=f(x_0+\Delta x)-f(x)$, donde $\Delta x$ es la diferencia entre $x_0$ y otro punto $x_1$ cercano (pero distinto), luego
$$f'(x_0)=\lim_{\Delta x\to 0}\frac{\Delta_{x_0}f}{\Delta x}.$$
Si eliminamos el límite de la expresión es evidente que en realidad esto corresponde una aproximación, con un error
$$\epsilon_{x_0}(\Delta x)=\frac{\Delta_{x_0}f}{\Delta x}-f'(x_0),$$
lo que realmente se explica a través de la siguiente figura.
\begin{figure}
\centering
\begin{tikzpicture}
\begin{axis}[demo,
	domain=.9:1.3, xmax=1.4,
	ymin=.7, ymax=1.05,
	xlabel=$x$, ylabel={$f(x)$},
	ticks=major,
	xtick={1,1.2}, xticklabels={$x_0$, $x_0+\Delta x$},
	ytick={.8414}, yticklabels={$f(x_0)$},
]
\begin{scope}[very thick]
\addplot[niceblue] {sin(deg(x))} node[pos=1,right]{$f(x)$};
\addplot[nicered] {sin(deg(1))+cos(deg(1))*(x-1)} node[pos=1,right]{$T^1_{x_0}f$};
\end{scope}
\addplot[nicepurple, only marks, mark=*] coordinates {(1,{sin(deg(1))})};
\begin{scope}[nicepurple, dashed, mark=none]
\addplot coordinates {(1,{sin(deg(1))}) (1,{sin(deg(1))+cos(deg(1))*.2})} node[pos=.5,left]{$f'(x_0)\Delta x$};
\addplot coordinates {(1,{sin(deg(1))+cos(deg(1))*.2}) (1.2,{sin(deg(1))+cos(deg(1))*.2})};
\addplot coordinates {(1,{sin(deg(1))}) (1.2,{sin(deg(1))})} node[pos=.5,below]{$\Delta x$};
\addplot coordinates {(1.2,{sin(deg(1))}) (1.2,{sin(deg(1.2))})} node[pos=.5,right]{$\Delta_{x_0}f$};
\addplot[niceorange] coordinates {(1.2,{sin(deg(1.2))}) (1.2,{sin(deg(1))+cos(deg(1))*.2})} node[pos=.5,right]{$\epsilon_{x_0}(\Delta x)$};
\end{scope}
\end{axis}
\end{tikzpicture}
\caption{}
\end{figure}

Desde un punto de vista del análisis no estándar esto significa que si $\Delta x$ es infinitesimal
$$\Delta_{x_0}f\simeq f'(x_0)\Delta x.$$
Finalmente estableceremos una función denominada \textit{diferencial} $df:D\rightarrow\R$ tal que $df_{\Delta x}(a)=f'(a)\Delta x$. Vemos que el diferencial de la función identidad $f(x)=x$, que denotaremos como $dx$ es $\Delta x$ por definición. Finalmente
$$f'(a)=\frac{df_{\Delta x}(a)}{dx_{\Delta x}},$$
ahora, el valor de $\Delta x$ es arbitrario para establecer la igualdad, pero para asegurar la cercanía infinita establecida con el análisis no estándar, es común decir que la elección de $dx$ es infinitesimal, aun que no nula. A esta notación de la derivada le llamamos \textit{notación de Leibniz}.
\begin{figure}
\centering
\begin{tikzpicture}
\begin{axis}[demo,
	width = 6cm,
	ymin = 0, ymax = 6,
	xlabel = $x$, ylabel = {$f(x)$}
]
\addplot[niceblue, domain = 0:8, thick, smooth] {-(x-4)^2 + 4};
\addplot [nicepurple, domain = 0:8] {2*(x-3) + 3};
\addplot[mark = square*, mark options={fill=white}, nicepurple] coordinates {(3,3)};
\end{axis}
\begin{scope}[shift={(5,0)}]
\draw[nicepurple] (0,0) -- (4,0) -- (4,4) -- (0,4) -- cycle (0,0) -- (4,4) (1.5,1.5) -- node[below]{$dx$} ++(1,0) -- node[right]{$df$} ++(0,1);
\draw[niceblue] (.1,0) to[out=47.5,in=222.5] (4,3.9);
\end{scope}
\end{tikzpicture}
\caption{Significado de la notación de Leibniz.}
\end{figure}

Esta notación es particularmente útil para los dos teoremas principales establecidos (y para enunciar futuros problemas). Digamos que $z(y)$ e $y(x)$, de forma que $z(x)$ es en realidad una composición de funciones, la regla de la cadena se enuncia de la siguiente manera
$$\frac{dz}{dx}=\frac{dz}{dy}\frac{dy}{dx},$$
mientras que el teorema de la función inversa se denota como
$$\frac{dy}{dx}=\frac{1}{dx/dy},$$
pues si $y(x)$ es una función, $x(y)$ es su inversa.

\subsection*{Cálculo de derivadas}
Al igual que hay límites trigonométricos, las derivadas son bastante intuitivas:
\begin{align}
\frac{d(\sin x)}{dx}&=\lim_{\epsilon\to 0}\frac{\sin(x+\epsilon)-\sin x}{\epsilon}\notag\\
&=\lim_{\epsilon\to 0}\frac{\sin x\cos\epsilon+\cos x\sin\epsilon-\sin x}{\epsilon}\notag\\
&=\lim_{\epsilon\to 0}\cos x\frac{\sin\epsilon}{\epsilon}+\sin\epsilon\frac{1-\cos\epsilon}{\epsilon}\notag\\
&=\cos x,\\
\frac{d(\cos x)}{dx}&=\lim_{\epsilon\to 0}\frac{\cos(x+\epsilon)-\cos x}{\epsilon}\notag\\
&=\lim_{\epsilon\to 0}\frac{\cos x\cos\epsilon-\sin x\sin\epsilon-\cos x}{\epsilon}\notag\\
&=\lim_{\epsilon\to 0}-\cos x\frac{1-\cos\epsilon}{\epsilon}-\sin x\frac{\sin\epsilon}{\epsilon}\notag\\
&=-\sin x.
\end{align}
Utilizando estas dos y la derivada del cociente deducimos la siguiente
\begin{align}
\frac{d\tan x}{dx}&=\frac{d}{dx}\left[\frac{\sin x}{\cos x}\right]\notag\\
&=\frac{\cos^2x+\sin^2x}{\cos^2x}\notag\\
&=1+\tan^2x=\sec^2x.
\end{align}

\section{Derivadas de $n$-ésimo orden}
\begin{mydef}[$n$-ésima derivada]
Sea $f:D\subseteq\R\rightarrow\R$ una función derivable, denotamos su $n$-ésima derivada como $f^{(n)}(x)$, donde
$$f^{(0)}(x)=f(x),\quad f^{(n+1)}(x)=\frac{df^{(n)}}{dx}(x),$$
además, la solemos anotar como
$$f^{(n)}(x)=\frac{d^nf}{dx^n}(x).$$
\end{mydef}
Diremos que una función $f$ es $n$-veces derivable (o de clase $C^n$), cuando $f^{(n)}$ es continua y no derivable. Hay funciones tales que este límite no existe de modo que las llamaremos \textit{infinitamente derivables}.

Es obvio que la suma y producto de funciones de clase $C^n$ es de clase $C^n$. Las funciones polinómicas, $\sin x$ y $\cos x$ son infinitamente derivables.
\begin{mydef}[Expansión de Taylor]
Sea $f:D\rightarrow\R$ una función de clase $C^n$ y $a\in D$, definimos la expansión o polinomio de Taylor de $f$ como
\begin{align}
T^n_a f(x)&=\sum_{k=0}^n f^{(k)}(a)\frac{(x-a)^k}{k!}\notag\\
&=f(a)+f'(a)(x-a)+f''(a)\frac{(x-a)^2}{2!}+\cdots
\end{align}
\end{mydef}
\begin{thm}
Sea $f:D\rightarrow\R$ una función de clase $C^n$ y $a\in D$, nótese que para todo $i$ entero tal que $0\leq k\leq n$ se cumple
$$\frac{d^k}{dx^k}[T_a^n f(a)]=f^{(i)}(a).$$
\end{thm}
\begin{proof}
Construyamos la función polinómica
$$g(x)=\sum_{k=0}^n c_k(x-a)^k,$$
veamos que $g(a)=c_0$, para las derivadas tenemos que
$$g'(x)=\sum_{k=1}^n k\cdot c_k(x-a)^{k-1},$$
es decir, que $g'(a)=c_1$. Luego
$$g''(x)=\sum_{k=2}^n k(k-1)c_k(x-a)^{k-2},$$
es decir, que $g''(a)=2c_2$. Luego
$$g^{(3)}(x)=\sum_{k=3}^n k(k-1)(k-2)c_k(x-a)^{k-3},$$
por lo tanto, $g^{(3)}(a)=3\cdot 2c_3=3!c_3$. El patrón es evidente, para todo $i$ $g^{(i)}(a)=i!c_i$, para lo cual dividimos la serie original por $k!$ en cada caso. La constante $c_i$ es en todo caso la $i$-ésima derivada de $f$ en $a$.
\end{proof}
En particular puede ver porque a los matemáticos nos gusta está expansión, pues las funciones polinómicas son siempre más fáciles de trabajar o son más \textit{familiares} para nosotros. Nótese que si $f$ es una función polinómica de grado $k$, para todo $r\in\R$ $T_r^k f(x)=f(x)$.
\begin{thm}[Teorema de Taylor]
Sea $f:I=[a,b]\rightarrow\R$ de clase $C^{k+1}$ con $f^{(k+1)}$ continua en $(a,b)$. Sea $u\in I$, entonces para todo $v\in I$ existe $c$ entre $u$ y $v$ tal que
$$f(v)=T^k_uf(v)+\frac{f^{(k+1)}(c)}{(k+1)!}(v-u)^{k+1}.$$
\end{thm}
\begin{proof}
No perdemos generalidad suponiendo que $u\lt v$. Luego definimos $g:[u,v]\rightarrow\R$ como
$$g(x)=f(v)-f(x)-(v-x)f'(x)-\cdots-\frac{(v-x)^k}{k!}f^{(k)}(x),$$
tal que su derivada es
$$g'(x)=-\frac{(v-x)^k}{k!}f^{(k+1)}(x).$$
Además, definamos $h:[u,v]\rightarrow\R$ como
$$h(x)=g(x)-\left(\frac{v-x}{v-u}\right)^{k+1}g(u).$$
Luego $h(u)=h(v)=0$, por teorema de Rolle existe un $c\in(u,v)$ tal que $h'(c)=0$, es decir:
$$h'(c)=g'(c)+(k+1)\frac{(v-c)^k}{(v-u)^{k+1}}g(u)=0$$
Despejando $g(u)$:
\begin{align*}
g(u)&=-\frac{1}{k+1}\frac{(v-u)^{k+1}}{(v-c)^k}g'(c)\\
&=\frac{1}{k+1}\frac{(v-u)^{k+1}}{\cancel{(v-c)^k}}\frac{\cancel{(v-c)^k}}{k!}f^{(k+1)}(c)\\
&=\frac{(v-u)^{k+1}}{(k+1)!}f^{(k+1)}(c).
\end{align*}
Pero
\begin{align*}
g(u)=f(v)-T^k_uf(v)&=\frac{(v-u)^{k+1}}{(k+1)!}f^{(k+1)}(c)\\
\iff f(v)&=T^k_uf(v)+\frac{(v-u)^{k+1}}{(k+1)!}f^{(k+1)}(c).
\end{align*}
Y así queda demostrado.
\end{proof}
\begin{mydef}[Funciones cóncavas y convexas]
Téngase $f:[a,b]\rightarrow\R$ con $\lambda\in(0,1)$, decimos que es convexa (resp. cóncava) si para todo intervalo $[x,y]\subseteq[a,b]$
$$f\left((1-\lambda)x+\lambda y\right)\leq(1-\lambda)f(x)+\lambda f(y)$$
(resp. $\geq$).
\end{mydef}
\begin{figure}
\centering
\begin{subfigure}{.49\textwidth}
\begin{tikzpicture}
\begin{axis}[demo,
	width = 6cm,
	xmin=0, xmax=5,
	ymin=1, ymax=6.5, samples=50,
	ticks=major, xtick={1, 4}, xticklabels={$a$, $b$}, ytick={2.5, 4}, yticklabels={$f(a)$, $f(b)$}
]
\addplot[niceblue, domain=0:5] {.5*(x-2)^2+2};
\addplot[nicepurple, domain=1:4] {.5*(x-4)+4};
\addplot[mark=*, only marks, nicepurple] coordinates {(1,2.5) (2.5,2.125) (2.5,3.25) (4,4)};
\end{axis}
\end{tikzpicture}
\caption{Función convexa.}
\end{subfigure}
\begin{subfigure}{.49\textwidth}
\begin{tikzpicture}
\begin{axis}[demo,
	width = 6cm,
	xmin=.5, xmax=5,
	ymin=0, ymax=5, samples=50,
	ticks=major, xtick={1, 4}, xticklabels={$a$, $b$}, ytick={2, 3.5}, yticklabels={$f(a)$, $f(b)$}
]
\addplot[niceblue] {-.5*(x-3)^2+4};
\addplot[nicepurple, domain=1:4] {.5*(x-4)+3.5};
\addplot[mark=*, only marks, nicepurple] coordinates {(1,2) (2.5,2.75) (2.5,3.875) (4,3.5)};
\end{axis}
\end{tikzpicture}
\caption{Función cóncava.}
\end{subfigure}
\caption{Tipos de funciones.}
\end{figure}

Nótese que el término en la izquierda es el punto inferior en el ejemplo de convexa, el punto superior es representado por el punto superior, ambos considerados para un mismo $\lambda$.
\begin{thm}
Sea $f$ una función de clase $C^{\geq 2}$, $f$ es convexa (resp. cóncava) en $D=[a,b]$ syss $f''(x)\geq 0$ (resp. $f''(x)\leq 0$) para todo $x\in[a,b]$.
\end{thm}
\begin{proof}
$\implies$. Desarrollemos primero la segunda derivada para un punto $x\in D$
$$f''(x)=\lim_{\epsilon\to 0}\frac{f(x+\epsilon)-2f(x)+f(x-\epsilon)}{\epsilon^2},$$
luego analizamos el intervalo $[x-\epsilon,x+\epsilon]$ de forma que evidentemente $x=\frac 12(x-\epsilon)+\frac 12(x+\epsilon)$. Por definición de convexa
$$f\left(\frac 12(x-\epsilon)+\frac 12(x+\epsilon)\right)\leq\frac 12f(x-\epsilon)+\frac 12f(x+\epsilon).$$
De manera que evidentemente $f''(x)\geq 0$.

$\Longleftarrow$. Tomemos un par de puntos $x_1,x_2\in D$ y para cualquier $\lambda\in(0,1)$ definamos $x_0=(1-\lambda)x_1+\lambda x_2$. Como $f$ es de clase $C^{\geq 2}$, aplicando el teorema de Taylor obtenemos que existe $c_1\in(x_1,x_\lambda)$ tal que
$$f(x_1)=f(x_0)+(x_1-x_0)f(x_0)+\frac{(x_1-x_0)^2}{2}f''(c_1).$$
Por el mismo argumento existe $c_2\in(x_0,x_2)$ tal que
$$f(x_2)=f(x_0)+(x_2-x_0)f(x_0)+\frac{(x_2-x_0)^2}{2}f''(c_2)$$
Como $f''(x)\geq 0$ por hipótesis, tenemos que
$$R\equiv(1-\lambda)\frac{(x_1-x_0)^2}{2}f''(c_1)+\lambda\frac{(x_2-x_0)^2}{2}f''(c_2),$$
se cumple $R\geq 0$. Luego
\begin{align*}
(1-\lambda)f(x_1)+\lambda f(x_2)&=f(x_0)+f'(x_0)\cancel{(\left(1-\lambda)x_1+\lambda x_2-x_0\right)}\\
&+\,(1-\lambda)\frac{(x_1-x_0)^2}{2}f''(c_1)+\lambda\frac{(x_2-x_0)^2}{2}f''(c_2)\\
&=f(x_0)+R\geq f(x_0)=f\left((1-\lambda)x_1+\lambda x_2\right).
\end{align*}
Y así queda demostrado.

Es análogo para $f$ cóncava.
\end{proof}
\begin{thm}\label{thm:convex-inequality}
Llamemos
$$p(x,y)\equiv\frac{f(y)-f(x)}{y-x}.$$
Sea $f$ convexa (resp. cóncava) con $x\lt z\lt y\in\Dom f$, luego
$$p(x,z)\leq p(x,y)\leq p(z,y)$$
(resp. $\geq$).
\end{thm}
\begin{proof}
Nótese que podemos definir $z=(1-\lambda)x+\lambda y$, despejando $\lambda$ obtenemos
$$\lambda=\frac{z-x}{y-x},$$
lo que aplicando la definición de convexa nos da que
$$f(z)\leq(1-\lambda)f(x)+\lambda f(y)=\frac{y-z}{y-x}f(x)+\frac{z-x}{y-x}f(y).$$
Reordenando los términos
$$0\leq yf(x)+zf(y)+xf(z)-zf(x)-xf(y)-yf(z),$$
se nos pide demostrar que (por ejemplo)
$$\frac{f(z)-f(x)}{z-x}\leq\frac{f(y)-f(x)}{y-x},$$
pasando los términos hacia un sólo lado
\begin{align*}
0&\leq\frac{f(y)-f(x)}{y-x}-\frac{f(z)-f(x)}{z-x}\\
&\leq(z-x)(f(y)-f(x))+(x-y)(f(z)-f(x))
\end{align*}
Y el último término es nuestra desigualdad que deducimos. Lo mismo se aplica para la otra inecuación restante. La demostración es análoga para $f$ cóncava.
\end{proof}
\begin{thm}\label{thm:convex-func-slope}
Sea $f:(a,b)\rightarrow\R$ una función convexa (resp. cóncava) derivable en $x$, entonces para todo $y\in(a,b)$ se cumple
$$f(x)+f'(x)(y-x)\leq f(y)$$
(resp. $\geq$).
\end{thm}
\begin{proof}
Para esta demostración utilizaremos la desigualdad anterior. Considere que $x\lt z$, tal que si $z\to x^+$ se obtiene que
$$\lim_{z\to x^+}\frac{f(z)-f(x)}{z-x}=f'(x)\leq\frac{f(y)-f(x)}{y-x}$$
de lo que se deduce el enunciado. Considere que $x\gt z$, tal que $z\to x^-$, se obtiene que
$$\lim_{z\to x^-}\frac{f(x)-f(z)}{x-y}=f'(x)\leq\frac{f(y)-f(z)}{y-z}\leq\frac{f(y)-f(x)}{y-x}$$
de la desigualdad entre términos a los extremos se deduce el enunciado análogamente. La demostración es similar para $f$ cóncava.
\end{proof}
\begin{figure}
\centering
\begin{tikzpicture}
\begin{axis}[demo,
	domain=.3:1.7,
	ymin=.2, ymax=1.6,
	samples=50, smooth
]
\addplot[niceblue, very thick] {.75*(x-.5)^2+.5};
\begin{scope}[nicepurple, mark=none]
\addplot {.5};
\addplot {.6875+.75*(x-1)};
\end{scope}
\begin{scope}[nicered, dashed, mark=none]
\addplot {.5+.375*(x-.5)};
\addplot {.5+.75*(x-.5)};
\addplot {.6875+1.125*(x-1)};
\end{scope}
\begin{scope}[nicered, thick, mark=none]
\addplot[domain=.5:1] {.5+.375*(x-.5)};
\addplot[domain=.5:1.5] {.5+.75*(x-.5)};
\addplot[domain=1:1.5] {.6875+1.125*(x-1)};
\end{scope}
\addplot[mark=*, only marks, nicepurple] coordinates {(.5, .5) (1, .6875) (1.5, 1.25)};
\end{axis}
\end{tikzpicture}
\caption{Teorema \ref{thm:convex-inequality} y \ref{thm:convex-func-slope}.}
\end{figure}

La figura aquí incluida tiene como fines mostrar que el teorema~\ref{thm:convex-func-slope} es cierto, al igual que el teorema~\ref{thm:convex-inequality} que utilizamos como ``lema''. La desigualdad está representada por las líneas rojas, que utilizan las pendientes entre dos puntos y mientras más inclinadas mayor es la pendiente en cada caso. El teorema está representado con las líneas púrpura tales que todo punto está por sobre la tangente a un punto anterior. 
\begin{thm}
Sea $f$ convexa o cóncava en $[a,b]$, entonces es continua en $[a,b]$.
\end{thm}
\begin{proof}
Consideremos un par de puntos $u\lt v\in(a,b)$, vamos a demostrar que para todo par de puntos $x\lt y\in[u,v]$, la función es continua. Llamemos $a\lt\bar a\lt u$ y $v\lt\bar b\lt b$, luego por el teorema~\ref{thm:convex-inequality}:
$$p(\bar{a},u)\leq p(u,y)\leq p(x,y)\leq p(x,v)\leq p(\bar b,v),$$
luego definimos $c\equiv\max\{|p(\bar a,u)|,|p(\bar b,v)|\}$ y vemos que $|f(x)-f(y)|\leq C|x-y|$ para todo $f:[u,v]\rightarrow\R$, es decir, $f$ en $[u,v]$ posee propiedad de Lipschitz, luego es continua en todo intervalo $[u,v]\subseteq[a,b]$, finalmente $f$ es continua en $[a,b]$.
\end{proof}
\begin{thm}[Desigualdad de Jensen]
Sea $f:[a,b]\rightarrow\R$ convexa (resp. cóncava). Sea $\{\lambda_i\}_{i=1}^n$ un conjunto finito de valores no-negativos tales que $\sum_{i=1}^n\lambda_i=1$ (con $n\geq 2$) y $\{x_i\}_{i=1}^n$ un conjunto de números (de menor a mayor) en el dominio tales que $\sum_{i=1}^n \lambda_ix_i$ entre $x_1$ y $x_n$, entonces
$$f\left(\sum_{i=1}^n\lambda_ix_i\right)\leq\sum_{i=1}^n\lambda_if(x_i)$$
(resp. $\geq$).
\end{thm}
\begin{proof}
La prueba será llevada acabo por inducción. Veamos que el caso $n=2$ es la definición de función convexa. Para el caso $n+1$ hemos de ver que si la suma de los elementos es no-nula, entonces debe haber por lo menos un $\lambda_i$ (digamos $\lambda_1$) tal que es mayor estricto que cero, de manera que, podemos aplicar el caso $n=2$ para comprobar que
$$f\left(\lambda_1x_1+(1-\lambda_1)\sum_{i=2}^{n+1}\frac{\lambda_i}{1-\lambda_1}x_i\right)\leq \lambda_1f(x_1)+(1-\lambda_1)f\left(\sum_{i=2}^{n+1}\frac{\lambda_i}{1-\lambda_1}x_i\right)$$
lo de la derecha es el caso para $n$ nos queda
$$f\left(\sum_{i=1}^{n+1}\lambda_ix_i\right)\leq \lambda_1f(x_1)+\cancel{(1-\lambda_1)}\sum_{i=2}^{n+1}\frac{\lambda_if(x_i)}{\cancel{1-\lambda_1}}=\sum_{i=1}^{n+1}\lambda_if(x_i).$$
Tal como queríamos probar.
\end{proof}
Ahora podemos pasar del tema y volver a enfocarnos en las propiedades del polinomio de Taylor, comenzando por un límite que se nos será fundamental en lo que sigue:
\begin{thm}
Para todo $x\geq 0$ se cumple que $\lim_n x^n/n!=0$.
\end{thm}
\begin{proof}
Vamos a resolver el límite aplicando análisis no estándar, tomemos un $N$ natural ilimitado. Para todo $x\geq 0$ real existe $n\equiv\lceil x\rceil$, tal que
$$\frac{x^N}{N!}=\frac{x^n}{n!}\cdot\prod_{k=n+1}^{N-1}\frac{x}{k}\cdot\frac{x}{N}\simeq 0.$$
El primer factor es finito, pues todos los números y operaciones son estándar, el factor del medio es una pitatoria de números menores que 1, el último factor es infinitesimal, luego todo el producto es infinitesimal.
\end{proof}
\begin{thm}
Sea $f:D\rightarrow\R$ de clase $C^\infty$. Luego para cualquier $a\in D$ se cumple que
$$f(x)=T^\infty_af(x)=\sum_{k=0}^\infty f^{(k)}(a)\frac{(x-a)^k}{k!}$$
si existe un $N$ tal que para todo $x$ se cumple que $f^{(k)}(x)\leq N^k$.
\end{thm}
\begin{proof}
Veamos que una forma equivalente es probar que
$$\lim_n f(x)-T^n_af(x)=0,$$
para todo $x$ en el intervalo. Por el teorema de Taylor, sabemos que existe $c$ entre $a$ y $x$ tal que
$$|f(x)-T^n_af(x)|=\left|f^{(n+1)}(c)\frac{(x-a)^{n+1}}{(n+1)!}\right|\leq\frac{|N(x-a)|^{n+1}}{(n+1)!}.$$
Por el teorema anterior el último término converge a cero, por lo cual, aplicando teorema del Sandwich (pues el término de la izquierda es siempre mayor o igual a cero), nuestro límite converge a cero.
\end{proof}
Esta es la razón del porqué se suelen enseñar tanto expresiones como las aproximaciones de Taylor en aplicaciones de las matemáticas, como en clases de física experimental. Nuestro principal uso será para definir las funciones trigonométricas de $\sin x$ y $\cos x$, que poseen un par de valores notables y propiedades es bastante misteriosas para ángulos intermedios, para ello escogeremos $a=0$:
\begin{align*}
\sin 0=0,&\quad\frac{d\sin x}{dx}(0)=\cos 0=1,\\
\frac{d^2\sin x}{dx^2}(0)=-\sin 0=0,&\quad\frac{d^3\sin x}{dx^3}(0)=-\cos 0=-1,\\
\frac{d^4\sin x}{dx^4}(0)=\sin 0=0,&\quad\cdots
\end{align*}
Vemos que todas las derivadas al ser trigonométricas están acotadas por $M=1$ y alternan en la forma 1, $-1$ con $k$ impar, con ello deducimos las dos siguientes expansiones para nuestras funciones trigonométricas:
\begin{align}
\sin x&=\sum_{k=0}^\infty(-1)^k\frac{x^{2k+1}}{(2k+1)!}=x-\frac{x^3}{3!}+\frac{x^5}{5!}+\cdots\\
\cos x&=\sum_{k=0}^\infty(-1)^k\frac{x^{2k}}{(2k)!}=1-\frac{x^2}{2!}+\frac{x^4}{4!}+\cdots
\end{align}
Cabe destacar que esta fórmula sólo se aplica para $x$ en radianes y que este es el cálculo que emplean todas las calculadoras al evaluar dichas funciones.
\begin{figure}
\centering
\begin{tikzpicture}
\begin{axis}[2dgraph,
	width=10cm,
	domain=-8:8,
	ymin=-5, ymax=5,
	samples=50,
	smooth, thick,
	ylabel={$f(x)=\sin x$}, xlabel=$x$
]
\addplot[niceblue, very thick] {sin(x*180/pi)};
\addplot[nicepurple, domain=-5:5] {x} node[below right,pos=1] {$n=0$};
\addplot[nicered, domain=-3.744:3.744] {x-x^3/6} node[above left,pos=1] {$n=1$};
\addplot[niceorange, domain=-4.538:4.538] {x-x^3/6+x^5/120} node[right, pos=.9] {$n=2$};
\addplot[nicegreen, domain=-4.958:4.958] {x-x^3/6+x^5/120-x^7/5040} node[above right, pos=1] {$n=3$};
\end{axis}
\end{tikzpicture}
\caption{Aproximación por Taylor para $\sin x$.}
\end{figure}

\subsection*{Reglas de L'Hôpital}
Una técnica muy común (y muy útil también) para el cálculo de límites es utilizar las llamadas \textit{reglas de L'Hôpital}, usualmente se escriben como si fueran un único y potente criterio, sin embargo, en realidad son varios teoremas, con demostraciones diferentes y es de ellos sobre el cual nos enfocaremos en esta subsección. Está demás decir que por esa misma razón no redundaremos con los títulos de las proposiciones acontinuación.
\begin{thm}
Sean $f,g:(a,b)\rightarrow\R$ diferenciables con $-\infty\leq a\lt b\leq\infty$, tales que $\lim_{x\to a}f(x)=\lim_{x\to a}g(x)=0$. Si existe
$$\lim_{x\to a}(f'/g')(x)=L$$
entonces existe
$$\lim_{x\to a}(f/g)(x)=L.$$
\end{thm}
\begin{proof}
Definamos para conservar continuidad la extensión $f,g:[a,b)\rightarrow\R$ tales que $f(a)=g(a)=0$, de forma que $f(x)-f(a)=f(x)$, luego por teorema de Cauchy para todo $x\in[a,b)$ existe $c\in(a,x)$ tal que
$$\frac{f'(c)}{g'(c)}=\frac{f(x)}{g(x)}.$$
Si existe el primer límite (el de la izquierda) es porque para todo $\epsilon\gt 0$ existe $\delta\gt 0$ tal que $0\lt d(a,c)\lt\delta$ implicaría
$$\left|\frac{f'(c)}{g'(c)}-L\right|\lt\epsilon.$$
Luego para todo $\epsilon\gt 0$ existe $\delta\gt 0$ tal que $x\in(a,a+\delta)$ implica las condiciones anteriores que por Cauchy satisfacen la definición de límite. Finalmente
$$\lim_{x\to a} (f/g)(x)=L.$$
Nótese que, en realidad, esta es la demostración para el límite lateral ``por la derecha'', sin embargo, por la versatilidad del teorema de Cauchy se aplica también para $x\to b^-$, luego por unicidad de los límites laterales se demostraría para un límite general.

Ahora proceremos a ver cuando $x\to+\infty$. Ahora el dominio es $(a,+\infty)$, por lo que definimos $F(x)=f(1/x)$ y $G(x)=g(1/x)$ (continuas por composición) con $F,G:(0,1/a)\rightarrow\R$ (si $a\leq 0$ entonces el dominio es $(0,+\infty)$, o se considera un $a+\epsilon$ tal que sea positivo). Veamos que
$$F'(x)=-\frac{f'(1/x)}{x^2},$$
por regla de la cadena, luego, los $-1/x^2$ se cancelan en la división. Por hipótesis si
$$\lim_{x\to 0^+}\frac{F'(x)}{G'(x)}=L,$$
entonces existe
$$\lim_{x\to 0^+}\frac{F(x)}{G(x)}=L$$
por regla de L'Hôpital probada anteriormente.
\end{proof}
\begin{thm}
Sean $f,g:(a,b)\rightarrow\R$ derivables con $-\infty\leq a\lt b\leq\infty$ tales que $\lim_{x\to a}f(x)=\lim_{x\to a}g(x)=\infty$ y que $g$ y $g'$ no se anulen en el dominio. Si existe
$$\lim_{x\to a} (f'/g')(x)=L,$$
entonces existe
$$\lim_{x\to a} (f/g)(x)=L.$$
\end{thm}
\begin{proof}
Comenzaremos por probar el caso particular cuando $x\to+\infty$, de forma que el dominio es $(a,\infty)$. Por hipótesis, consideremos que para 
\end{proof}

\section{Exponentes y logaritmos}
\begin{mydef}[Números complejos]
Definimos un conjunto $\C\equiv\R^2$ como de números complejos, tal que
$$(a,b)+(c,d)=(a+c,b+d),\quad (a,b)\cdot(c,d)=(ac-bd,ad+bc).$$ 
\end{mydef}
Podemos ver que los números de forma $(r,0)$ se comportan como los reales, por ejemplo, $(r,0)\cdot(s,0)=(rs,0)$ y $(r,0)\cdot(a,b)=(ra,rb)$. En la práctica lo denotaremos sólo como $r$. Además, nótese que $(0,1)^2=(0,1)\cdot(0,1)=(-1,0)=-1$, a este valor lo denotaremos como $\imaginary=(0,1)$ y denominaremos \textbf{unidad imaginaria}, de forma que todo par $(a,b)=(a,0)+(0,b)=a+b(0,1)=a+\imaginary b$.

Un último grupo de notaciones es ver que las potencias de $\imaginary$ son
$$\imaginary^1=\imaginary,\quad \imaginary^2=-1,\quad \imaginary^3=\imaginary^2\cdot\imaginary=-\imaginary,\quad \imaginary^4=-\imaginary^2=1,\dots$$
Cabe destacar que utilizaremos la norma $\Vert\,\Vert_2$ (usualmente llamada \textit{euclidiana}) en $\C$. Además, sea $z=x+\imaginary y$, a la parte $x$ le llamamos \textbf{parte real} y a la $y$ \textbf{parte imaginaria}; usualmente se introducen las funciones proyección sobre los complejos como $\Re z=x$ e $\Im z=y$.

Sea $z=x+\imaginary y$, definimos $\bar{z}$ (léase ``conjugado de $z$'') como $\bar{z}=x-\imaginary y$. Unas propiedades básicas del conjugado son que
$$\overline{a+b}=\bar a+\bar b,\quad\overline{ab}=\bar a\bar b.$$
Observe que, bajo nuestra norma,
$$z\bar{z}=x^2+y^2=\Vert z\Vert^2.$$
También $\Vert z\Vert=\Vert\bar z\Vert$. Utilizando el dato anterior, notamos que
\begin{equation}
z^{-1}=\frac{\bar z}{\Vert z\Vert^2},
\end{equation}
esto nos permite determinar que $(\C,+,\cdot)$ es un cuerpo.
\begin{mydef}[Función exponencial]
Sea $r\in\R^+$ un número que hemos de llamar \textit{base} (no relacionado a las bases topológicas), diremos que $r^x:\R\rightarrow\R$ es una ``función exponencial'' syss satisface que $r^1=r$ y 
$$\forall ab\in\R,\quad r^{a+b}=r^ar^b$$
(puede no estar definida en dichos puntos).
\end{mydef}
Nótese que es inmediato ver que $r^0=1$ (tómese 1+0) y que $r^{-x}=1/r^x$. Además sabemos que $\sqrt[n]{r}=r^{1/n}$ es positivo por el teorema~2.x, lo que implica que para todo $q\in\Q$ se tiene que $r^q$ es positivo.
\begin{thm}
La función
$$\exp z=\sum_{k=0}^\infty\frac{z^k}{k!}$$
converge para todo $z\in\C$ y es exponencial.
\end{thm}
\begin{proof}
Para probar la convergencia sobre $\R$ aplicamos el criterio de d'Alambert, pues
$$\lim_n\frac{x^{n+1}}{(n+1)!}\frac{n!}{x^n}=\lim_n\frac{x}{n+1},$$
como $\C$ es evidentemente un espacio métrico completo, esto asegura la convergencia de toda sucesión.

Para demostrar que es exponencial aplicaremos producto de Cauchy
\begin{align*}
\exp x\cdot\exp y&=\sum_{k=0}^\infty\frac{x^k}{k!}\sum_{k=0}^\infty\frac{y^k}{k!}=\sum_{k=0}^\infty\sum_{j=0}^k\frac{x^j}{j!}\frac{y^{k-j}}{(k-j)!}\\
&=\sum_{k=0}^\infty\sum_{j=0}^k\frac{1}{k!}\binom{k}{j}x^jy^{k-j}=\sum_{k=0}^\infty\frac{(x+y)^k}{k!}=\exp(x+y).
\end{align*}
Veremos que la base de $\exp z$ es
$$e\equiv\exp 1=\sum_{k=0}^\infty\frac{1}{k!}\approx 2.71828182845\dots$$
Para fines próximos denotaremos $\exp z=e^z$.
\end{proof}
Escribamos un complejo general como $z=\imaginary\theta$, veamos que
\begin{align}
e^{\imaginary\theta}&=1+\imaginary\theta-\frac{\theta^2}{2!}-\imaginary\frac{\theta^3}{3!}+\frac{\theta^4}{4!}+\cdots\notag\\
&=\left(1-\frac{\theta^2}{2!}+\cdots\right)+\imaginary\left(\theta-\frac{\theta^3}{3!}+\cdots\right)\notag\\
&=\sum_{k=0}^\infty(-1)^k\frac{\theta^{2k}}{(2k)!}+\imaginary\sum_{k=0}^\infty(-1)^k\frac{\theta^{2k+1}}{(2k+1)!}=\cos\theta+\imaginary\sin\theta.
\end{align}
Esta última ecuación se llama \textit{la ecuación de Euler}. Otra propiedad es que
\begin{thm}
El número $e$ es irracional.
\end{thm}
\begin{proof}
Vamos a demostrarlo con la prueba de Fourier, como la serie de $e$ es monótona creciente, por lo cual es inmediato ver que $2\lt e$, además como $n!\gt 2^{n-1}$ (dem. por inducción) para todo natural mayor o igual que 1, vemos que
$$e=1+\left(\frac{1}{1!}+\frac{1}{2!}+\frac{1}{3!}+\cdots\right)\lt 3=1+\left(1+\frac{1}{2}+\frac{1}{2^2}+\frac{1}{2^3}+\cdots\right),$$
es decir, $e$ no puede ser entero.

Supongamos, por contradicción, que $e=a/b$, dónde $a,b$ son naturales mayores que 1, luego, lo multiplicamos por $b!$ y obtenemos:
\begin{align*}
a(b-1)!&=b!+\frac{b!}{1!}+\frac{b!}{2!}+\cdots+1+\sum_{k=b+1}^\infty\frac{b!}{k!}\\
&={\color{niceblue}\sum_{k=0}^b(b-k)!\binom{b}{k}}+{\color{nicered}\sum_{k=b+1}^\infty\frac{b!}{k!}}.
\end{align*}
El término azul es evidentemente entero, sin embargo, el término rojo es problemático, pues
$$\frac{1}{b+1}+\frac{1}{(b+1)(b+2)}+\cdots\lt1+\frac{1}{b+1}+\frac{1}{(b+1)^2}+\cdots=\frac{1}{b}\lt 1,$$
la última desigualdad es verdad pues ya probamos que $b$ tiene que ser mayor que 1.
\end{proof}
Ahora es buen momento para redefinir las funciones coseno y seno para admitir argumentos complejos, ello lo reservamos para el siguiente capítulo.

Nótese que la función $\exp z$ es evidentemente continua. A su vez, no puede ser 0 en ningún punto real, puesto que si lo fuese en $c$ por ejemplo, lo sería en todo el dominio, ya que $x=c+\Delta$, luego $e^x=e^ce^\Delta=0e^\Delta=0$, lo cual evidentemente es falso. Por eso mismo sabemos que para todo real $r$, $e^r$ es positivo (de lo contrario sería nulo en algún punto), sin embargo, $\lim_{x\to\infty}e^{-x}=0$.

Finalmente, la otra razón para introducir esta nueva base es que si la derivamos
$$[e^x]'=\sum_{k=0}^\infty\frac{d}{dx}\left(\frac{x^k}{k!}\right)=\sum_{k=1}^\infty\frac{x^{k-1}}{(k-1)!}=e^x$$
¡obtenemos la misma función! Esto, como veremos acontinuación, es bastante útil, entre otras cosas pues de aquello se deduce que como la derivada es siempre positiva, la función es monótona creciente, inyectiva y también es convexa.
\begin{mydef}[Función logarítmica]
Utilizando lo descrito en métodos anteriores se deduce que $\exp:\R\rightarrow(0,\infty)$, de forma que definimos $\ln:(0,\infty)\rightarrow\R$ como la función inversa a la exponencial. Esta función será llamada \textit{logarítmo natural}.
\end{mydef}
De forma que si $y=e^x$ entonces $x=\ln y$. Por el teorema de la función inversa, vemos que su derivada es
$$\ln y=\frac{1}{(e^x)'}=\frac{1}{e^x}=\frac{1}{y}.$$
Luego las derivadas de $\ln x$ son, en orden:
$$\frac{1}{x},\quad -\frac{1}{x^2},\quad 2\frac{1}{x^3},\quad -2\cdot 3\frac{1}{x^4},\cdots$$
\begin{thm}
Sean $f, g$ un par de funciones tales que $\lim_{x\to c}f(x)=1$ y $\lim_{x\to c}g(x)=\pm\infty$, luego, si existe $\lim_{x\to c}g(x)(f(x)-1)=L$, entonces
$$\lim_{x\to c}f(x)^{g(x)}=e^L.$$
\end{thm}
\begin{proof}
Con L'Hôpital se puede probar que
$$\lim_{x\to 1}\frac{\ln x}{x-1}=1,$$
por lo tanto,
$$\lim_{x\to c}\frac{\ln(f(x))}{f(x)-1}=1,$$
con lo cual, como $\lim_{x\to c}g(x)(f(x)-1)=\lim_{x\to c}g(x)\ln(f(x))=L$, finalmente
$$\lim_{x\to c}f(x)^{g(x)}=\lim_{x\to c}e^{g(x)\ln(f(x))}=e^L.$$
\end{proof}
Veremos que ahora podemos definir todas las exponenciales a través de $a^x=e^{x\ln a}$. A ello se le suman las siguientes propiedades:
\begin{prop}[Propiedades del logarítmo]
Sean $a,b\in\R^+$ y $r\in\R$, luego:
\begin{enumerate}[$a)$]
\item $\ln a+\ln b=\ln(ab)$.
\item $\ln a-\ln b=\ln(a/b)$.
\item $r\ln a=\ln(a^r)$.
\end{enumerate}
\end{prop}
Todas salen al aplicar $\exp$ a ambos lados.

La mejor forma de definir el logaritmo natural es a través de la expansión de Taylor con $a=1$:
$$\ln x=\sum_{k=1}^\infty\frac{(-1)^{n+1}}{n}(x-1)^n.$$
Que por criterio de d'Alambert debería converger para $x\in(0,2)$, de hecho para $x=0$ obtenemos la serie harmónica negativa y para $x=2$ obtenemos una serie perfectamente convergente por criterio de Leibniz. Por lo tanto, la serie funciona sólo para $x\in(0,2]$. Para las otras $x$, aplicamos el hecho de que $\ln(1/x)=-\ln x$.

Aun que igualmente vamos a cambiar un poco este criterio de forma que la fórmula directa la aplicaremos para el intervalo $(0,1]$ y la extensión para el intervalo $(1,\infty)$, pues la fórmula es muy ``ineficiente'' para $x=2$, por ejemplo, de hecho, necesitamos utilizar $N=1000$ para obtener los dos primeros decimales de $\ln 2$, en cambio, si calculamos $-\ln(1/2)$:
\begin{figure}
\centering
\begin{tabular}{|c|ll|}
1 & 0 & 0 \\
2 & 1.0 & 0.5 \\
3 & 0.5 & 0.625 \\
4 & 0.8333333333333333 & 0.6666666666666666 \\
5 & 0.5833333333333333 & 0.6822916666666666 \\
6 & 0.7833333333333332 & 0.6885416666666666 \\
7 & 0.6166666666666666 & 0.6911458333333332 \\
8 & 0.7595238095238095 & 0.6922619047619046 \\
9 & 0.6345238095238095 & 0.6927501860119046 \\
10 & 0.7456349206349207 & 0.6929671999007935 \\
11 & 0.6456349206349207 & 0.6930648561507935 \\
12 & 0.7365440115440116 & 0.6931092453553389 \\
13 & 0.6532106782106782 & 0.6931295904074223 \\
14 & 0.7301337551337552 & 0.6931389804314607 \\
15 & 0.6587051837051838 & 0.6931433400854786
\end{tabular}
\caption{Convergencia de $\ln 2$.}
\end{figure}

El resultado real es 0,6931471805599453. Como ve, el método de $-\ln(1/2)$ es muchísimo más efectivo. Otra particularidad del logaritmo natural, es que como hemos definido los exponentes en base a $e$, las funciones son continuas e infinitamente derivables, con derivada
\begin{equation}
\frac{d}{dx}(a^x)=\frac{d}{dx}(e^{x\ln a})=e^{x\ln a}\ln a=a^x\ln a.
\end{equation}
A través de esto, podemos probar que si $x\gt 0$ y $r\in\R$ entonces
\begin{equation}
\frac{d}{dx}(x^r)=\frac{d}{dx}(e^{r\ln x})=e^{r\ln x}\frac{r}{x}=rx^{r-1},
\end{equation}
este dato será vital para probar el siguiente teorema:
\begin{thm}[Teorema generalizado del binomio de Newton]
Sean $a+b\gt 0$ con $r\in\R$, tal que $0\leq|a|\lt|b|$, luego
\begin{equation}
(a+b)^r=\sum_{k=0}^\infty\binom{r}{k}a^kb^{r-k},
\end{equation}
donde
$$\binom{r}{k}=\frac{1}{k!}\prod_{j=0}^{k-1}(r-j)=\frac{r(r-1)\cdots(r-k+1)}{k!}.$$
\end{thm}
\begin{proof}
Definiremos la función $f(x)=(x+b)^r$ y aplicaremos expansión de Taylor en torno al punto cero. Luego
$$f(x)=f(0)+\frac{f'(0)}{1!}x+\frac{f''(0)}{2!}x^2+\cdots,$$
evidentemente $f(0)=b^r$, más generalmente, $f^{(n)}(0)=n!\binom{r}{n}b^{r-n}$ (puede aplicar inducción si duda al respecto). Sin embargo es importante ver que la expansión
$$(x+b)^r=\sum_{k=0}^\infty\binom{r}{k}x^kb^{r-k}$$
converge cuando $|x|\lt|b|$. Finalmente tomando $f(a)$ obtenemos la expresión deseada.
\end{proof}
A su vez, como $\ln x$ es la inversa de $e^x$, podemos definir $\log_a x$ como la inversa de $a^x$, esta operación se debe leer como ``logaritmo de $x$ en base $a$''. Usualmente se utiliza $\log x=\log_{10}x$.
\begin{prop}[Cambio de base]
Sean $a,b\in\R^+$, luego
\begin{equation}
\log_bx=\frac{\log_a x}{\log_a b}.
\end{equation}
\end{prop}
\begin{proof}
Definamos $y\equiv\log_a x$ y $z\equiv\log_bx$, es decir, $x=a^y=b^z$, por esta última igualdad se obtiene que $y=\log_a(b^z)=z\log_ab=\log_bx\log_ab$. Despejando
$$\log_bx=\frac{y}{\log_ab}=\frac{\log_ax}{\log_ab}.$$
\end{proof}
Utilizando este dato podemos ver que las propiedades del logaritmo natural son generales para cualquier base (positiva).

Para finalizar la sección, puede entender que más de alguno se sienta un tanto perdido entre el lío de potencias, exponentes y logaritmos, sin embargo, hay un truco usualmente llamado \textit{el triángulo del poder} (sacado de un video de 3Blue1Brown del mismo nombre) que consiste en lo siguiente:
\begin{figure}
\centering
\begin{tikzpicture}
\draw (90:1) node[above]{\color{nicegreen}3} -- (-150:1) node[below left]{\color{niceblue}2} -- (-30:1) node[below right]{\color{nicered}8} -- cycle;
\draw (2,1) node[right]{${\color{nicered}8}=2^3$} (2,{1/4}) node[right]{${\color{niceblue}2}=\sqrt[3]{8}$} (2,-.5) node[right]{${\color{nicegreen}3}=\log_28$};
\end{tikzpicture}
\caption{}
\end{figure}

Como puede ver si tapamos algún valor en el triángulo, los otros se acomodan de forma perfecta para recordar que operación aplicar. El ejemplo es general, en este caso se ha utilizado $2^3=8$, pues no se repiten números y es fácil, pero igual funciona con cualquier otro trío de números.

\section{Otras funciones elementales}
\begin{mydef}
Decimos que una función $f$ es \textit{par} syss $f(-z)=f(z)$. Asimismo, decimos que una función $f$ es \textit{impar} syss $f(-z)=-f(z)$.
\end{mydef}
Visualmente las funciones (reales) pares son reconocibles pues su imagen es simétrica en torno al eje $y$, mientras que las impares son simétricas en torno al punto 0.

Nótese que si $f$ es impar, $f(0)=0$, pues $f(0)=f(z-z)=f(z)-f(z)=0$.
\begin{thm}
Toda función $f:D\subseteq\R\rightarrow\R$ puede descomponerse en la suma de dos funciones: una par y otra impar, estas a su vez son únicas.
\end{thm}
\begin{proof}
Veamos que la parte par de $f$ es
$$f_p(x)=\frac{f(x)+f(-x)}{2},$$
mientras que la impar es
$$f_i(x)=\frac{f(x)-f(-x)}{2}.$$
La unicidad es trivial.
\end{proof}
A su vez, veamos que estas funciones ``ganan'' su nombre debido a las siguientes propiedades:
\begin{prop}[Propiedades de las funciones pares e impares]
Sean $\alpha,\beta\in\R$ y $f,g$ funciones:
\begin{itemize}
\item $f$ es par (impar resp.) syss $1/f$ es par (impar resp.).
\item $f$ es par (impar resp.) syss $\alpha f$ (con $\alpha\neq 0$) es par (impar resp.).
\item Si $f$ y $g$ son pares (impares resp.) entonces $\alpha f+\beta g$ es par (impar resp.).
\item Si $f$ y $g$ son pares o impares entonces $f\cdot g$ es par.
\item Si entre $f$ y $g$ hay una función par y una impar entonces $f\cdot g$ es impar.
\item Si $f$ es derivable y par (impar resp.) entonces $f'$ es impar (par resp.).
\end{itemize}
\end{prop}
Un ejemplo de funciones pares son $x^{2n}$ y de impares son $x^{2n+1}$, donde $n\in\Z$. Por las propiedades de estas, podemos ver que $\sin x$ es impar mientras que $\cos x$ es par.

\subsection*{Funciones trigonométricas}
Como dijimos, definiremos ahora las funciones trigonométricas en base a las series de Taylor derivadas de ella. Veremos una propiedad muy interesante en un momento, pero primero nótese que
$$e^{-\imaginary z}=\cos(-z)+\imaginary\sin(-z)=\cos z-\imaginary\sin z,$$
con esta ecuación podemos construir las siguientes formulas
\begin{align}
\cos z&=\frac{e^{\imaginary z}+e^{-\imaginary z}}{2}\label{eq:cos-exp},\\
\sin z&=\frac{e^{\imaginary z}-e^{-\imaginary z}}{2\imaginary}\label{eq:sin-exp}.
\end{align}
A su vez, utilizaremos la definición de función exponencial para ver que
\begin{align*}
e^{\imaginary(\alpha+\beta)}&=e^{\imaginary\alpha}e^{\imaginary\beta}=(\cos\alpha+\imaginary\sin\alpha)(\cos\beta+\imaginary\sin\beta)\\
&=\cos\alpha\cos\beta-\sin\alpha\sin\beta+\imaginary(\sin\alpha\cos\beta+\cos\alpha\sin\beta).
\end{align*}
Es fácil ver que $e^{-\imaginary(\alpha+\beta)}$ representa la misma fórmula pero con la parte imaginaria de signo opuesto. Aplicando esto en las ecuaciones~(\ref{eq:cos-exp}) y (\ref{eq:sin-exp}), además que probando $\alpha-\beta$ nos resulta en las siguientes fórmulas
\begin{align}
\cos(\alpha\pm\beta)&=\cos\alpha\cos\beta\mp\sin\alpha\sin\beta,\\
\sin(\alpha\pm\beta)&=\sin\alpha\cos\beta\pm\cos\alpha\sin\beta,
\end{align}
que son clásicas de todo curso de trigonometría. Esta propiedad la podemos extender a $\tan x$:
\begin{align}
\tan(\alpha\pm\beta)&=\frac{\sin(\alpha\pm\beta)}{\cos(\alpha\pm\beta)}\notag\\
&=\frac{\sin\alpha\cos\beta\pm\cos\alpha\sin\beta}{\cos\alpha\cos\beta\mp\sin\alpha\sin\beta}\notag\\
&=\frac{\tan\alpha\pm\tan\beta}{1\mp\tan\alpha\tan\beta}.
\end{align}
A su vez, vemos que de (\ref{eq:cos-exp}) y (\ref{eq:sin-exp}) se obtiene que
\begin{align}
\cos^2z+\sin^2z&=\left(\frac{e^{\imaginary z}+e^{-\imaginary z}}{2}\right)^2+\left(\frac{e^{\imaginary z}-e^{-\imaginary z}}{2\imaginary}\right)^2\notag\\
&=\frac{(e^{\imaginary z}+e^{-\imaginary z})^2-(e^{\imaginary z}-e^{-\imaginary z})^2}{4}\notag\\
&=\frac{e^{2\imaginary z}+2+e^{-2\imaginary z}-(e^{2\imaginary z}-2+e^{-2\imaginary z})}{4}\notag\\
&=1.\label{eq:trig-identity}
\end{align}
En todo esto, hay un elemento característico de la geometría restante y es el número $\pi$. En particular, definiremos tal valor como la mitad primera raíz positiva de la función $\cos x$, es decir, $\cos(\pi/2)=0$ donde $\pi$ es un número real positivo. Por la identidad~(\ref{eq:trig-identity}) sabemos que $\sin(\pi/2)$ es 1 o $-1$, la segunda la descartamos, pues
$$\sin(\pi)=\sin(\pi/2+\pi/2)=2\sin(\pi/2){\color{nicered}\cos(\pi/2)}=0$$
es la primera raíz positiva, pues $\cos(\pi/2)$ es el primer punto dónde aquello ocurre. Sabiendo que $\sin^2(\pi/2)=1$ podemos ver que $\cos(\pi)=-1$. Luego deducimos que $\sin(2\pi)=0$ y $\cos(2\pi)=1$. O más generalmente que
\begin{equation}
\sin(x+2\pi)=\sin x,\quad\cos(x+2\pi)=\cos x,
\end{equation}
finalmente, ambas son periódicas (se repiten), por lo cual, sólo nos interesan en el intervalo $[0,2\pi)$.
\begin{figure}
\centering
\begin{tikzpicture}
\begin{axis}[2dgraph,
	width = 12cm,
	xmin=-2*pi, xmax=2*pi,
	ymin=-5, ymax=5,
	samples=50,
	smooth,
	xtick={-6.28318, -4.7123889, -3.14159, -1.5708, 0, 1.5708, 3.14159, 4.7123889, 6.28318},
	xticklabels = {$-2\pi$, $-\frac{3}{2}\pi$, $-\pi$, $-\frac{1}{2}\pi$, $0$, $\frac{1}{2}\pi$, $\pi$, $\frac{3}{2}\pi$, $2\pi$},
	xlabel = $x$, ylabel = $y$
]
\begin{scope}[very thick]
\addplot[niceblue, domain=-2*pi:2*pi] {sin(deg(x))};
\addplot[nicepurple, domain=-2*pi:2*pi] {cos(deg(x))};
\foreach \n in {-2,...,2} {
	\addplot[nicered, mark=none, domain={(\n-.5)*pi+.01}:{(\n+.5)*pi-.01}] {tan(deg(x))};
}
\legend{$\sin x$, $\cos x$, $\tan x$}
\end{scope}
\end{axis}
\end{tikzpicture}
\caption{}
\end{figure}

Además, observe que aplicando la suma de argumentos con $\pi/4$ obtenemos que
$$0=\cos\frac{\pi}{2}=\cos\left(2\frac{\pi}{4}\right)=\cos^2\frac{\pi}{4}-\sin^2\frac{\pi}{4},$$
es decir, $|\cos(\pi/4)|=|\sin(\pi/4)|$, pero como las conclusiones indican, las funciones son positivas en ese intervalo, luego son iguales. Si queremos calcular su valor podemos usar la función seno en ese punto
$$1=\sin\frac{\pi}{2}=\sin\left(2\frac{\pi}{4}\right)=2\sin\frac{\pi}{4}\cos\frac{\pi}{4},$$
luego, despejando, nos queda que $\sin(\pi/4)=\cos(\pi/4)=1/\sqrt{2}=\sqrt{2}/2$. Como la función $\tan$ es la división entre ambas, obtenemos que $\tan(\pi/4)=1$ (este hecho será fundamental).

Ahora probaremos que $\tan:(-\pi/2,\pi/2)\rightarrow\R$ es una biyección. Es fácil probar que es suprayectiva, pues evidentemente es continua, $\lim_{x\to-\pi/2^+}\tan x=-\infty$ y $\lim_{x\to\pi/2^-}\tan x=\infty$, luego por teorema de valores intermedios es suprayectiva. Es inyectiva pues su derivada es $1+\tan^2x$, es decir, es siempre positiva, luego es monótona creciente. Al serlo, existe $\tan^{-1}:\R\rightarrow(-\pi/2,\pi/2)$.

\subsection*{Cálculo de $\pi$}
Una propiedad de $x=\tan y$ es que al ser la inversa de una función derivable posee derivada
$$(\tan^{-1}x)'=\frac{1}{(\tan y)'}=\frac{1}{1+\tan^2y}=\frac{1}{1+x^2},$$
y, luego, nótese que la ecuación obtenida es una potencia de un binomio, con la cuál, por el teorema general de Newton es
$$f(x)=\frac{1}{1+x^2}=\sum_{k=0}^\infty\binom{-1}{k}x^{2k}$$
syss $|x|\lt 1$, con un poco de trabajo es fácil probar que $\binom{-1}{k}=(-1)^k$ (para $k$ natural), luego como esta expresión se obtiene a través de una expansión de Taylor con centro cero, las derivadas deben ser
$$f^{(2k)}(0)=(-1)^k(2k)!,\quad f^{(2k+1)}(0)=0,$$
luego, la expansión de Taylor deseada para $g(x)=\tan^{-1}x$ está \textit{desfasada}, en el sentido de que tendremos $g^{(n)}=f^{(n-1)}$ en su lugar, lo que nos conlleva a deducir que la expresión que estamos buscando es
\begin{equation}\label{eq:arctan-taylor}
\tan^{-1}(x)=\sum_{k=0}^\infty(-1)^k\frac{x^{2k+1}}{2k+1}=x-\frac{x^3}{3}+\frac{x^5}{5}-\cdots,
\end{equation}
que por criterio de D'Alambert converge para todo $|x|\lt 1$ y por criterio de Leibniz converge para $|x|=1$, es decir, sirve para todo $x\in[-1,1]$. Finalmente, nótese que probamos que $\tan(\pi/4)=1$, finalmente
$$\pi=4\sum_{k=0}^\infty\frac{(-1)^k}{2k+1}=4\left(1-\frac{1}{3}+\frac{1}{5}-\cdots\right)$$
a esta se le llama la fórmula de Gregory-Leibniz. Sin embargo, este método es tan lento que se necesita $n=300$ para obtener los dos primeros decimales. Por lo cual, acudiremos a otro forma más precisa, que son las llamadas fórmulas de Machin-Like.

Primero, cabe destacar que $\tan^{-1}(1/5)$ es bastante cercano a $\pi/16$, esto no lo probaremos rigurosamente (pues aún desconocemos el valor de $\pi$), pero sólo servirá de observación. En particular, vemos que como $\tan^{-1}x$ tiene de conjunto imagen el intervalo $(-\pi/2,\pi/2)$, debe existir $r$ tal que
$$\frac{\pi}{16}=\tan^{-1}\frac{1}{5}-\frac{1}{4}\tan^{-1}(r),$$
aplicando despeje a la ecuación, vemos que ese $r$ debe satisfacer
$$r=\tan\left(4\tan^{-1}\frac{1}{5}-\frac{\pi}{4}\right),$$
luego por suma de argumentos debe ser
$$r=\frac{{\color{nicered}\tan(4\tan^{-1}(1/5))}-1}{1+{\color{nicered}\tan(4\tan^{-1}(1/5))}}.$$
Ahora vemos que el término en rojo es indispensable para poder avanzar, aplicando dos veces suma de argumentos se llega a que
$$\tan\left(4\tan^{-1}\frac 15\right)=\frac{120}{119},$$
aplicando esto en la ecuación de nuestro buscado $r$ obtenemos que $r=1/239$. Volviendo a la ecuación original nos quedamos con que
$$\frac{\pi}{4}=4\tan^{-1}\frac{1}{5}-\tan^{-1}\frac{1}{239},$$
que converge realmente bien:
\begin{figure}
\centering
\begin{tabular}{|cl|cl|}
0 & 3,18326359832636 & 6 & 3,141592653623555 \\
1 & 3,1405970293260603 & 7 & 3,1415926535886025 \\
2 & 3,1416210293250346 & 8 & 3,141592653589836 \\
3 & 3,1415917721821773 & 9 & 3,1415926535897922 \\
4 & 3,1415926824043994 & 10 & 3,141592653589794 \\
5 & 3,1415926526153086 & 11 & 3,141592653589794
\end{tabular}
\caption{Convergencia de $\pi$.}
\end{figure}

Cabe decir que las fórmulas de Machin-Like no constituyen sólo la que acabamos de ver, sino que todas son una serie de ellas que aplican sumas de tangente a la inversa de argumentos pequeños, esto se debe a que, como puede adivinar, la fórmula para $\tan^{-1}x$ converge más rápidamente para $x$ cercanos a cero, lo cual con un segundo de meditación puede ver porque es el caso.

\subsection*{Funciones hiperbólicas}
Nótese que por las ecuaciones (\ref{eq:cos-exp}) y (\ref{eq:sin-exp}) podemos ver que
$$\cos(\imaginary z)=\frac{e^{-z}+e^z}{2},\quad\sin(\imaginary z)=\frac{e^{-z}-e^z}{2\imaginary}=-\imaginary^{-1}\frac{e^z-e^{-z}}{2},$$
con lo cual se definen:
\begin{mydef}
Las funciones $\sinh,\cosh,\tanh:\C\rightarrow\C$ (llamadas seno, coseno y tangente hiperbólica, respectivamente) son aquellas tales que
$$\sinh z\equiv-\imaginary\sin(\imaginary z)=\frac{e^z-e^{-z}}{2},\quad\cosh z\equiv\cos(\imaginary z)=\frac{e^z+e^{-z}}{2},$$
$$\tanh z\equiv\frac{\sinh z}{\cosh z}=-\imaginary\tan(\imaginary z)=\frac{e^z-e^{-z}}{e^z+e^{-z}}.$$
\end{mydef}
Podemos ver que $\sinh$ y $\tanh$ siguen siendo impares, mientras $\cosh$ es par. Más importante aun, satisfacen la siguiente ecuación fundamental
\begin{equation}
\cosh^2z-\sinh^2z=1,
\end{equation}
que en algún curso de geometría explicarán que es la ecuación que define una hipérbola. Con esto deduces las identidades de suma de argumentos:
\begin{align*}
\sinh(\alpha\pm\beta)&=\sinh\alpha\cosh\beta\pm\cosh\alpha\sinh\beta,\\
\cosh(\alpha\pm\beta)&=\cosh\alpha\cosh\beta\pm\sinh\alpha\sinh\beta,\\
\tanh(\alpha\pm\beta)&=\frac{\tanh\alpha\pm\tanh\beta}{1\pm\tanh\alpha\tanh\beta}.
\end{align*}
Por impar, $\sinh0=\tanh0=0$ y $\cosh0=1$. Además, sus derivadas son
$$(\sinh x)'=\cosh x,\quad(\cosh x)'=\sinh x,\quad(\tanh x)'=\frac{1}{\cosh^2x}=1-\tanh^2x.$$
\begin{figure}
\centering
\begin{tikzpicture}
\begin{axis}[2dgraph,
	width = 12cm,
	domain=-6:6,
	ymin=-5, ymax=5,
	samples=100,
	smooth,
	xlabel = $x$, ylabel = $y$
]
\begin{scope}[very thick]
\addplot[niceblue] {sinh(x)};
\addplot[nicepurple] {cosh(x)};
\addplot[nicered] {tanh(x)};
\legend{$\sinh x$, $\cosh x$, $\tanh x$}
\end{scope}
\end{axis}
\end{tikzpicture}
\caption{}
\end{figure}

\subsection*{Métodos de graficación}
Antes de la llegada de las computadoras, la graficación era todo un desafío para matemáticos, por lo que desarrollaron un ``sistema'' de pasos sobre qué hacer para encontrar la manera más eficaz para lograrlo:
\begin{enumerate}[1.]
\item Buscar los ``ceros'' de la función, osea, los puntos en donde $f(x)=0$.
\item Buscar los ceros de la derivada. Si hay un punto en dónde $f'(x)=0$, es recomendable tenerlo en cuenta, y es recomendable calcular $f(x)$ en el mismo.
\item Ver el valor de la segunda derivada en un punto donde la derivada sea nula, y buscar ceros de la segunda derivada (punto de inflexión). El primer paso se incluye, pues si $f'(x)=0$ y la función es convexa (cóncava resp.), entonces es un mínimo (máximo resp.) local; si el punto es de inflexión, puede no ser ninguno (i.e. la función $x^3$). Recordad que en punto de inflexión, puede cambiar la concavidad de esta.
\item También es recomendable ver dónde se indetermina y los límites (laterales de ser necesarios) en dicho punto. Lo mismo se dice para ver si la función es par o impar (o ninguna de ambas), o si es periódica. Y para terminar, buscar el límite cuando $x$ tiende a infinito positivo y negativo.
\end{enumerate}
Un ejemplo breve será analizar la función $f(x)=x^3-6x^2+11x-6$, será un tanto anti-intuitivo, pero las raíces de esta función son los puntos $\{1,2,3\}$. Si derivamos la función obtenemos $3x^2-12x+11$, cuyas raíces son $2\pm\frac{\sqrt{3}}{3}$ (1,422... y 2,577...). Por otro lado, la segunda derivada es $6(x-2)$, cuya raíz es 2. Con esta información vemos que las raíces de la derivada son un máximo y un mínimo local respectivamente. Es fácil ver que $\lim_{x\to\pm\infty}f(x)=\pm\infty$.
\begin{figure}
\centering
\begin{tikzpicture}
\begin{axis}[2dgraph,
	width = 10cm,
	domain = 0:5,
	ymin=-2, ymax=2,
	samples=50,
	smooth,
	xlabel = $x$, ylabel = $f(x)$
]
\addplot[niceblue, very thick] {(x-1)*(x-2)*(x-3)};
\addplot[nicepurple, mark=*, only marks] coordinates {(1.423,.3849) (2.577,-.3849)} node[pos=0, above]{$f'(x_-)=0$} node[pos=1, below]{$f'(x_+)=0$};
\addplot[nicered, mark=*] coordinates {(2,0)} node[above right]{$f''(2)=0$};
\end{axis}
\end{tikzpicture}
\caption{}
\end{figure}

\chapter{Introducción a la integración}
Cálculo se compone de dos herramientas principales: la derivada y la integral. Mientras ya deberíamos de estar familiarizados con el primer concepto, no hemos tocado el segundo en absoluto. Sin embargo, a pesar de las nociones generales sobre el asunto, la integración no es cosa sencilla de enseñar, y sus bases per se son mucho más complicadas que las de la derivada. Este problema surge a partir de métodos muchísimo más avanzados que se relacionan con el \textbf{álgebra lineal} y \textbf{multilineal}, y con la \textbf{geometría diferencial} --a la cual ya nos acercaremos en el próximo capítulo-- por lo que debemos conformarnos con una vista bastante rudimentaria en torno al tema. Inclusive esta simplificación del problema requiere de dos definiciones de la misma herramienta: la primera se relaciona a las mismas derivadas en la sección de \textit{Primitivas} y la segunda es una nueva herramienta bajo el nombre \textit{Integral definida de Riemann}.

\section{Primitivas}
En el capítulo anterior enunciamos un teorema bastante importante que decía que si $f'=g'$ entonces $f=g+k$ donde $k\in\R$. Luego vemos que si quisiéramos desarrollar una herramienta similar a una \textit{antiderivada}, sabemos que el resultado serían un conjunto de funciones, todas similares, pero que difieren por una constante; esto nos lleva a llamar a la antiderivada $F$ de una función $f$ su \textit{primitiva}. En particular, este hecho lo denotaremos como
$$\int f(x)\,dx=F(x)+C,$$
donde el lector no debe interpretar esto como una igualdad estricta, pero sino como que la primitiva de $f(x)$ es una cierta función $F(x)$ el que puede diferir por una constante $C$. La expresión original solemos llamarla \textit{integral indefinida} o simplemente \textit{integral} (a futuro tendrá sentido este uso de la terminología). Recordar que la idea definitiva tras esta expresión es ver que $F'=f$. Además podemos ver que se cumplen
$$d\int f(x)\,dx=dF(x)=F'(x)\,dx=f(x)\,dx$$
y
$$\int df=\int f'(x)\,dx=f(x)+C.$$
Quiero dejar en claro que la notación de la integral es elegida digamos para combinarse con la notación de Leibniz de derivada, es decir, con nuestra noción del diferencial ya establecida, sin embargo, podría haberse tomado cualquier otra arbitraria. Los signos $\int\,dx$ sólo tienen significado cuando juntos, a pesar de que $dx$ ya lo posee independientemente, $\int$ no (aun que su semejanza a una gran ``S'' supone una interpretación de ``suma'' que comprenderemos pronto).

Ciertos argumentos aplicados a derivadas se utilizan para las primitivas, por ejemplo, $(kf)'=kf'$ y $(f+g)'=f'+g'$ se combinan para deducir que
\begin{equation}
\int\alpha f(x)+\beta g(x)\,dx=\alpha\int f(x)\,dx+\beta\int g(x)\,dx.
\end{equation}
De hecho, como estamos trabajando con la integral como herramienta antiderivativa, podemos deducir (a partir del producto de derivadas y reglas de la cadena) dos técnicas fundamentales de integración: el \textit{producto de funciones}
\begin{equation}
\int f\,dg=fg-\int f'g\,dx
\end{equation}
y el \textit{cambio de variable}
\begin{equation}
\int f(x(t))x'(t)\,dt=\int f(x)\,dx.
\end{equation}
Además, podemos calcular integrales debido a nuestras derivadas:
\begingroup
\allowdisplaybreaks
\begin{align}
\int x^r\,dx&=\frac{x^r}{r+1}+C,\quad r\in\R\setminus\{1\}\\
\int x^{-1}\,dx&=\ln x+C\\
\int e^x\,dx&=e^x+C\\
\int a^x\,dx=\frac{a^x}{\ln a}+C,\quad a\in\R^+\\
\int\sin x\,dx&=-\cos x+C\\
\int\cos x\,dx&=\sin x+C\\
\int\frac{1}{\sqrt{1-x^2}}dx&=\sin^{-1}x+C\\
\int-\frac{1}{\sqrt{1-x^2}}dx&=\cos^{-1}x+C\\
\int\frac{1}{x^2+1}dx&=\tan^{-1}x+C\\
\int\frac{1}{\sqrt{x^2+1}}dx&=\sinh^{-1}x+C\\
\int\frac{1}{\sqrt{x^2-1}}dx&=\cosh^{-1}x+C\\
\int\frac{1}{1-x^2}dx&=\tanh^{-1}x+C.
\end{align}
\endgroup
Veamos un par de aplicaciones de estos teoremas, al calcular la integral de $\ln x$, aquí en particular podemos utilizar el producto de funciones considerando que las dos funciones son 1 y $\ln x$
\begin{equation}
\int\ln x\,dx=x\ln x-\int\,dx=x(\ln x-1)+C.
\end{equation}
Algo que puede resultar muy molesto es tener que escribir ``$+C$'' al final de toda ecuación. Esto puede resolverse de una forma un tanto incómoda, pero eficaz. Supongamos que $F(x)$ es una de las antiderivadas de $f(x)$, entonces $F(b)-F(a)$ elimina la constante, y esto se aplica para toda solución de la forma $F(x)+C$. Luego definimos
$$\int_a^bf(x)\,dx=\left.F(x)\right|_a^b=F(b)-F(a),$$
ahora, es probable que un lector pueda objetar contra la definición ya dada diciendo que es una introducción informal del \textit{teorema fundamental del cálculo}, sin embargo, considere esto como definición.

\section{Uniformidad continua}
Una lección que obviamos en su momento y que ahora se nos puede hacer necesaria es la de \textit{uniformidad continuidad}. Consideremos la definición auxiliar estándar de continuidad, esta dice que para todo $\epsilon\gt 0$ debe existir un $\delta\gt 0$ tal que $d(x,a)\lt\delta$ implica $d(f(x),f(a))\lt\epsilon$ ($\lim_{x\to a}f(x)=f(a)$). Pero usualmente, veremos que esta $\delta$ es relativa a tu $a$ y esto es permitido, el ejemplo más común es la función $1/x$ que (inclusive sin la necesidad de la definición a través de límites) fue de las primeras en ver que es continua.
\begin{figure}
\centering
\begin{tikzpicture}
\begin{axis}[2dgraph,
	xmin=0, ymin=0, ymax=3,
	samples=70,
	xlabel=$x$, ylabel={$1/x$}
]
\addplot[niceblue, domain=.25:5, very thick] {1/x};
\foreach \x in {1.75,2.25,.75,.25} {\addplot[mark=none] coordinates {(0,\x) ({1/\x},\x) ({1/\x},0)};}
\foreach \x in {2,.5} {\addplot[dashed,mark=none] coordinates {(0,\x) ({1/\x},\x) ({1/\x},0)};}
\addplot[mark=none, draw=none] coordinates {(.6,.15) (2,.15)} node[pos=0, nicepurple]{\small $\delta_1=5/90$} node[pos=1, nicepurple]{\small $\delta_2=2/3$};
\addplot[mark=none] coordinates {(4,2.5)} node[pos=0, nicered]{$\epsilon=1/2$};
\end{axis}
\end{tikzpicture}
\caption{$\delta$s locales.}
\end{figure}
\begin{mydef}[Continuidad uniforme]
Una función $f:D\subseteq M\rightarrow M$, con $M$ un espacio métrico completo, es \textit{uniformemente continua} syss para todo $\epsilon\gt 0$ existe $\delta\gt 0$ tal que para todo $x,a\in D$
$$d(x,a)\lt\delta\implies d(f(x),f(a))\lt\epsilon.$$
\end{mydef}
La idea en la continuidad uniforme es que el $\delta$ elegido es ``universal''.
\begin{cor}
La continuidad uniforme implica continuidad.
\end{cor}
\begin{thm}[Criterio de continuidad irregular]
Sea $f:D\subseteq\R\rightarrow\R$, son equivalentes:
\begin{enumerate}[$a)$]
\item $f$ no es continua uniformemente.
\item Existe un $\epsilon\gt0$ tal que para todo $\delta\gt 0$ existen $x,y\in D$ tales que $|x-y|\lt\delta$ y $|f(x)-f(y)|\geq\epsilon$.
\item Existe $\epsilon\gt0$ y un par de secuencias $x_n,y_n$ en $D$ tales que $\lim_nx_n-y_n=0$ pero $|f(x_n)-f(y_n)|\geq\epsilon$.
\end{enumerate}
\end{thm}
\begin{proof}
$a)\iff b)$. Nótese que la expresión $b)$ es la negación con cuantificadores de la definición para $\R$.

$c)\implies b)$. Vemos que una secuencia requiere que para todo $\delta\gt 0$ exista $n_0\in\N_0$ tal que para todo $n\geq n_0$ $|x_n-y_n|\lt\delta$ y $|f(x_n)-f(y_n)|\geq\epsilon$.

$b)\implies c)$. A su vez podemos formar una secuencia utilizando $\delta=1/n$ y así obteniendo un par $x_\delta,y_\delta$ para cada $n$, formando así una sucesión tal que $\lim_nx_n-y_n=0$ y siempre cumple $|f(x_n)-f(y_n)|\geq\epsilon$ para algún $\epsilon$.
\end{proof}
\begin{thm}
Sea $f:[a,b]\rightarrow\R$ continua,  luego es uniformemente continua.
\end{thm}
\begin{proof}
Supongamos que $f$ no lo fuese. Luego existirían $\epsilon\gt0$ y $x_n,y_n$ contenidas en $I=[a,b]$ tales que $\lim_n(x_n-y_n)=0$ y $|f(x_n)-f(y_n)|\geq\epsilon$. Como $I$ es un cerrado acotado, toda sucesión admite una subsucesión convergente, luego $x_{n_k}$ converge digamos a $z$ contenido en $I$ (por ser cerrado). Como
$$|y_{n_k}-z|\leq|y_{n_k}-x_{n_k}|+|x_{n_k}-z|$$
se da que $y_{n_k}\to z$. Luego ambas subsucesiones convergen al mismo valor, pero como indicamos, el criterio de irregularidad les impide que sus imágenes converjan al mismo valor, contradiciendo el que $f$ sea continua.
\end{proof}
\begin{thm}
Sea $f:D\subseteq\R\rightarrow\R$ de Lipschitz, entonces es uniformemente continua.
\end{thm}
\begin{proof}
Veamos que es trivial pues elegimos $\delta=\epsilon/K$. Luego $f(x)-f(a)\lt K\cdot\epsilon/K=\epsilon$.
\end{proof}

\section{Integral de Riemann}
Ya vimos la \textit{integral} como directa herramienta antiderivativa, sin embargo, este enfoque no sería evidente hasta que uno de los matemáticos contemporáneos más importantes, Bernhard Riemann, formalizaría la vieja idea de integral y la relacionaría a la derivada.

Comencemos por plantearnos un problema diferente, supongamos que teniendo un gráfico obtenido por una cierta función $f$ acotada sobre un intervalo, y queremos calcular el ``área con signo'' bajo este gráfico, con ello nos referimos a que si el área está bajo el eje $x$ consideraremos un ``área negativa'', mientras que de estar sobre él la consideraremos ``positiva''. En este capítulo exploraremos la respuesta de Riemann.
\begin{mydef}[Partición]
Diremos que un conjunto $P$ es una partición de $[a,b]$ syss es un subconjunto finito de él y contiene a $a,b$. Usualmente se describen sus elementos como
$$P=\{a=x_0\lt x_1\lt\cdots\lt x_n=b\}.$$
\end{mydef}
Definiremos la norma de una partición $P$ como la máxima distancia entre dos elementos consecutivos
\begin{equation}
\Vert P\Vert=\max\{x_i-x_{i-1}\}_{i=1}^n.
\end{equation}
Para simplificar notación, escribiremos $I_i=[x_{i-1},x_i]$. A su vez, como $f$ es acotada, podemos definir
$$m_i=\inf\{f(x):x\in I_i\},\quad M_i=\sup\{f(x):x\in I_i\}$$
con estos datos, podemos describir la \textit{suma inferior} y \textit{superior de Riemann} como
$$L(f;P)=\sum_{i=1}^nm_i(x_i-x_{i-1}),\quad U(f;P)=\sum_{i=1}^nM_i(x_i-x_{i-1})$$
\begin{figure}
\centering
\begin{tikzpicture}
\begin{axis}[demo,
	xlabel=$x$, ylabel={$f(x)$},
	domain=2:5, ymin=0, ymax=3,
	xmin = 1.5, xmax=5.5]
\begin{scope}[draw=black, mark=none]
\foreach \x in {2,2.2,...,4.8} {\addplot[fill=niceblue, fill opacity=.6] coordinates {(\x,0) ({\x+.2},0) ({\x+.2},{.25*(\x-3)^2+1}) (\x,{.25*(\x-3)^2+1}) (\x,0)}; \addplot[solid] coordinates {(\x,{.25*(\x-3)^2+1}) (\x,{.25*(\x-2.8)^2+1}) ({\x+.2},{.25*(\x-2.8)^2+1}) ({\x+.2},{.25*(\x-3)^2+1})};}
\addplot {.25*(x-3)^2+1};
\end{scope}
\end{axis}
\end{tikzpicture}
\caption{}
\end{figure}

En la figura vemos ambas sumas de Riemann sobre un gráfico. El área pintada corresponde a aquella obtenida utilizando $f(x_{i-1})$ en lugar de $m_i$ en la ecuación. Es evidente que $L(f;P)\leq U(f;P)$ para $P$ fijo.
\begin{mydef}[Refinamiento]
Sea $P$ una partición de $f:[a,b]\rightarrow\R$, $Q$ se dice un \textit{refinamiento} de $P$ syss $Q\supseteq P$. Dadas dos particiones $P_1,P_2$; una tercera se dice \textit{refinamiento común} syss $Q\subseteq P_1\cup P_2$.
\end{mydef}
\begin{lem}
Sea $f:[a,b]\rightarrow\R$ una función acotada con $P$ una partición y $Q$ un refinamiento de $P$, entonces
\begin{align*}
L(f;P)&\leq L(f;Q)\leq L(f;P)+2Mn\Vert P\Vert,\\
U(f;P)&\geq L(f;Q)\geq U(f;P)-2Mn\Vert P\Vert,
\end{align*}
donde $M$ es la cota de $f$ y $n=|Q\setminus P|$.
\end{lem}
\begin{proof}
Lo demostraremos por inducción sobre $n$.

Consideremos un intervalo $I_i$ y un punto $z\in I_i$, luego definamos $m^{\prime}_i=\inf\{f(x):x\in[x_{i-1},z]\}$ y $m^{\prime\prime}_i=\inf\{f(x):x\in[z,x_i]\}$. Evidentemente $m_i\leq m^{\prime}_i,m^{\prime\prime}_i$ (por inclusión conjuntivista y definición de ínfimo), por lo cual
\begin{align*}
m_i(x_{i-1}-x_i)&=m_i(z-x_{i-1})+m_i(x_i-z)\\
&\leq m^{\prime}_i(z-x_{i-1})+m^{\prime\prime}_i(x_i-z).
\end{align*}
Como hemos añadido un sólo punto, podemos ver que lo que debemos demostrar es que $L(f;Q)-L(f;P)\leq2M\Vert P\Vert$. Asimismo, la resta se cancela a exceptuar por el ``lugar'' en dónde introducimos el nuevo punto:
\begin{align*}
L(f;Q)-L(f;P)&=m^{\prime}_i(z-x_{i-1})+m^{\prime\prime}_i(x_i-z)-m_i(x_i-x_{i-1})\\
&=(m^{\prime}_i-m_i)(z-x_{i-1})+(m^{\prime\prime}_i-m_i)(x_i-z).
\end{align*}
Es fácil ver que $|m^\prime_i-m_i|\leq|m^\prime_i|+|m_i|\leq 2M$ (análogo para $m^{\prime\prime}_i$), mientras que $z-x_i\leq\Vert P\Vert$. Para mostrar el caso inductivo, llamemos $P_n$ al refinamiento obtenido y agreguémosle un punto, obteniendo $P_{n+1}$, utilizando el método anterior obtenemos
\begin{align*}
L(f;P_n)-L(f;P)+L(f;P_{n+1})-L(f;P_n)&\leq 2Mn\Vert P\Vert+2M\Vert P_n\Vert\\
&\leq 2M(n+1)\Vert P\Vert.
\end{align*}
La demostración es análoga para la suma superior.
\end{proof}
\begin{mydef}[Integrales de Darboux y suma de Riemann]
Sea $f:[a,b]\rightarrow\R$ acotada, definimos la \textit{integral inferior de Darboux} como
$$\lowint_a^bf(x)\,dx=\sup_{P\subseteq[a,b]}L(f;P)$$
y la \textit{integral superior de Darboux} como
$$\upint_a^bf(x)\,dx=\inf_{P\subseteq[a,b]}U(f;P).$$
Una \textit{suma de Riemann} es cualquier sumatoria, en donde $\xi$ es un conjunto de \textit{elementos representativos} $\xi_i\in I_i$
$$S(f;(P,\xi))=\sum_{i=1}^nf(\xi_i)(x_i-x_{i-1}).$$ 
\end{mydef}
En particular, solemos referirnos a la \textit{integral de Riemann} al límite
$$I(f)=\lim_n\sum_{i=1}^nf(x_{i-1})(x_i-x_{i-1}),$$
donde $x_i-x_{i-1}=(b-a)/n$.
\begin{mydef}[Integral de Riemann-Steiltjes]
Dadas $f,\alpha:[a,b]\rightarrow\R$ acotadas con $\alpha$ monótona creciente, entonces una suma de Steiltjes (para acortar) es aquella tal que $P$ es partición con $\xi$ conjunto representativo
$$S(f;(P,\xi);\alpha)=\sum_{i=1}^n f(\xi_i)(\alpha(x_i)-\alpha(x_{i-1})),$$
si, en cambio, utilizamos $m_i$ (resp. $M_i$) en lugar de $f(\xi_i)$ le llamamos \textit{suma inferior (resp. superior) de Steiltjes} y le denotamos como usualmente pero con el argumento de $\alpha$ al final.

Análogo a las integrales de Riemann y Darboux se definen las integrales inferiores y superiores de Steiltjes como
\begin{align*}
\lowint_a^bf(x)\,d\alpha(x)&=\sup_{P\subseteq[a,b]}L(f;P;\alpha)\\
\upint_a^bf(x)\,d\alpha(x)&=\inf_{P\subseteq[a,b]}U(f;P;\alpha).
\end{align*}
\end{mydef}
Veamos que la expresión $d\alpha(x)$ es meramente simbólica, pues podría simplificarse a $d\alpha$ (y eso haremos). Además, la integral inferior (resp. superior) de Darboux es la integral inferior (resp. superior) de Steiltjes con $\alpha(x)=x$.

Añadido el argumento de $\alpha$, la norma $\Vert P\Vert$ se redefine como $\max_i(\alpha(x_i)-\alpha(x_{i-1}))$. Es fácil ver que las propiedades asignadas a las sumas de Riemann se conservan en las sumas de Steiltjes, con lo cual llegaremos a resultados más generales.
\begin{thm}
Sean $f,\alpha$ sobre $[a,b]$ en $\R$ acotada, con $\alpha$ monótona creciente, luego
$$\lowint_a^bf(x)\,d\alpha\leq\upint_a^bf(x)\,d\alpha$$
\end{thm}
\begin{proof}
Previo al teorema demostraremos que dado cualquier $P_1,P_2$ particiones cualesquiera se da $L(f;P_1;\alpha)\leq L(f;P_2;\alpha)$. Para esto, tomamos $Q$ un refinamiento común y vemos que por el lema anterior
$$L(f;P_1;\alpha)\leq L(f;Q;\alpha)\leq L(f;Q;\alpha)\leq L(f;P_2;\alpha).$$
Teniendo esto, podemos ver que para toda partición $P$, $l=L(f;P_1;\alpha)$ es una cota inferior de $U(f;\,;\alpha)$, luego $l$ es menor o igual al ínfimo de $U(f;\,;\alpha)$ que denotaremos como $U$. Además, por esto, $U$ es cota superior de $L(f;\,;\alpha)$, con lo cual, su supremo $L\leq S$.
\end{proof}
Luego, utilizando $\alpha=x$ llegamos al mismo resultado para las integrales de Darboux. Es también evidente que la integral de Riemann está acotada por la integral inferior y superior de Darboux.
\begin{mydef}[Riemann Integrable]
Decimos que una función $f:[a,b]\rightarrow\R$ es Riemann integrable sobre $\alpha$ (lo que denotaremos como $f\in\mathscr{R}[\alpha]$) syss
$$\lowint_a^bf(x)\,d\alpha=\upint_a^bf(x)\,d\alpha=\int_a^bf(x)\,d\alpha,$$
la última expresión se denomina \textit{integral definida} de $f$ en $[a,b]$ sobre $\alpha$.

Se dice simplemente Riemann integrable si $\alpha=x$.
\end{mydef}
En el futuro evitaremos redundar en las condiciones para $\alpha$.

A pesar de que utilizamos la misma notación que en la sección de \textit{Primitivas}, debe considerar que, por el momento, las integrales definidas de Riemann y Steiltjes, y la antiderivada definida son dos herramientas distintas.
\begin{thm}
$f\in\mathscr{R}[\alpha]$ syss para todo $\epsilon\gt 0$ existe una partición $P_\epsilon$ tal que para toda $P\supseteq P_\epsilon$ cumple
$$U(f;P_\epsilon;\alpha)-L(f;P_\epsilon;\alpha)\lt\epsilon.$$
\end{thm}
\begin{proof}
$\implies$. Si $f\in\mathscr{R}[\alpha]$ es porque la integral inferior $L$ y superior $S$ de Steiltjes, concuerdan, recordemos que ambas se basan en una definición de ínfimo y supremo que pueden reescribirse como
\begin{align*}
\forall\epsilon\gt 0\exists P_\epsilon:\forall P\supseteq P_\epsilon&\;L-L(f;P;\alpha)\lt\epsilon\\
\forall\epsilon\gt 0\exists P^\prime\epsilon:\forall P\supseteq P_\epsilon&\;U(f;P;\alpha)-U\lt\epsilon.
\end{align*}
Tomemos $\epsilon/2$ para obtener y definamos $P^{\prime\prime}_\epsilon=P_{\epsilon/2}\cup P^\prime_{\epsilon/2}$, luego todo $P$ subconjunto de él satisface $ \color{niceblue}L-L(f;P;\alpha)\lt\epsilon/2$ y $\color{nicered}S(f;P;\alpha)-S\lt\epsilon/2$, sumando ambas expresiones obtenemos
$$\cancelto{0}{{\color{niceblue}L}-{\color{nicered}U}}+{\color{nicered}U(f;P;\alpha)}-{\color{niceblue}L(f;P;\alpha)}\lt{\color{niceblue}\frac{\epsilon}{2}}+{\color{nicered}\frac{\epsilon}{2}}=\epsilon.$$
$\Longleftarrow$. Conservemos la notación de $L$ y $U$ de la demostración de la implicancia. Vemos que la última expresión equivale a 
$$L(f;P;\alpha)\leq L\leq U\leq U(f;P;\alpha)\lt L(f;P;\alpha)+\epsilon\leq L+\epsilon$$
en síntesis
$$-\epsilon\lt 0\leq U-L\lt\epsilon$$
lo que satisface la definición de límite, es decir, $U=L$, por lo tanto, es Riemann integrable sobre $\alpha$.
\end{proof}
\begin{thm}
Sea $f:[a,b]\rightarrow\R$ continua, entonces $f\in\mathscr{R}[\alpha]$.
\end{thm}
\begin{proof}
Para probar esto haremos uso de nuestro criterio anterior. Tomemos $\epsilon\gt 0$, entonces evidentemente existe $\eta\gt 0$ tal que
$$\eta(\alpha(b)-\alpha(a))\lt\epsilon.$$
Luego existe $\delta$ tal que para todo $x,y\in[a,b]$
$$|x-y|\lt\delta\implies|f(x)-f(y)|\lt\eta.$$
Si elegimos una partición $P$ tal que $\Delta x_i\lt\delta$ siempre, entonces
$$M_i-m_i\lt\eta$$
(pues como $f$ es continua sobre $I_i$, por 1\textsuperscript{r} teorema de Weierstrass, el conjunto imagen es compacto). Finalmente
\begin{align*}
U(f;P;\alpha)-L(f;P;\alpha)&=\sum_{i=1}^n|M_i-m_i|\Delta\alpha_i\\
&\leq\eta\sum_{i=1}^n\Delta\alpha=\eta(\alpha(b)-\alpha(a))\lt\epsilon.
\end{align*}
\end{proof}
\begin{thm}
Sea $f:[a,b]\rightarrow\R$ monótona y $\alpha(x)$ continua (además de monótona), entonces $f\in\mathscr{R}[\alpha]$.
\end{thm}
\begin{proof}
Como $\alpha$ es continua y monótona creciente, por segundo teorema de Weierstrass podemos obligar que nuestra partición $P_n$ satisfaga que
$$\alpha(x_i)-\alpha(x_{i-1})=\frac{\alpha(b)-\alpha(a)}{n}=\Delta\alpha$$
para cualquier $n$. Luego, como $f$ es monótona (y supondremos que es creciente)
$$M_i=f(x_i),\quad m_i=f(x_{i-1})$$
por el criterio
\begin{align*}
U(f;P_n;\alpha)-L(f;P_n;\alpha)&=\Delta\alpha\sum_{i=1}^nf(x_i)-f(x_{i-1})\\
&=\frac{\alpha(b)-\alpha(a)}{n}(f(b)-f(a))\lt\epsilon,
\end{align*}
por propiedad arquimediana. Es análogo si $f$ es decreciente.
\end{proof}
\begin{thm}
Sea $f\in\mathscr{R}[\alpha]$ en $[a,c]$ syss dado $b\in[a,c]$ se cumple que $f\in\mathscr{R}[\alpha]$ en $[a,b]$ y $[b,c]$. En cuyo caso
\begin{equation}
\int_a^cf(x)\,d\alpha=\int_a^bf(x)\,d\alpha+\int_b^cf(x)\,d\alpha.
\end{equation}
\end{thm}
\begin{proof}
$\Longleftarrow$. Definamos $f_1=f|_{[a,b]}$ y $f_2=f|_{[b,c]}$. Como $f_1,f_2\in\mathscr{R}[\alpha]$, por criterio de integración, existen $P_1,P_2$ tal que
$$U(f_1;P_1;\alpha)-L(f_1;P_1;\alpha)\lt\epsilon/2$$
y análogo a ello. Luego es evidente que $P=P_1\cup P_2$ es una partición de $[a,c]$ con $U(f;P;\alpha)=U(f_1;P_1;\alpha)+U(f_2;P_2;\alpha)$ y análogo con $L$. Finalmente
\begin{align*}
U(f;P;\alpha)-L(f;P;\alpha)&=\\&U(f_1;P_1;\alpha)-L(f_1;P_1;\alpha)+U(f_2;P_2;\alpha)-L(f_2;P_2;\alpha)\\
\lt&\frac{\epsilon}{2}+\frac{\epsilon}{2}=\epsilon.
\end{align*}
\end{proof}
\begin{mydef}
Supongamos que $a\gt b$ entonces definimos
$$\int_a^bf(x)\,d\alpha=-\int_b^af(x)\,d\alpha\quad\text{y}\quad\int_a^af(x)\,d\alpha=0.$$
\end{mydef}
\begin{cor}
Sean $f\in\mathscr{R}[\alpha]$ en $[a,b]$, y sean $i,j,k\in[a,b]$ cualesquiera
$$\int_i^kf(x)\,d\alpha=\int_i^jf(x)\,d\alpha+\int_i^kf(x)\,d\alpha.$$
\end{cor}
\begin{proof}
Veamos que primero debemos probar que si $[c,d]\subset[a,b]$ entonces $f|_{[c,d]}$ es integrable, esto es consecuencia directa del teorema anterior. No perdemos generalidad asumiendo que $i'$ es el mínimo y $k'$ es el máximo entre $i,j,k$ (pues es un conjunto finito de puntos) y $j'$ es el punto intermedio; luego, utilizando la notación de que $\int_a^b f(x)\,d\alpha=I(a,b)$ deducimos que $I(i',k')=I(i',j')+I(j',k')$. Utilizando el que $-I(i',j')=I(j',i')$ deducimos todos los casos.
\end{proof}
\begin{thm}[Teorema Fundamental del Cálculo I]
Sea $f:[a,b]\rightarrow\R$ continua, luego posee (al menos una) primitiva $F:(a,b)\rightarrow\R$ tal que $F'(c)=f(c)$.
\end{thm}
\begin{proof}
Tómese cualquier $k\in[a,b]$; luego, una primitiva $F$ puede ser
$$F(x)=\int_k^xf(x)\,dx.$$
Probemos que esta $F$ satisface que $F'=f$:
\begin{align*}
\frac{dF}{dx}(c)&=\lim_{\epsilon\to0}\frac{\int_k^{c+\epsilon}f(x)\,dx-\int_k^cf(x)\,dx}{\epsilon}\\
&=\lim_{\epsilon\to0}\frac{\int_c^{c+\epsilon}f(x)\,dx+\int_k^cf(x)\,dx-\int_k^cf(x)\,dx}{\epsilon}\\
&=\lim_{\epsilon\to0}\frac{1}{\epsilon}\int_c^{c+\epsilon}f(x)\,dx.
\end{align*}
Luego, como $f$ es continua existen $u,v\in[x,x+\epsilon]$ tales que $f(u)$ (resp. $f(v)$) es el mínimo (resp. máximo) de $f$ en tal intervalo. Luego para toda suma de Riemann
$$f(u)\epsilon\lt S(f|_{[x,x+\epsilon]};P)\lt f(v)\epsilon$$
pero por continuidad, ambos tienden a $f(x)\epsilon$ y por teorema del sandwhich, $F'=f$.
\end{proof}
\begin{thm}[Teorema Fundamental del Cálculo II (Regla de Barrow)]
Sea $f:[a,b]\rightarrow\R$ una función continua con primitiva $F$, entonces
\begin{equation}
\int_a^b f(x)\,dx=F(b)-F(a).
\end{equation}
\end{thm}
\begin{proof}
Sabemos que como $f$ es continua, es Riemann integrable, por lo que consideraremos la suma de Riemann
$$\int_a^b f(x)\,dx=\lim_n\frac{b-a}{n}\sum_{i=1}^nf(x_{i-1}),$$
donde $x_i-x_{i-1}=\frac{b-a}{n}=\Delta x$ para todo índice $i$; esta suma es igual a la integral pues evidentemente está entre la suma inferior y superior de Darboux. Además podemos definir la serie telescópica
$$\sum_{i=1}^n F(x_i)-F(x_{i-1})=F(b)-F(a)$$
que nos será de gran utilidad, pues ahora, el teorema puede enunciarse como
$$\lim_n\sum_{i=1}^nf(x_{i-1})\Delta x-\sum_{i=1}^n(F(x_i)-F(x_{i-1}))=0,$$
para probarlo hay que ver que para todo $\epsilon\gt 0$ existe $n_0$ tal que $n\geq n_0$ satisface que la expresión anterior es estricta menor que $\epsilon$. Primero veremos que por teorema de valores medios existe $\xi_i\in I_i$ tal que
$$f(\xi_i)=\frac{F(x_i)-F(x_{i-1})}{\Delta x},$$
con lo cual, la expresión queda como
$$\lim_n\sum_{i=1}^n(f(x_{i-1})-f(\xi_i))\Delta x=0$$
ahora, como $f$ es continua y $\lim_n x_i-\xi_i=0$, se concluye que $\lim_n f(x_i)-f(\xi_i)=0$; por lo tanto, para todo $\epsilon/(b-a)$ existe $n_i$ (estándar) tal que para todo $n\geq n_i$ la expresión se cumple. Deje que $N=\max_in_i$ (pues todos los elementos son finitos), entonces
\begin{align*}
|\sum_{i=1}^N f(x_{i-1})-f(\xi_i)\Delta x|&\leq\sum_{i=1}^N|f(x_{i-1})-f(\xi_i)|\frac{b-a}{N}\\
&\lt\sum_{i=1}^N\frac{\epsilon}{b-a}\frac{b-a}{N}=\epsilon.
\end{align*}
\end{proof}
\begin{thm}
$\pi$ es irracional.
\end{thm}
\begin{proof}
Supongamos que fuese igual a $a/b$. Por definición, sabemos que es positivo, luego la función
$$f_n(x)=\frac{x^n(a-bx)^n}{n!}$$
es no negativa en $[0,\pi]$ y se demuestra que $f_n(x)=0$ y $f_n(\pi-x)=f_n(x)$. Sea $h(x)=a-2bx$, podemos probar por inducción que
$$f_n^{(k)}(x)=\sum_{i=0}^kc_i(f_{n-i}h^{j_i})(x),$$
donde $c_i,j_i\in\N$. Nótese que $f_0(x)=1$. Definamos $f:=f_n$ para un $n$ fijo, con lo cual podemos también definir
$$g(x)=f(x)-f^{(2)}(x)+f^{(4)}(x)-\cdots=\sum_{k=0}^\infty(-1)^kf^{(2k)}(x)$$
con lo que notamos que $g(0),g(\pi)$ son enteros. Además es fácil comprobar que $f(x)=g(x)+g''(x)$. De esta propiedad se comprueba que
$$\frac{d}{dx}[g'(x)\sin x-g(x)\cos x]=f(x)\sin x.$$
De aquí concluimos que
$$\int_0^\pi f(x)\sin x\,dx=g(0)+g(\pi)\in\Z$$
Como $f(x)$ y $\sin x$ son no-negativos en el intervalo $[0,\pi]$, en particular, en $\pi/2$ es mayor que cero. Ademas como $\sin x\leq 1$ se obtiene que
$$0\lt f(x)\sin x\leq f(x)=\frac{x^n(a-bx)^n}{n!}\lt\frac{a^n\pi^n}{n!};$$
utilizando esta última propiedad, integramos todos los lados para obtener que
$$0\lt\int_0^\pi f(x)\sin x\,dx\lt\frac{a^n\pi^{n+1}}{n!}$$
La última parte converge a cero cuando $n\to\infty$; luego existe $n_0$ tal que todo natural $n\geq n_0$ satisface que la integral es no-entera, contradicción.
\end{proof}

\part{Cálculo multivariable y teoría de la medida}
\chapter{Derivadas de varias variables}
Una de las herramientas más útiles para matemáticos, tanto amantes de la teoría como la aplicación, es el campo de la \textbf{geometría diferencial}, que es por lo general una aplicación particular entre la topología y el cálculo multivariable, lo que involucra un término muy curioso llamado \textit{variedad diferencial} (que estudiaremos en capítulos posteriores). Debido a nuestro breve --pero conciso-- acercamiento a la topología, podemos despreocuparnos con ese requisito, por ello dedicaremos este capítulo a analizar el cálculo (en particular las derivadas), para funciones de varias variables.

\section{Diferenciación}
La noción de la derivada en una variable es aquella de ``balancear'' una única recta tangente en un punto del gráfico. Pero al subir el número de variables, podemos ver que aparecen infinitas rectas según la dirección que elijamos. En cierta manera, para cada punto y una dirección dada, ``cortamos'' esa sección del gráfico para obtener uno de una única variable y calcular la derivada como normalmente, esta aclaración previa es necesaria.
\begin{mydef}
Sea $f:D\subseteq\R^n\rightarrow\R^m$ con $n,m\in\N_0$, $\R^n$ un espacio normado bajo norma euclidea y $D$ un abierto. Dado un vector $v$, se define
$$f'(a,v)=\lim_{\epsilon\to 0}\frac{f(a+\epsilon v)-f(a)}{\epsilon}$$
como la \textit{derivada direccional} de $f$ en $a$ según la dirección $v$. Nótese que $f'(a,v)\in\R^m$.
\end{mydef}
\begin{figure}
\centering
\begin{tikzpicture}
\begin{axis}[heatbox,
	view={45}{30},
	domain=-1.2:1.2, domain y=-1.2:1.2,
	zmin = -1.5, zmax=1.5,
	hide axis,
	grid=none]
\addplot3[surf] {sin(deg(x^2+y^2))};
\begin{scope}[mark=none,very thick]
\addplot3[nicegreen] coordinates {(-.2,1,{sin(deg(1))}) (.2,1,{sin(deg(1))})};
\addplot3[niceblue] coordinates {(0,.8,{sin(deg(1))-.2*2*cos(deg(1))}) (0,1,{sin(deg(1))}) (0,1.2,{sin(deg(1))+.2*2*cos(deg(1))})};
\end{scope}
\addplot3[niceblue!50!nicegreen, mark=*] coordinates {(0,1,{sin(deg(1))})};
\end{axis}
\end{tikzpicture}
\caption{}
\end{figure}

En la figura vemos unos ejemplos de derivadas direccionales sobre la función $f(x,y)=\sin(x^2+y^2)$, las direcciones son $(1,0)$ y $(0,1)$ sobre el punto $(0,1)$. Es fácil ver que $f'(a,\lambda v)=\lambda f'(a,v)$ (con cambio de variable en los límites) con $\lambda\in\R_0$, luego elegiremos los $v$ tales que $\Vert v\Vert=1$.

Por otro lado, definiremos la \textit{derivada parcial} de $f$ como
$$D_if(a)=\frac{\partial f}{\partial x_i}(a)=f'(a;e_i),$$
donde $e_i=(0,\dots,1,\dots,0)$ en donde hay un único 1 en la $i$-ésima posición. Más formalmente
\begin{equation}
\frac{\partial f}{\partial x_i}(a)=\lim_{\epsilon\to 0}\frac{f(a_1,\dots,a_i+\epsilon,\dots,a_n)-f(a)}{\epsilon}.
\end{equation}
Esto nos es útil pues todo vector $v$ puede expresarse como $(v_1,\dots,v_n)$, luego
\begin{equation}
f'(a,v)=\sum_{i=1}^n v_i\frac{\partial f}{\partial x_i}(a).
\end{equation}
Un ejemplo rápido es tener la función $f(x,y)=x^y$, podemos ver que $D_1f(x,y)=yx^{y-1}$ y $D_2f(x,y)=x^y\cdot\ln x$; la analogía tras la derivada parcial es considerar las otras variables como ``constantes'' al momento de trabajar.

\part*{Apéndices}
\appendix
\chapter{Biografías matemáticas}
\section{Isaac Newton}
\begin{wrapfigure}{R}{.3\textwidth}
\includegraphics[width=.25\textwidth]{Newton.jpg}
\caption{}
\end{wrapfigure}
Isaac Newton nació el 5 de enero de 1643\footnote{Aun que en sus tiempos por el uso del calendario juliano era el 25 de noviembre de 1942.} en el pueblo de Woolsthorpe, Inglaterra. Su padre biológico --de quién heredó el nombre-- había ya muerto para su nacimiento, tres años más tarde su madre se casaría con otro hombre el cuál lo enviaría a vivir con sus abuelos. Este hecho le fue profundamente traumático para el joven Newton, quién nunca demostraría afecto alguno por aquellos parientes y cuya relación sería recíproca con su abuelo. En 1953 su padrastro fallecería, lo que llevaría a su madre a mudarse con el chico, acompañada de dos hermanastros suyos. Esta unión sería realmente efímera, al cabo de dos años se le enviaría al colegio de Grantham.

En la escuela, Newton demostró un cierto gusto por la teología --de hecho lo podemos caracterizar como un personaje muy ortodoxo a los principios del catolicismo antiguo-- y ciertas ramas clásicas de la matemática como la geometría y aritmética en particular. Se dice que un día un compañero suyo le daría un golpe fatal en el estómago que motivaría su rabia al punto de retarlo a una pelea --en el que saldría vencedor-- y que sería el punto culmine de una rivalidad eterna, que inspiraría en Newton una ambición por superarle en todo aspecto, particularmente en lo académico.

El indiscutible conocimiento y hábitos de estudio de Newton, sumado a sus experiencias solitarias con sus abuelos, hicieron de él un joven extremadamente reservado. En la casa de hospedaje de Grantham conocería a una muchacha, con la que se cree tendría un romance juvenil, esta podría haber sido su única experiencia romántica del científico.

Asistió a la Universidad de Cambridge en la cual asistía intermitentemente, debido a que su verdadera pasión yacía en la biblioteca, rodeado de las obras más importantes del momento: \textit{Geometría} de Descartes, \textit{Astronomiae Pars Optica} de Kepler, \textit{Aritmética} de John Wallis, etc. Se graduaría en el Trinity College.

Su intelecto le valió de un puesto como lider de la Royal Society. Sus compañeros le describen como una persona vengativa y cruel; especialmente ante sus ``rivales'' Hooke y Leibniz. Curiosamente, sería una carta de Hooke respecto a sus ideas sobre la gravitación que le inspirarían a escribir su libro \textbf{Principios Matemáticos de la Filosofía Natural}, que sentaría las bases de la teoría universal de la Gravedad y los principios de la mecánica newtoniana. Además de ello, cerca de los veinte años descubriría su famoso teorema del binomio y el \textbf{Método de las Fluxiones}, libro que se llama fundamental en la creación del cálculo diferencial e integral. Años más tarde también demostraría interés en la óptica geométrica, escribiendo \textbf{Óptica} en 1704. Todo esto es lo que genera que Newton sea reconocido como el científico ingenioso más importante de la historia.

\section{Augustin Louis Cauchy}
\begin{wrapfigure}{R}{.3\textwidth}
\includegraphics[width=.25\textwidth]{Cauchy.jpg}
\caption{}
\end{wrapfigure}
Augustin Louis Cuachy nació el 21 de agosto de 1789 en Paris, Francia; durante el periodo de la Revolución Francesa, de un padre que era abogado del cuartel de policía francesa. Como resultado de todas las transformaciones socio-políticas, el joven tuvo una infancia difícil y agitada, lo que le dio este carácter anti-revolucionario al matemático.

Estudió en la Escuela Politécnica de Paris, donde obtuvo su título como ingeniero, aun que sus ideales y pensamiento político se ganaron el desagrado de varios de sus colegas. Debido al oficio de su padre, fue introducido a un par de los matemáticos más importantes de la época, Lagrange y Laplace; quienes al ver el talento del francés, quedaron impresionados, guiándolo a través de sus estudios.

A lo largo de la historia, podría considerarsele uno (sino) de los matemáticos más brillantes y prolíficos de toda la historia. Sus aportes abordan principalmente el análisis matemático, formalizando los conceptos de límite, continuidad y complitud; aun que también otorgó numerosos aportes a la teoría de números, ecuaciones diferenciales, física --en particular la óptica y el electromagnetismo-- y probabilidad. Se cuenta que en total escribió ocho libros y 798 artículos, entre los que se encuentran \textbf{Cours d'Analyse}.


\nocite{*}
\printbibliography

\end{document}
